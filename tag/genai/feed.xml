<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator>
  <link href="https://heuristicwave.github.io/tag/genai/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://heuristicwave.github.io/" rel="alternate" type="text/html" />
  <updated>2024-03-31T00:17:52+00:00</updated>
  <id>https://heuristicwave.github.io/tag/genai/feed.xml</id>

  
  
  

  
    <title type="html">Heuristic Wave Blog | </title>
  

  
    <subtitle>Careful Writer</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">LLM Evaluation에 대해 끄적이기</title>
      <link href="https://heuristicwave.github.io/LLMEvaluation" rel="alternate" type="text/html" title="LLM Evaluation에 대해 끄적이기" />
      <published>2024-03-31T00:00:00+00:00</published>
      <updated>2024-03-31T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/LLMEvaluation</id>
      <content type="html" xml:base="https://heuristicwave.github.io/LLMEvaluation">&lt;p&gt;LLMOps, LLM App Development Life Cycle의 한 부분 LLM Evaluation에 대하여…&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;LLM Evaluation 솔루션에 대해 조사를 하다, 도입부에 소개할 만한 좋은 글을 발견했습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://maverickventures.medium.com/what-the-history-of-software-development-tells-us-about-the-hurdles-to-enterprise-adoption-of-llms-c96bc968456d&quot;&gt;📝 What the History of Software Development Tells Us about the Hurdles to Enterprise Adoption of LLMs&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;소프트웨어 개발 프로세스에 모든 단계가 중요하지만, 궁극적인 목표는 사용자에게 안정적으로 가치를 제공하는 것이므로 ‘테스트’, ‘평가’, ‘모니터링’은 항상 역사적으로 큰 시장이었습니다.
자체 설문 조사에서 LLM을 운영에 배포하는 데 있어 가장 큰 장벽은 “모델 품질 평가(evaluating model quality)”를 꼽았습니다.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;LLM Evaluate, Test, Monitoring Landscape&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;아래 그림은 위에서 언급한 글에 소개된 LLMOps Landscape로, 잘못된 내용들이 있으므로 참고만 하세요.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:4800/format:webp/1*7ot7nNqNWIu7Tw8X8yyGsw.png&quot; width=&quot;870&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 포스팅에서는 해당 글에서 소개하는 여러 LLM 평가 스타트업 중, ‘UpTrain’과 ‘Ragas’를 중점으로 이야기를 풀어나가 보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1️⃣-uptrain&quot;&gt;1️⃣ &lt;a href=&quot;https://uptrain.ai/&quot;&gt;UpTrain&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;주요-특징&quot;&gt;주요 특징&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ycombinator.com/companies/uptrain-ai&quot;&gt;Y Combinator&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/uptrain-ai/uptrain&quot;&gt;GitHub(1.9k)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Ground Truth 비교, 사용자 정의 평가 등 9개의 범주 아래, 20개의 평가 메트릭을 제공&lt;/li&gt;
  &lt;li&gt;LlamaIndex, Langfuse, ChromaDB 등에 대한 통합 제공&lt;/li&gt;
  &lt;li&gt;홈페이지에서 GDPR, ISO 27001 취득한 것으로 보임&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;사용-방법&quot;&gt;사용 방법&lt;/h3&gt;

&lt;h4 id=&quot;llm-모델-선택&quot;&gt;LLM 모델 선택&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uptrain&lt;/code&gt;을 설치하고 다음과 같이 모델을 선택합니다. 본래 모델 선택 시, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EvalLLM()&lt;/code&gt;에 LLM 호출을 위한 KEY를 기재합니다.
Amazon Bedrock 서비스를 사용하는 경우, Settings를 활용해 LLM 주입이 가능합니다. (&lt;a href=&quot;https://github.com/uptrain-ai/uptrain/issues/589&quot;&gt;참고&lt;/a&gt;)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;uptrain&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EvalLLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Evals&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bedrock/anthropic.claude-3-sonnet-20240229-v1:0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eval_llm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EvalLLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;평가-dataset-준비&quot;&gt;평가 DataSet 준비&lt;/h4&gt;

&lt;p&gt;아쉽게도 UpTrain에서는 평가 DataSet 생성을 보조하는 기능이 아직은 없습니다. 질문(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;question&lt;/code&gt;), 맥락(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;context&lt;/code&gt;), 답변(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;response&lt;/code&gt;)을 다음과 같이 준비합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;question&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Which is the most popular global sport?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Who created the Python language?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;context&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;_comment&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;생략&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;response&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Football is the most popular sport with around 4 billion followers worldwide&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Python language was created by Guido van Rossum.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;평가-메트릭-선택&quot;&gt;평가 메트릭 선택&lt;/h4&gt;

&lt;p&gt;제공되는 &lt;a href=&quot;https://docs.uptrain.ai/predefined-evaluations/overview&quot;&gt;지표&lt;/a&gt;를 참고하여, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;checks&lt;/code&gt; 변수에 list로 주입합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eval_llm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Evals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONTEXT_RELEVANCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Evals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FACTUAL_ACCURACY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Evals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RESPONSE_COMPLETENESS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Results
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dumps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;details&gt;
  &lt;summary&gt;결과 보기 👉 Click&lt;/summary&gt;

  &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;question&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_comment&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;생략&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;context&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_comment&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;생략&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;response&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_comment&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;생략&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;score_context_relevance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;explanation_context_relevance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Reasoning&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    The extracted context contains two separate paragraphs, each addressing one of the two queries. &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    The first paragraph discusses the popularity of sports globally, &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    mentioning that football is considered the most popular sport with a large following. &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    This information can answer the first query 'Which is the most popular global sport?' completely. &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    The second paragraph provides details about the creation of the Python programming language by Guido van Rossum, &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    which can answer the second query 'Who created the Python language?' completely. &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    Therefore, the extracted context can answer both queries in their entirety.&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Choice&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;score_factual_accuracy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;explanation_factual_accuracy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Result&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: [&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;        {&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Fact&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Football is the most popular sport with around 4 billion followers worldwide.&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Reasoning&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;The context directly states that 'Football is undoubtedly the world's most popular sport' &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    and mentions that it has 'a followership of more than 4 billion people'. &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    This supports the given fact.&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Judgement&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;yes&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;        },&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    {&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Fact&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Python language was created by Guido van Rossum.&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Reasoning&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;The context explicitly mentions that 'Python, created by Guido van Rossum in the late 1980s,
    is a high-level general-purpose programming language'. This directly supports the given fact.&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Judgement&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;yes&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;        }&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;    ]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;score_response_completeness&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;explanation_response_completeness&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;_comment&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;생략&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/details&gt;

&lt;h4 id=&quot;대시보드-사용&quot;&gt;대시보드 사용&lt;/h4&gt;

&lt;p&gt;UpTrain OSS Dashboard도 제공하는데, Docker Compose로 Server Up 하는 스크립트 실행합니다.
이어서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;localhost:3000&lt;/code&gt;에서 코드로 평가를 진행할 때와 동일하게 GUI를 눌러 수행하면 평가 결과를 시각화하여 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/built/images/post/etc/uptrain.png&quot; alt=&quot;dashboard&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;pros-and-cons&quot;&gt;Pros and Cons&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;장점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다양한 상황에서 적용할 수 있는 지표들에 대한 손쉬운 적용&lt;/li&gt;
  &lt;li&gt;Evaluations/Prompts 테스트에 대하여 한 번에 여러 가지 테스트가 가능 (배치)&lt;/li&gt;
  &lt;li&gt;‘A/B 테스트’, ‘사용자 정의 프롬프트 기반 평가 셋(사용자가 평가 기준을 LLM에게 전달)’ 등의 기능 제공&lt;/li&gt;
  &lt;li&gt;Local 환경에서 평가 가능&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;단점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GitHub에서 제공하는 OSS Dashboard가 오퍼링 웹사이트만큼 다양한 기능을 제공하고 있지는 않음&lt;/li&gt;
  &lt;li&gt;평가 후, 얻은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jsonl&lt;/code&gt; 파일을 업로드해서 시각화하는 기능은 미제공&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-생각&quot;&gt;🤔 생각&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=35069839&quot;&gt;UpTrain 팀의 수익화&lt;/a&gt; 계획에서 더 넓은 통합과 Dashboard의 향상된 경험을 제공하는 것으로 보이나,
OSS로 활용한다면 별도의 Dashboard 개발 필요한 것 같습니다. 또한 아직은 통합을 지원하는 범위가 좁지만, 평가 역할 수행하기에는 좋은 도구인 것 같습니다.&lt;/p&gt;

&lt;p&gt;LLM Evaluation은 어렵습니다. 어떻게 평가 기준을 설계해야 하는지 모르겠다면, 제공되는 20여 개의 metrics들로 다양한 시각에서 평가하는 방법을 고려할 수 있을 것 같습니다.
그뿐만 아니라 해당 도구를 채택하지 않더라도, 제공하는 metrics들을 참고하면 계획하고 있는 평가 방법들에 대한 좋은 참고 자료가 되는 것 같습니다.
예를 들어, UpTrain은 응답의 품질을 평가하기 위해 대응 여부, 간결성, 관련성, 유효성, 일관성 등 5가지의 요소로 품질을 평가합니다.
UpTrain이 제공하는 metrics의 종류는 평가 Task를 해결하기 위한 방법들이 되므로, 평가 계획 수립에 유용할 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2️⃣-ragas&quot;&gt;2️⃣ &lt;a href=&quot;https://docs.ragas.io/en/stable/&quot;&gt;Ragas&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;주요-특징-1&quot;&gt;주요 특징&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/explodinggradients/ragas&quot;&gt;GitHub(4.1k)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;RAG 파이프라인 전용 평가 솔루션 : 데이터 셋 생성, RAG 평가, 모니터링 등의 기능 제공&lt;/li&gt;
  &lt;li&gt;정확도, 관련성 등 10개의 범주 아래 다양한 메트릭 제공(평가 방법에 대한 수식 제공)&lt;/li&gt;
  &lt;li&gt;언어별 다중 프롬프트 생성, 평가를 위한 테스트 데이터 증강 등 부가 기능 제공&lt;/li&gt;
  &lt;li&gt;LangChain을 활용한 CSP 모델 및 LlamaIndex, LangSmith 등 다양한 프레임워크에 통합 지원&lt;/li&gt;
  &lt;li&gt;Atina, Zeno, Tonic 등 다양한 방법으로 시각화 제공&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-생각-1&quot;&gt;🤔 생각&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.uptrain.ai/tutorials/analyzing-failure-cases&quot;&gt;UpTrain 문서에서 RAG 파이프라인을 분석하는 글&lt;/a&gt;을 보고, RAG 파이프라인 전용 평가 도구의 필요성을 고민하다 Ragas가 흥미로워 살펴보게 되었습니다.
UpTrain뿐만 아니라, 다른 Evaluation 솔루션들도 ‘RAG 평가’는 방법 중 하나일 뿐, 왜 RAG에 한정하여 전문적인 도구가 필요할지 고민해 보았습니다.
Ragas는 &lt;strong&gt;&lt;a href=&quot;https://docs.ragas.io/en/stable/concepts/metrics_driven.html&quot;&gt;MDD(지표 중심 개발)&lt;/a&gt;&lt;/strong&gt;라는 용어를 내세우며, LLM 앱을 데이터 기반 의사 결정이 매우 중요하다고 강조합니다.
해당 사실은 Ragas뿐만 아니라, 다른 Evaluation 솔루션들도 입을 모아 Observability의 중요성을 언급합니다.
그러나 다른 솔루션들의 문서와는 달리, Ragas 문서는 &lt;a href=&quot;https://docs.ragas.io/en/stable/concepts/metrics/index.html&quot;&gt;측정 메트릭&lt;/a&gt; 별, 수식과 예시와 함께 제공하니 그들의 주장에 조금 더 마음이 가는 것 같습니다.&lt;/p&gt;

&lt;p&gt;Ragas의 테스트 데이터 셋 생성 기능은 Ragas를 채택하지 않더라도 도움이 될 것 같습니다. 더하여 Ragas는 내부적으로 langchain을 활용하므로,
프로덕션급 LLM 앱 구축 플랫폼인 &lt;a href=&quot;https://docs.smith.langchain.com/&quot;&gt;LangSmith&lt;/a&gt;를 보완하여 더 나은 기능을 제공할 것으로 보입니다. (앞으로의 숙제네요 🫠)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;Evaluation에서도 Data가 매우 중요합니다. 아직 스터디가 더 필요하지만, 그동안 ‘평가 Data 제작’ 부분은 종종 봤지만, ‘평가 Data 활용 방안’은 더 적은 것 같습니다.
평가 &lt;strong&gt;Data의 재사용성&lt;/strong&gt;을 높이기 위해 고려할 지점이 있어 보여, 다음과 같이 몇 자 끄적이며 마치도록 하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt; : sLM 도입 및 파인튜닝 시, 튜닝을 위한 Datasets에 평가 Datasets을 활용할 수 있음&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;호환성&lt;/strong&gt; : 다양한 평가도구들이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jsonl&lt;/code&gt; 형태로 지원하여, 이기종 간 호환이 자유롭다면 다양한 평가 가능&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="llm" />
      
        <category term="genai" />
      

      
        <summary type="html">LLMOps, LLM App Development Life Cycle의 한 부분 LLM Evaluation에 대하여…</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ReAct leverages LLM as a reasoning engine</title>
      <link href="https://heuristicwave.github.io/ReAct" rel="alternate" type="text/html" title="ReAct leverages LLM as a reasoning engine" />
      <published>2024-02-18T00:00:00+00:00</published>
      <updated>2024-02-18T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/ReAct</id>
      <content type="html" xml:base="https://heuristicwave.github.io/ReAct">&lt;p&gt;LLM을 추론엔진으로 활용하는 ReAct (with LangChain &amp;amp; Amazon Bedrock)&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/&quot;&gt;LangChain for LLM Application Development&lt;/a&gt; 강의에서 Andrew Ng 교수님은 &lt;em&gt;“사람들은 때때로 LLM이 많은 정보를 암기하기 위해 학습된 지식 저장소라 생각한다”&lt;/em&gt;라며,
LLM을 더 유용하게 사용하는 방법은 추론(Reasoning) 엔진으로 생각하는 것이 더 유용하다고 말합니다. 교수님의 말대로 추론엔진으로써의 LLM을 활용하기 위해서는 ReAct 개념을 숙지해야 하는데요,
저는 작년 5월경 AutoGPT, BabyAGI가 소개될 때 ReAct를 처음 접했는데 굉장히 어려운 개념이다 보니 이해하는데 시간이 오래 걸렸습니다.&lt;/p&gt;

&lt;p&gt;ICLR 2023, &lt;a href=&quot;https://arxiv.org/abs/2210.03629&quot;&gt;ReAct: Synergizing Reasoning and Acting in Language Models&lt;/a&gt; 논문에서 LLM을 사용하여 인터리브 방식으로 &lt;strong&gt;추론 추적(reasoning traces)&lt;/strong&gt;과 &lt;strong&gt;작업별 동작(task-specific actions)&lt;/strong&gt;을 모두 생성하는 ReAct라는 프레임워크를 소개했습니다.
이후, LangChain(이하, 🦜️🔗)에서는 Agents를 통해 ReAct 기법을 지원하기 시작했습니다. 앞으로 3편 이상의 시리즈물을 통해, ReAct 개념과 구현 및 AWS, OpenAI 등의 회사가 어떻게 ReAct와 관련된 제품을 설계했는지 등을 알아보겠습니다.
이번 포스팅에서는 LLM을 추론엔진으로 활용하는 ReAct의 개념과 Amazon Bedrock과 🦜️🔗을 활용해 ReAct 기법을 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1️⃣-react-prompting&quot;&gt;1️⃣ &lt;a href=&quot;https://www.promptingguide.ai/techniques/react&quot;&gt;ReAct Prompting&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;앞서 언급한 ReAct 논문을 바탕으로 작성된 Prompt Engineering Guide 문서는 ReAct Prompting을 다음과 같이 설명합니다.&lt;/p&gt;

&lt;p&gt;ReAct는 인간이 새로운 작업을 학습하고 의사 결정이나 추론을 할 수 있도록 하는 “행동” 과 “추론”의 시너지 효과에서 영감을 받았다고 합니다.
첫 번째 단계는 트레이닝 세트(예:&lt;a href=&quot;https://huggingface.co/datasets/hotpot_qa&quot;&gt;HotPotQA&lt;/a&gt;)에서 사례를 선택하고 ReAct 형식의 궤적(trajectories)을 구성합니다.
이는 일종의 퓨샷(few-shot) 예시로 사용됩니다. 궤적은 여러 생각-행동-관찰(thought-action-observation) 단계로 구성됩니다.&lt;/p&gt;

&lt;h3 id=&quot;️-agents&quot;&gt;🦜️🔗 &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/concepts&quot;&gt;Agents&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;앞서 소개한 ReAct의 개념을 🦜️🔗에서는 Agents라는 개념으로 구현했습니다. Agents의 핵심 아이디어는 언어 모델을 추론 엔진으로 사용해 어떤 작업을 어떤 순서로 수행할지 결정하는 것입니다.
Agents를 크게 5개의 핵심 컴포넌트로 구성되어 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Schema
    &lt;ul&gt;
      &lt;li&gt;AgentAction : Agent가 수행해야 하는 작업을 나타내는 dataclass&lt;/li&gt;
      &lt;li&gt;AgentFinish : Agent의 최종 결과, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;return_values&lt;/code&gt;의 경우 &lt;strong&gt;key-value&lt;/strong&gt; 형태로 리턴&lt;/li&gt;
      &lt;li&gt;Intermidiate Steps : Agents 사이의 출력, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;List[Tuple[AgentAction, Any]]&lt;/code&gt; 타입으로 Observation은 최대한의 유연성을 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Any&lt;/code&gt;로 남겨짐(실제로는 대부분 문자열)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Agent : 다음 단계에 수행할 역할을 결정하며, 보통 &lt;em&gt;‘언어 모델’, ‘프롬프트’&lt;/em&gt; 와 &lt;em&gt;‘output parser’&lt;/em&gt;로 실행됨
    &lt;ul&gt;
      &lt;li&gt;Agent Inputs : &lt;strong&gt;key-value&lt;/strong&gt; 매핑의 형. 일반적으로 PromptTemplate은 LLM에 잘 전달할 수 있는 형식으로 변환하는 처리&lt;/li&gt;
      &lt;li&gt;Agent Outputs : 다음에 수행할 작업(&lt;strong&gt;AgentActions&lt;/strong&gt;) 혹은 최종 응답(&lt;strong&gt;AgentFinish&lt;/strong&gt;)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AgentExecutor : Agent의 런타임. Agent를 호출하고, 선택한 작업을 실행하고, 출력을 Agent로 전달하고 반복하는 역할&lt;/li&gt;
  &lt;li&gt;Tools : Agent가 호출할 수 있는 함수. (Tool에 올바른 권한과 도움 되는 방식으로 설명해야 함)&lt;/li&gt;
  &lt;li&gt;Toolkits : 특정 목표를 달성하기 위해 여러 개의 tool이 필요하다면, toolkit을 통해 제공&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2️⃣-실시간으로-상호-작용하는-llm-with-bedrock&quot;&gt;2️⃣ 실시간으로 상호 작용하는 LLM (with Bedrock)&lt;/h2&gt;

&lt;p&gt;Amazon Bedrock Playground에서 Claude 2.1 모델에 23년 아시안컵 우승국을 물어보면, 아직 개최되지 않았다는 정보와 함께 22년 아시안컵이 우승국이 호주라는 환각이 발생합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/23AFC.png&quot; alt=&quot;AFC&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아직 Claude 2.1 모델은 23년 아시안컵에 대해서 사전학습된 정보가 없지만, LangChain을 활용해 실시간으로 정보를 검색해 답변이 가능하도록 구현해 보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.agents&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_tools&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AgentType&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain_community.chat_models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BedrockChat&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;chat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BedrockChat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anthropic.claude-v2:1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model_kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;max_tokens_to_sample&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;temperature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;region_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;us-west-2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_tools&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wikipedia&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AgentType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHAT_ZERO_SHOT_REACT_DESCRIPTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;handle_parsing_errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2023년, AFC 아시안컵에서 우승한 나라는?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initialize_agent&lt;/code&gt; 함수를 사용해 간단하게 Agent를 구현했습니다. Agent를 사용하기 위해, 사용할 도구, 모델, Agent Type 등을 인자로 받습니다.
여기서는 Wikipedia를 사용하는 도구를 로드하고, 위에서 초기화한 BedrockChat 모델을 대화(chat) 모델로 사용합니다. 그리고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CHAT_ZERO_SHOT_REACT_DESCRIPTION&lt;/code&gt; 타입의 Agent로 초기화해 사용합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/ReAct.png&quot; alt=&quot;ReAct&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같이 질문을 받아, wikipedia를 tool로 사용하여 thought-action-observation 단계를 거쳐 최종적으로 2023 아시안컵 우승국이 카타르라는 사실을 성공적으로 도출했습니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;해당 예시는 앞서 소개한 🦜️🔗 Agents의 5가지 컴포넌트가 나와있지만, 아주 간단한 Agent라 앞서 배운 AgentExecutor, Toolkits 등의 개념이 나와있지 않습니다.
다음 편에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create_react_agent&lt;/code&gt; 등의 함수로 교체하며 자세히 다루겠습니다.&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 이번 예시에서 다룬 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initialize_agent&lt;/code&gt;는 0.1.0(&lt;a href=&quot;https://blog.langchain.dev/langchain-v0-1-0/&quot;&gt;24년 1월 8일 release&lt;/a&gt;)에서 deprecate 되었으며, 0.2.0에서는 삭제될 예정입니다. &lt;br /&gt;
&lt;em&gt;LangChainDeprecationWarning: The function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initialize_agent&lt;/code&gt; was deprecated in LangChain 0.1.0 and will be removed in 0.2.0.
Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3️⃣-tools&quot;&gt;3️⃣ Tools&lt;/h2&gt;

&lt;h3 id=&quot;️-load_tools&quot;&gt;🛠️ &lt;a href=&quot;https://api.python.langchain.com/en/latest/agents/langchain.agents.load_tools.load_tools.html&quot;&gt;load_tools&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;이전 예시에서는 단 하나의 tool(wikipedia)만을 정의해, llm의 선택지가 하나밖에 존재하지 않았지만, 다음과 같은 형태로 다양할 tool 들을 준비하고 LLM의 추론을 완성시킬 수 있습니다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tools = load_tools([&quot;llm-math&quot;,&quot;wikipedia&quot;])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;만약, 특정 액션 이후 누군가에게 이메일을 보내야 하는 Action을 추가하려면, AWS Lambda에 email을 보내는 함수를 만들어두고 다음과 같이 tool로 활용해 llm에 의해 이메일을 발송할 수도 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example : &lt;a href=&quot;https://python.langchain.com/docs/integrations/tools/awslambda&quot;&gt;AWS Lambda&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_tools&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;awslambda&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;awslambda_tool_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;email-sender&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;awslambda_tool_description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sends an email with the specified content to test@testing123.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;function_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;testFunction1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AgentType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZERO_SHOT_REACT_DESCRIPTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Send an email to test@testing123.com saying hello world.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;load_tools에는 AWS Lambda 외에 Amazon API Gateway도 있고, 필요하다면 다음과 같이 직접 tool을 만들 수도 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;️-custom-tools&quot;&gt;⚒️ &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/tools/custom_tools&quot;&gt;Custom Tools&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;다음은 단어의 글자 수를 구하는 간단한 Custom Tool입니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@tool&lt;/code&gt; decorator와 함께 함수(tool 이름)와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;description&lt;/code&gt; 정의 후, Agent에서 호출해 사용합니다.
Custom Tools은 앞서 배운 &lt;strong&gt;🦜️🔗 Agents&lt;/strong&gt;의 핵심 컴포넌트를 유의하여 작성해야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tool&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;단어의 글자수를 구합니다.&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AgentType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZERO_SHOT_REACT_DESCRIPTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;invoke&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;input&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;langchain의 글자수를 구하시오.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;코드가 로직상으로 맞을 수 있지만, 추론에 의거하여 답을 구하기 때문에 원하는 대답이 나오지 않을 수도 있습니다. 
예를 들어, ‘Tool에 올바른 권한과 도움 되는 방식으로 설명해야 함’을 무시하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;description&lt;/code&gt;에 ‘&lt;em&gt;단어의 글자 수를 구하는 질문에 해당 도구를 사용하지 마세요.&lt;/em&gt;‘라고 기재하면 다음과 같이 잘못된 추론을 진행합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/customTool.png&quot; alt=&quot;customTool&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;이번 포스팅에서는 ReAct 개념을 🦜️🔗에서 &lt;strong&gt;Agents&lt;/strong&gt;로 알아보았습니다.
다음 포스팅에서는 AWS가 ReAct 개념을 구현한 &lt;strong&gt;Agents for Amazon Bedrock&lt;/strong&gt;과 Open AI의 &lt;strong&gt;Function calling&lt;/strong&gt;를 비교하며 각각 어떻게 ReAct를 구현했는지 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="llm" />
      
        <category term="genai" />
      
        <category term="aws" />
      

      
        <summary type="html">LLM을 추론엔진으로 활용하는 ReAct (with LangChain &amp;amp; Amazon Bedrock)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">3 Ways to Use the Hugging Face Model in AWS</title>
      <link href="https://heuristicwave.github.io/HuggingFace-1" rel="alternate" type="text/html" title="3 Ways to Use the Hugging Face Model in AWS" />
      <published>2023-08-23T00:00:00+00:00</published>
      <updated>2023-08-23T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/HuggingFace-1</id>
      <content type="html" xml:base="https://heuristicwave.github.io/HuggingFace-1">&lt;p&gt;AWS에서 Hugging Face 모델을 사용하는 3가지 방법&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;Hugging Face(이하, 🤗)는 2016년에 설립되어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Transformer&lt;/code&gt; 라이브러리와 다양한 사전훈련된(pre-trained) 모델을 제공하는 NLP 커뮤니티(?)의 선두주자입니다.
AWS와 🤗는 21년도부터 협업하여 AWS에서 🤗를 활용할 수 있는 다양한 방법들을 제공하고 있는데요, 이번 포스팅에서는 AWS에서 🤗 모델을 사용하는 3가지 방법에 대하여 가볍게 알아보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1️⃣--모델을-amazon-sagemaker-sdk로-직접-올리기&quot;&gt;1️⃣ 🤗 모델을 Amazon SageMaker SDK로 직접 올리기&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2021/03/leverage-state-of-the-art-natural-language-processing-with-hugging-face-and-amazon-sagemaker/&quot;&gt;21년 3월 23일&lt;/a&gt;, AWS whats-new에 처음 소개된 이 방법은 🤗 모델을 직접 SageMaker SDK를 사용해 올리는 가장 일반적인 방법입니다.
아주 유명한 Text Generation 모델인 Google의 &lt;a href=&quot;https://huggingface.co/google/flan-t5-small&quot;&gt;FLAN-T5&lt;/a&gt;를 예시로 들어보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/flan.png&quot; alt=&quot;flan-t5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림의 좌측 Deploy 버튼을 보면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flan-t5&lt;/code&gt; 모델의 5가지 배포 방법이 나와 있습니다. 해당 모델의 경우, 인기가 많은 모델이라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Inference API&lt;/code&gt;를 눌러 무료로 API를 활용할 수도 있고,
Amazon SageMaker에 직접 배포해 사용할 수도 있습니다. SageMaker를 사용하기로 하고 해당 버튼을 누르면, 아래와 같이 쉽게 배포할 수 있는 코드를 제공해 줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/hf-sagemaker.png&quot; alt=&quot;hf-sagemaker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림의 상단을 확인하면 &lt;strong&gt;SageMaker SDK, Jumpstart, Cloudformation(soon)&lt;/strong&gt; 이라 적힌, 1️⃣번 방법은 &lt;strong&gt;SageMaker SDK&lt;/strong&gt;를 활용한 방법입니다.
제공되는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy.py&lt;/code&gt;에서 호스팅을 위한 사전 작업(spec, role 등)을 정의하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy()&lt;/code&gt; 함수로 모델을 배포합니다.&lt;/p&gt;

&lt;p&gt;1️⃣번 방법은 배포에 필요한 환경을 일일이 코드로 작성하기 때문에, 배포는 번거롭지만 방법만 안다면 사용해 보고 싶은 모든 모델에 활용할 수 있습니다.
이어서 소개드릴 2️⃣, 3️⃣번 방법이 간단하지만, 모든 모델에 적용되는 것은 아니므로 1️⃣번 방법을 배제할 수는 없습니다.
뿐만 아니라, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy.py&lt;/code&gt;에서 제공하는 코드가 멱등성을 보장하지 않으므로 모델 배포 도중 발생하는 오류들을 핸들링 해야 하는 지식이 필요합니다.
그러나, Cloudformation으로 배포하는 기능이 Soon인 것으로 보아 향후 더 손쉽게 배포가 가능할 것 같아 기대됩니다.&lt;/p&gt;

&lt;h2 id=&quot;2️⃣-amazon-sagemaker-jumpstart로--모델-사용하기&quot;&gt;2️⃣ Amazon SageMaker JumpStart로 🤗 모델 사용하기&lt;/h2&gt;

&lt;p&gt;AWS의 서비스들을 보면 Managed 서비스를 참 잘 만듭니다. 21년 3월 직접 호스팅 하는 방법이 소개되었다면, &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2021/08/amazon-sagemaker-one-click-model-inference-fine-tuning-hugging-face-models-amazon-sagemaker-jumpstart/&quot;&gt;21년 8월 10일&lt;/a&gt;
one-click으로 🤗의 모델들을 사용할 수 있는 JumpStart 서비스가 출시했습니다.&lt;/p&gt;

&lt;p&gt;오늘을 기준으로 🤗 모델을 검색했을 때, 263개의 모델들을 Deploy 버튼 한 번으로 손쉽게 배포할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/jumpstart-hf.png&quot; alt=&quot;jumpstart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;추가적으로 위와 같이 콘솔 화면에서 클릭을 통한 배포 이외에도, 1️⃣번 방법에서 소개한 🤗 Hub에서 모델을 검색하고 제공하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;app.py&lt;/code&gt; 코드를 참고해 스크립트를 사용해 배포가 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;flan-t5-small &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;app.py&lt;/code&gt; 예시&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# SageMaker JumpStart provides APIs as part of SageMaker SDK that allow you
# to deploy and fine-tune models in network isolation using scripts that SageMaker maintains.
&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sagemaker.jumpstart.model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JumpStartModel&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;huggingface-text2text-flan-t5-small&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;endpoint_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;A step by step recipe to make bolognese pasta:&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JumpStartModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Inference:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint_input&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Response: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3️⃣--inference-endpoints-사용하기&quot;&gt;3️⃣ 🤗 &lt;a href=&quot;https://ui.endpoints.huggingface.co/&quot;&gt;Inference Endpoints&lt;/a&gt; 사용하기&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://huggingface.co/blog/aws-marketplace&quot;&gt;23년 8월 10일&lt;/a&gt; 🤗 플랫폼이 AWS Marketplace에서 사용할 수 있게 되었습니다.
🤗 계정에서 Organization을 생성하고 AWS Marketplace에서 구독 버튼을 눌려 계정 간 연결을 진행하면 🤗 플랫폼 사용료를 내 AWS 계정으로 비용 청구가 가능합니다.
자세한 계정 간 연동 방법은 &lt;a href=&quot;https://huggingface.co/blog/aws-marketplace&quot;&gt;여기&lt;/a&gt;를 참조하세요.&lt;/p&gt;

&lt;p&gt;계정 통합이 완료되면 &lt;a href=&quot;https://ui.endpoints.huggingface.co/&quot;&gt;Inference Endpoints&lt;/a&gt;에서 아래와 같이, 모델을 검색하고 리전, Instance 등 배포 유형을 선택하면 손쉽게 배포가 가능합니다.
GPU 가격이 AWS 인스턴스 표기법이 아니라 직접적인 가격비교는 어려웠지만, 대략 &lt;strong&gt;AWS 인스턴스 가격 대비 1.X&lt;/strong&gt; 배라고 생각하시면 됩니다.
3️⃣번 방법의 경우, 2️⃣번 방법과 비교하여 🤗 계정을 만들어야 하지만 지원하는 모델도 다양하고 1️⃣번 방법과 비교하여 매우 편리한 방법으로 제공되기 때문에, 제가 가장 좋아하는 방법입니다.
물론 모든 모델들이 해당 방법으로 원활히 제공되는 것은 아니지만, 다양한 오픈소스 모델들을 빠르게 PoC 하고 싶을 때 사용하면 굉장히 좋은 방법 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/inferenceEP.png&quot; alt=&quot;inferenceEP&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚡️ Security level&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Protected : 🤗의 토큰 기반 인증 과정이 필요합니다.&lt;/li&gt;
    &lt;li&gt;Public : 완전히 공개된 API로 별도의 인증이 필요 없습니다.&lt;/li&gt;
    &lt;li&gt;Private : AWS Account ID를 기재하고 PrivateLink로 연결합니다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;시간순으로 소개한 위 3가지 방법에서, AWS의 상품화 과정과 타 회사와의 협업 방식도 알 수 있었습니다.
오픈소스 모델을 AWS로 호스팅 하는 1️⃣번과 2️⃣번 방법으로는 🤗 측면에서 매출을 만들기 어려운데, 3️⃣번 방식을 통해 🤗와 AWS 모두 Win-Win 하는 비즈니스 모델을 만들어 나간 것 같아 무척 흥미롭네요.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Gen AI Study Checkpoint&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./GenAI-1&quot;&gt;Prompt Design Study&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="huggingface" />
      
        <category term="genai" />
      
        <category term="aws" />
      

      
        <summary type="html">AWS에서 Hugging Face 모델을 사용하는 3가지 방법</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Generative AI 1 - Prompt Design Study</title>
      <link href="https://heuristicwave.github.io/GenAI-1" rel="alternate" type="text/html" title="Generative AI 1 - Prompt Design Study" />
      <published>2023-08-03T00:00:00+00:00</published>
      <updated>2023-08-03T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/GenAI-1</id>
      <content type="html" xml:base="https://heuristicwave.github.io/GenAI-1">&lt;p&gt;본 글은 제 개인적 학습을 위해 &lt;a href=&quot;https://www.cloudskillsboost.google/focuses/63251?parent=catalog&quot;&gt;Generative AI with Vertex AI: Prompt Design&lt;/a&gt; 실습한 내용의 일부를 적은 글입니다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Prompt Design&lt;/code&gt;에 대하여 설명하지 않으며, 학습이 필요하시다면 Intro 부분을 참고하시기 바랍니다.&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;요즘 주목받는 GenAI를 공부하며, 많은 자료들을 찾아보고 있습니다. 과거에도 Google은 제가 k8s나 terraform을 공부할 때도 도움이 되는 학습자료를 많이 제공해 주었는데, GenAI 분야에서도 큰 도움을 주고 있네요. (&lt;em&gt;🤗 문서와 더불어 학습하기 정말 최고인 것 같습니다.&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;실습 환경을 제공해 주는 Qwiklabs(&lt;a href=&quot;https://www.cloudskillsboost.google/focuses/63251?parent=catalog&quot;&gt;Generative AI with Vertex AI: Prompt Design&lt;/a&gt;)에서 실습을 할 수 있지만,
해당 과정은 크레딧이 필요한 유료과정입니다. 그러나, &lt;a href=&quot;https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/prompts/examples&quot;&gt;GoogleCloudPlatform의 generative-ai 깃헙&lt;/a&gt;에서 Colab에서 실습할 수 있는 환경을 제공하고 있습니다.
또한, 파이썬 코드만 참고하여 Google Cloud의 Vertex AI 대신 다른 언어 모델을 활용해 과금을 피할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-prompt-design-best-practices&quot;&gt;👍 Prompt Design Best Practices&lt;/h2&gt;

&lt;p&gt;프롬프트의 의도를 잘못 해석할 가능성을 줄이기 위해 “unfancy” 하게 작성하는 방법을 다음과 같이 안내합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;간결하게 작성&lt;/li&gt;
  &lt;li&gt;구체적이고 명확하게 정의&lt;/li&gt;
  &lt;li&gt;한 번에 하나의 작업만 요청&lt;/li&gt;
  &lt;li&gt;예시를 포함하여 응답 품질 개선&lt;/li&gt;
  &lt;li&gt;생성 작업을 분류 작업으로 바꿔 안전성 개선&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;생성형 작업은 브레인스토밍에 유용한 개방형 응답을 유도합니다. &lt;br /&gt; &lt;em&gt;예) 프로그래밍 실력을 향상시키는 방법을 추천해 주세요.&lt;/em&gt; &lt;br /&gt;
분류 작업은 결과의 가변성을 줄입니다. &lt;br /&gt; &lt;em&gt;예) Python, Java, C 중 어떤 활동을 추천하고 이유를 알려주세요&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 원칙을 포함하여 N-shot Prompting을 통해 향상된 답변을 받을 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;️-prompt-design&quot;&gt;🖥️ &lt;a href=&quot;https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/intro_prompt_design.ipynb&quot;&gt;Prompt Design&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;해당 부분에서는 5가지 분야에서 효과적인 Prompt를 작성하는 방법을 안내합니다.&lt;/p&gt;

&lt;h3 id=&quot;1-ideation&quot;&gt;1. Ideation&lt;/h3&gt;

&lt;p&gt;Generative 모델의 장점을 활용하여 아래와 같은 사용 예시를 소개합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;마케팅 캠페인 활용 방법&lt;/li&gt;
  &lt;li&gt;몇 가지 예시 질문을 생성하여 테스트용 문제 제작 방법&lt;/li&gt;
  &lt;li&gt;밈, 인터뷰 질문, 이름 생성&lt;/li&gt;
  &lt;li&gt;팁과 조언 받기&lt;/li&gt;
  &lt;li&gt;의인화(impersonation) 하여 답변 받기&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-question--answering&quot;&gt;2. Question &amp;amp; Answering&lt;/h3&gt;

&lt;p&gt;question-answering 프롬프트를 만들 때는 가능한 많은 맥락(context)을 제공해야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;배경지식&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Open domain:
    &lt;ul&gt;
      &lt;li&gt;Zero-shot prompting&lt;/li&gt;
      &lt;li&gt;Few-shot prompting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Closed domain:
    &lt;ul&gt;
      &lt;li&gt;Providing custom knowledge as context&lt;/li&gt;
      &lt;li&gt;Instruction-tune the outputs&lt;/li&gt;
      &lt;li&gt;Few-shot prompting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-open&quot;&gt;📭 Open&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Few-shot 프롬프프 예시&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Q: 한국의 수도는 어디인가요?&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
            A: 서울
            Q: 미국의 수도는 어디인가요?&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
            A:
         &quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;-closed&quot;&gt;📪 Closed&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;프롬프트에 내부 지식을 컨텍스트로 추가&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
Amazon S3의 데이터 보호 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
Amazon S3에서는 미션 크리티컬 및 기본 데이터 스토리지에 적합하게 설계된, 내구성이 뛰어난 스토리지 인프라를 제공합니다. &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
AWS 리전의 최소 3개 가용 영역에 걸쳐 여러 디바이스에 객체를 중복 저장합니다.
...생략...
지정된 기간 동안 객체에 대해 99.999999999%의 내구성과 99.99%의 가용성을 제공할 수 있도록 설계되었습니다.
&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;고가용성은 어떻게 달성됩니까?&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;아래 컨텍스트에서 대답합니다:
Context: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
Question: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
Answer:
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Instruction-tuning outputs (미움받을 용기 🤣)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;모델이 컨텍스트에 제공된 외의 정보를 사용할 수 없게 지정하려면 다음과 같은 기법을 반영합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;허깅페이스 모델을 호스팅 하려면 어떻게 해야 하나요?&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;주어진 다음 컨텍스트&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;에 대해 대답하세요. &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
만약 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Context&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;에서 답변할 수 없고 출력에 확신이 없는 경우,
&quot;제공된 컨텍스트에서 사용할 수 없는 정보&quot;라고 말하세요. &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
Context: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
Question: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
Answer:
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;평가&quot;&gt;평가&lt;/h4&gt;

&lt;p&gt;질문과 ground truth(정답)에 대한 데이터 프레임을 만들어, &lt;a href=&quot;https://en.wikipedia.org/wiki/Levenshtein_distance&quot;&gt;Levenshtein distance&lt;/a&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fuzzywuzzy&lt;/code&gt; 라이브러리를 사용해 평가합니다.&lt;/p&gt;

&lt;h3 id=&quot;3-text-classification&quot;&gt;3. Text Classification&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Classify&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Given&lt;/code&gt; 등의 명령어를 프롬프트에 넣어 다양한 텍스트 분류 예시들을 보여줍니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Zero-shot 프롬프팅을 통한 문장 예측&lt;/li&gt;
  &lt;li&gt;Few-shot 프롬프팅을 통한 맥락에 맞는 분류&lt;/li&gt;
  &lt;li&gt;주제 분류/스팸 탐지/의도 인식/언어 파악/유해성 파악/감정 파악&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;평가-1&quot;&gt;평가&lt;/h4&gt;

&lt;p&gt;해당 방법도 앞선 단계와 같이 ground truth(정답)과 예측에 대한 데이터 프레임을 만들고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sklearn.metrics&lt;/code&gt; 등을 활용하여 정확도를 평가합니다.&lt;/p&gt;

&lt;h3 id=&quot;4-text-extraction&quot;&gt;4. Text Extraction&lt;/h3&gt;

&lt;p&gt;다음과 같은 텍스트 추출 예시들을 보여줍니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;출력 예시(JSON 구조)를 프롬프트로 주고, 특정 문자열 들을 나열하여 주어진 포맷으로 출력하기&lt;/li&gt;
  &lt;li&gt;프롬프트에 JSON 구조(key)를 정하고, 해당 키에 맞춰 JSON 구조로 출력하기&lt;/li&gt;
  &lt;li&gt;문맥을 Few-Shot으로 제공하고 명령에 따라 대답 출력하기&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-text-summarization&quot;&gt;5. Text Summarization&lt;/h3&gt;

&lt;p&gt;다음과 같은 지시를 프롬프트에 넣어 텍스트 요약 예시들을 보여줍니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;스크립트 요약
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Provide a very short summary, no more than three sentences, for the following article:&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Provide a TL;DR for the following article:&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;글머리 기호(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt;)로 요약
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Provide a very short summary in four bullet points for the following article:&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#&lt;/code&gt; 토큰화 (SNS에서 #맛집, #추천 등의 요약)
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Tokenize the hashtags of this tweet:&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;5가지의 옵션으로 제목 생성
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Write a title for this text, give me five options:&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;평가-2&quot;&gt;평가&lt;/h4&gt;

&lt;p&gt;요약 결과를 &lt;a href=&quot;https://en.wikipedia.org/wiki/ROUGE_(metric)&quot;&gt;ROUGE&lt;/a&gt; 프레임워크로 평가합니다. 해당 측정법은 컴퓨터가 생성한 요약과 사람의 이상적인 요약 간의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n-gram&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;word sequences&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;word pairs&lt;/code&gt; 등의 겹치는 단어의 수를 계산합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;이제서야, &lt;a href=&quot;https://heuristicwave.github.io/Kendra&quot;&gt;이전 RAG 포스팅&lt;/a&gt;에서 언급했던 메타의 ‘오픈북과 클로스드북 장점의 결합’과 ‘Instruction-tuning outputs의 존재 이유’가 이해 가는 것 같습니다.
또한 정량적인 평가 기준을 마련하는 방법을 알게 되어 매우 뿌듯합니다. 배움의 즐거움을 느끼게 해준 구글의 자료에 다시한번 감사함을 느낍니다.&lt;/p&gt;

&lt;p&gt;본 글의 원본 교육 자료는 이 &lt;a href=&quot;https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/examples/prompt-design&quot;&gt;링크&lt;/a&gt;에서 만날 수 있습니다. 실습을 통해 Gen AI 지식을 얻어 가세요! 🤗&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Gen AI Study Checkpoint&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./GenAI-1&quot;&gt;Prompt Design Study&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="genai" />
      
        <category term="gcp" />
      

      
        <summary type="html">본 글은 제 개인적 학습을 위해 Generative AI with Vertex AI: Prompt Design 실습한 내용의 일부를 적은 글입니다. Prompt Design에 대하여 설명하지 않으며, 학습이 필요하시다면 Intro 부분을 참고하시기 바랍니다.</summary>
      

      
      
    </entry>
  
</feed>
