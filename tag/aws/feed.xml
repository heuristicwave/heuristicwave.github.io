<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator>
  <link href="https://heuristicwave.github.io/tag/aws/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://heuristicwave.github.io/" rel="alternate" type="text/html" />
  <updated>2025-02-01T19:09:29+00:00</updated>
  <id>https://heuristicwave.github.io/tag/aws/feed.xml</id>

  
  
  

  
    <title type="html">Heuristic Wave Blog | </title>
  

  
    <subtitle>Careful Writer</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Exploring Amazon Kendra GenAI Index with Amazon Bedrock Knowledge Bases</title>
      <link href="https://heuristicwave.github.io/Kendra2" rel="alternate" type="text/html" title="Exploring Amazon Kendra GenAI Index with Amazon Bedrock Knowledge Bases" />
      <published>2025-02-01T00:00:00+00:00</published>
      <updated>2025-02-01T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/Kendra2</id>
      <content type="html" xml:base="https://heuristicwave.github.io/Kendra2">&lt;p&gt;Amazon Bedrock Knowledge Bases로 알아보는 Amazon Kendra GenAI Index&lt;/p&gt;

&lt;h2 id=&quot;-kendra-genai-index&quot;&gt;&lt;a href=&quot;#kendra&quot;&gt;🔍 Kendra GenAI Index&lt;/a&gt;&lt;a id=&quot;kendra&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2023년 12월 12일 Amazon Bedrock Knowledge Bases(이하 지식 기반)가 정식 출시된 이후, AWS 생태계에서 유일한 Retriever 역할을 담당하던 Kendra는 한동안 주목받지 못했습니다.
하지만 &lt;a href=&quot;https://aws.amazon.com/ko/about-aws/whats-new/2024/12/genai-index-amazon-kendra/&quot;&gt;2024년 re:Invent에서 Amazon Kendra GenAI Index&lt;/a&gt;라는 새로운 기능이 추가되었습니다.
이는 &lt;strong&gt;Bedrock 지식 기반의 관리형 리트리버로 제공&lt;/strong&gt;되어, 사용자들이 보다 손쉽게 관리형 서비스를 통해 RAG를 구축할 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;새로운 기능의 도입과 함께, AWS는 Amazon Kendra GenAI Index에 대한 새로운 가격 정책을 발표하였습니다.
이 가격 구조는 최신 기능의 가치를 반영하면서도, 서비스의 접근성을 높여 더 많은 사용자들이 고급 검색 및 RAG 기능을 활용할 수 있도록 설계되었습니다.
그럼 이제 Amazon Kendra GenAI Index의 새로운 가격 정책과 그 특징들을 자세히 살펴보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;가격-정책&quot;&gt;&lt;a href=&quot;https://aws.amazon.com/ko/kendra/pricing/&quot;&gt;가격 정책&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;새로운 GenAI 에디션은 커넥터를 제외한 기본 인덱스(스토리지 및 쿼리 요금)의 시간당 비용이 $0.32로, &lt;strong&gt;기존 베이직 에디션 대비 1/4 수준으로 낮아져 더 경제적&lt;/strong&gt;으로 서비스를 이용할 수 있게 되었습니다.
커넥터 요금의 경우, 데이터 동기화가 빈번한 서비스에서는 GenAI 에디션이 비용 효율적일 수 있습니다. 다만, 기본 인덱스 요금만큼 큰 폭의 가격 인하가 이루어지지 않은 점은 아쉬움으로 남습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;구성 요소&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;GenAI 엔터프라이즈 에디션&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;베이직 엔터프라이즈 에디션&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;기본 개발자 에디션&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;기본&lt;br /&gt; 인덱스&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;시간당 0.32 USD &lt;br /&gt;&lt;br /&gt; 포함 항목 &lt;br /&gt;- 최대 문서 20,000개 or 추출된 텍스트 200MB &lt;br /&gt;- 0.1 QPS(하루 약 8,000개의 쿼리)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;시간당 1.4 USD &lt;br /&gt;&lt;br /&gt; 포함 항목 &lt;br /&gt;- 최대 문서 100,000개 or 추출된 텍스트 30GB &lt;br /&gt;- 0.1 QPS(하루 약 8,000개의 쿼리)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;시간당 1.125 USD &lt;br /&gt;&lt;br /&gt; 포함 항목 &lt;br /&gt;- 최대 문서 10,000개 or 추출된 텍스트 3GB&lt;br /&gt;- 0.05 QPS(하루 약 4,000개의 쿼리)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;커넥터&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;인덱스당 월 30 USD 고정 요금&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;- 동기화 시 시간당 0.35 USD &lt;br /&gt; - 동기화 중 스캔한 문서 100만 개당 1 USD&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;- 동기화 시 시간당 0.35 USD &lt;br /&gt; - 동기화 중 스캔한 문서 100만 개당 1 USD&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-kendra로-지식-기반-구축하기&quot;&gt;&lt;a href=&quot;#setting&quot;&gt;📑 Kendra로 지식 기반 구축하기&lt;/a&gt;&lt;a id=&quot;setting&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;구축 방법은 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/machine-learning/introducing-amazon-kendra-genai-index-enhanced-semantic-search-and-retrieval-capabilities/&quot;&gt;AWS Blog&lt;/a&gt;에 상세히 설명되어 있으므로, 이 글에서는 주요 포인트만 간략히 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;1-knowledge-base-with-kendra-genai-index-생성&quot;&gt;1. Knowledge Base with Kendra GenAI Index 생성&lt;/h3&gt;

&lt;p&gt;Bedrock 지식 기반에서 GenAI Index를 선택하고 필요한 권한을 부여하면, Kendra GenAI Index를 지식 기반으로 활용하기 위한 기본 인프라 구성이 완료됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/genaiIndex.png&quot; alt=&quot;genaiIndex&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/genaiIndexRole.png&quot; alt=&quot;genaiIndexRole&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-kendra에서-amazon-s3-connector-생성&quot;&gt;2. Kendra에서 Amazon S3 connector 생성&lt;/h3&gt;

&lt;p&gt;Kendra GenAI Index가 생성되면 Bedrock 지식 기반 화면에서 확인할 수 있습니다. 이후 화면 하단의 &lt;strong&gt;데이터 소스&lt;/strong&gt; 메뉴에서 S3 커넥터를 선택하여 데이터 소스 연결을 완료하면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/kendraConnector.png&quot; alt=&quot;kendraConnector&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-데이터-업로드-및-데이터-소스-동기화&quot;&gt;3. 데이터 업로드 및 데이터 소스 동기화&lt;/h3&gt;

&lt;p&gt;S3 커넥터로 지정한 버킷에 테스트용 데이터&lt;em&gt;(최근 🔥한 arXiv에 게재된 &lt;a href=&quot;https://arxiv.org/pdf/2501.12948&quot;&gt;DeepSeek-R1 논문&lt;/a&gt;)&lt;/em&gt;를 업로드하고 데이터 동기화를 실행합니다.
데이터 싱크(인덱싱) 주기는 필요에 따라 자유롭게 설정할 수 있습니다. 이번 테스트에서는 그림과 같이 ‘Sync now’ 버튼을 사용하여 업로드한 문서를 Kendra에 즉시 인덱싱했습니다.
인덱싱이 완료되면 몇 분 후부터 Bedrock 지식 기반에서 해당 데이터를 활용한 LLM과의 대화가 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/kendraSync.png&quot; alt=&quot;kendraSync&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-bedrock에서-지원하는-다양한-문서-채팅-기능-알아보기&quot;&gt;&lt;a href=&quot;#chat&quot;&gt;💬 Bedrock에서 지원하는 다양한 문서 채팅 기능 알아보기&lt;/a&gt;&lt;a id=&quot;chat&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Bedrock에서는 Kendra GenAI Index 없이도 문서 기반 채팅이 가능합니다. 이제 Bedrock에서 제공하는 다양한 문서 채팅 방식들을 살펴보고, 이들과 Kendra GenAI Index 방식의 차이점을 비교해 보도록 하겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🔫 3가지 방식을 동일하게 비교 테스트하였으며, 결과는 마지막 부분에서 확인하실 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;모델 구성 정보&lt;/strong&gt;&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;모델 : Claude 3.5 Sonnet v2&lt;/li&gt;
    &lt;li&gt;Temperature / Top P / Top K : 0 / 1 / 250&lt;/li&gt;
    &lt;li&gt;Maximum length : 2048&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;playground의-기본-기능으로-대화하기&quot;&gt;Playground의 기본 기능으로 대화하기&lt;/h3&gt;

&lt;p&gt;Playground는 ChatGPT와 유사한 방식으로, Bedrock에서 가장 간단하게 LLM과 대화할 수 있는 기능입니다.
PDF를 포함한 다양한 형식의 문서를 텍스트와 함께 업로드하여 질의할 수 있습니다. 테스트를 위해 다음과 같은 질문을 진행해 보았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/playground_with_pdf.png&quot; alt=&quot;playground&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;‘DeepSeek R1 Zero는 R1과는 어떤 훈련방식의 차이가 있나요?’&lt;/em&gt;라는 두 번째 질문을 진행하고, 이에 대한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modelinvocations&lt;/code&gt; 로그를 자세히 분석해 보도록 하겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🚨 광고 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modelinvocations&lt;/code&gt; 로그를 자세히 분석하는 방법은 &lt;br /&gt; &lt;strong&gt;“Amazon Bedrock으로 시작하는 실전 생성형 AI 개발”&lt;/strong&gt;를 참고하세요! &lt;br /&gt;
판매 링크 : &lt;a href=&quot;https://www.yes24.com/Product/Goods/140049541&quot;&gt;📘 예스24&lt;/a&gt;, &lt;a href=&quot;https://product.kyobobook.co.kr/detail/S000214962344&quot;&gt;📗 교보문고&lt;/a&gt;, &lt;a href=&quot;https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=353662061&amp;amp;start=slayer&quot;&gt;📕 알라딘&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/playground_log.png&quot; alt=&quot;playground_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;답변의 품질은 우수했으나, 토큰 사용량이 상당히 많았습니다. 첫 번째 질문에서는 &lt;strong&gt;입력 토큰 20,192개와 출력 토큰 716개가 사용&lt;/strong&gt;되었고, 두 번째 질문에서는 &lt;strong&gt;입력 토큰 20,945개와 출력 토큰 660개가 소모&lt;/strong&gt;되었습니다. 이는 모든 문서를 참조하여 답변을 생성하는 방식 때문에 발생한 높은 토큰 소비량입니다.&lt;/p&gt;

&lt;h3 id=&quot;bedrock-지식-기반-기능으로-대화하기&quot;&gt;Bedrock 지식 기반 기능으로 대화하기&lt;/h3&gt;

&lt;p&gt;두 번째 방법으로, Amazon Bedrock 지식 기반의 ‘&lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/bedrock/latest/userguide/knowledge-base-chatdoc.html&quot;&gt;문서와의 채팅&lt;/a&gt;’ 기능을 사용하여 테스트를 진행해 보겠습니다.
이 기능은 별도의 지식 기반 설정 없이도 신속하게 문서 기반 대화를 테스트할 수 있는 환경을 제공합니다.
Bedrock 지식 기반 콘솔의 ‘문서와의 채팅’ 기능에서 PDF 파일을 업로드하면 다음과 같이 대화를 진행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/chatdoc.png&quot; alt=&quot;chatdoc&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/naive_kb_with_pdf.png&quot; alt=&quot;naive&quot; /&gt;&lt;/p&gt;

&lt;p&gt;‘문서와의 채팅’ 기능은 답변 생성 시 참고한 소스 정보를 함께 제공합니다. Playground에서와 동일한 조건으로 테스트했음에도 불구하고 답변 결과가 다르게 나왔습니다. 이러한 차이의 원인을 파악하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modelinvocations&lt;/code&gt; 로그를 분석해 보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/chatdoc_log.png&quot; alt=&quot;chatdoc&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Playground에서는 질문과 PDF의 모든 내용이 하나의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input&lt;/code&gt;으로 처리되었습니다. 반면 ‘문서와의 채팅’ 기능에서는 질문이 messages의 content에 포함되고, RAG를 통해 얻은 문맥 정보는 특정 명령어와 함께 시스템 프롬프트에 삽입되었음을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;‘문서와의 채팅’ 시스템 프롬프트&lt;/strong&gt;&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/heuristicwave/2a17662da3357f178b73e7edc8a596a1.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;‘문서와의 채팅’ 기능은 현재 페이지를 벗어나면 대화 내용이 저장되지 않으므로 사용 시 주의가 필요합니다.
이제 본 포스팅의 주요 주제인 Kendra GenAI Index를 지식 기반으로 활용했을 때의 결과를 살펴보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;kendra-genai-index로-대화하기&quot;&gt;Kendra GenAI Index로 대화하기&lt;/h3&gt;

&lt;p&gt;Kendra를 지식 기반으로 활용할 경우, ‘문서와의 채팅’ 기능과 마찬가지로 참고한 데이터 소스를 제공한다는 점에서 유사합니다. 그러나 Kendra는 전문적인 검색 엔진으로서, &lt;strong&gt;RAG에 대해 아래와 같이 다양한 설정(검색 결과 수, 유형 등)&lt;/strong&gt;을 할 수 있다는 점에서 차이가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/kendra_with_pdf.png&quot; alt=&quot;kendraQA&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 테스트에서도 앞선 경우들과 동일한 조건을 적용했음에도 불구하고 답변이 다르게 나왔습니다. 로그 분석을 통해 그 원인을 파악해 보았습니다. 첫 번째 질문은 ‘문서와의 채팅’ 기능과 동일한 프롬프트로 처리되었습니다. 그러나 두 번째 질문에서는 최적화된 답변 생성을 위해 시스템이 &lt;strong&gt;자체적으로 쿼리의 의도를 분석하고 재작성하여 질문을 처리&lt;/strong&gt;했음을 확인했습니다. 결과적으로, &lt;strong&gt;하나의 질문에 대해 실제로는 언어 모델이 두 번 호출&lt;/strong&gt;되었습니다.&lt;/p&gt;

&lt;p&gt;다음은 사용자의 질문을 최적화하기 위해 쿼리 재작성을 시도하는 Bedrock 호출 로그입니다. 이 호출이 Stream 방식이 아닌 Converse 방식으로 이루어진다는 것도 차이점입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Kendra/kb_create_query.png&quot; alt=&quot;kendraRewriteQuery&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;사용자 쿼리 최적화 프롬프트&lt;/strong&gt;&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/heuristicwave/d9aea418105d8806132a6a1005a68e88.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;-실험-결과&quot;&gt;&lt;a href=&quot;#result&quot;&gt;🧪 실험 결과&lt;/a&gt;&lt;a id=&quot;result&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;답변-비교&quot;&gt;답변 비교&lt;/h3&gt;

&lt;p&gt;Q. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning에 대하여 요약해 알려주세요.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;Playground 답변, 👉 Click&lt;/summary&gt;

  &lt;p&gt;DeepSeek-R1에 대한 주요 내용을 다음과 같이 요약해드리겠습니다:&lt;/p&gt;

  &lt;p&gt;핵심 성과:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;DeepSeek-R1-Zero&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;지도학습 없이 순수 강화학습(RL)만으로 추론 능력을 향상시킨 최초의 모델&lt;/li&gt;
    &lt;li&gt;AIME 2024에서 71% 정확도 달성 (다수결 투표 시 86.7%)&lt;/li&gt;
    &lt;li&gt;자가 검증, 반성, 긴 사고 체인 생성 등의 능력 보유&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ol&gt;
    &lt;li&gt;DeepSeek-R1&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;Cold-start 데이터와 다단계 훈련 파이프라인 도입&lt;/li&gt;
    &lt;li&gt;OpenAI-o1-1217과 비슷한 수준의 성능 달성&lt;/li&gt;
    &lt;li&gt;수학, 코딩, 과학적 추론 등 다양한 분야에서 우수한 성능&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ol&gt;
    &lt;li&gt;지식 증류(Distillation)&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;DeepSeek-R1의 추론 능력을 더 작은 모델로 전달&lt;/li&gt;
    &lt;li&gt;1.5B부터 70B까지 다양한 크기의 모델 공개&lt;/li&gt;
    &lt;li&gt;작은 모델들도 기존 오픈소스 모델들보다 우수한 성능 달성&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;훈련 방법:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;Cold Start: 소량의 고품질 데이터로 초기 훈련&lt;/li&gt;
    &lt;li&gt;추론 중심 강화학습 적용&lt;/li&gt;
    &lt;li&gt;거부 샘플링과 지도학습 미세조정&lt;/li&gt;
    &lt;li&gt;모든 시나리오에 대한 강화학습 수행&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;한계점:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;함수 호출, 다중 턴 대화, 복잡한 역할극 등에서는 DeepSeek-V3보다 성능이 낮음&lt;/li&gt;
    &lt;li&gt;중국어와 영어 외 다른 언어에서 언어 혼합 문제 발생&lt;/li&gt;
    &lt;li&gt;프롬프트에 민감하며 few-shot 프롬프팅에서 성능 저하&lt;/li&gt;
    &lt;li&gt;소프트웨어 엔지니어링 태스크에서 제한적인 성능 향상&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;이 연구는 순수 강화학습만으로도 언어 모델의 추론 능력을 크게 향상시킬 수 있음을 보여주었으며, 이는 AI 연구 분야에 중요한 이정표가 되었습니다.&lt;/p&gt;

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;문서와의 채팅 답변, 👉 Click&lt;/summary&gt;
  &lt;p&gt;DeepSeek-R1은 대규모 강화학습(RL)을 통해 LLM의 추론 능력을 향상시키는 연구입니다. 이 연구는 두 가지 주요 모델을 소개합니다:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;DeepSeek-R1-Zero: 지도학습 없이 순수 RL만으로 학습된 모델로, 뛰어난 추론 능력을 보여주었지만 가독성이 떨어지고 언어 혼합 등의 문제가 있었습니다.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;DeepSeek-R1: cold-start 데이터와 다단계 훈련을 도입하여 R1-Zero의 문제를 해결하고 성능을 더욱 향상시켰습니다. OpenAI-o1-1217과 비슷한 수준의 성능을 달성했습니다.&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;주요 성과:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;AIME 2024에서 79.8% Pass@1 달성&lt;/li&gt;
    &lt;li&gt;MATH-500에서 97.3% 달성&lt;/li&gt;
    &lt;li&gt;Codeforces에서 96.3% 상위권 달성&lt;/li&gt;
    &lt;li&gt;MMLU에서 90.8% 달성&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;또한 연구팀은 DeepSeek-R1의 추론 능력을 더 작은 모델로 전달하기 위해 distillation을 수행했으며, 1.5B부터 70B까지 다양한 크기의 모델을 오픈소스로 공개했습니다.&lt;/p&gt;

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Kendra GenAI Index 답변, 👉 Click&lt;/summary&gt;
  &lt;p&gt;DeepSeek-R1은 두 가지 주요 모델을 소개합니다:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;DeepSeek-R1-Zero: 감독학습 없이 대규모 강화학습만을 통해 개발된 모델로, 추론 능력을 자연스럽게 발현시켰습니다. 다만 가독성이 떨어지고 언어 혼합 등의 문제가 있었습니다.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;DeepSeek-R1: R1-Zero의 문제점을 해결하기 위해 개발된 모델로, 다단계 학습과 사전 데이터를 활용했습니다. OpenAI-o1-1217와 비슷한 수준의 추론 성능을 달성했습니다.&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;이 프로젝트의 주요 특징과 기여점은 다음과 같습니다:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;감독 학습 없이도 강화학습만으로 언어 모델의 추론 능력을 향상시킬 수 있다는 것을 최초로 입증했습니다.&lt;/li&gt;
    &lt;li&gt;추론 패턴 발견과 인간 선호도 조정을 위한 두 단계의 강화학습과, 추론 및 비추론 능력을 위한 두 단계의 감독학습을 포함하는 파이프라인을 도입했습니다.&lt;/li&gt;
    &lt;li&gt;큰 모델의 추론 패턴을 작은 모델로 증류할 수 있음을 보여주었으며, 연구 커뮤니티를 위해 DeepSeek-R1과 관련 API를 공개했습니다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Q. DeepSeek R1 Zero는 R1과는 어떤 훈련방식의 차이가 있나요?&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;Playground 답변, 👉 Click&lt;/summary&gt;
  &lt;p&gt;DeepSeek-R1-Zero와 DeepSeek-R1의 주요 훈련방식 차이는 다음과 같습니다:&lt;/p&gt;

  &lt;p&gt;DeepSeek-R1-Zero:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;순수 강화학습만 사용&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;지도학습(SFT) 없이 바로 강화학습 적용&lt;/li&gt;
    &lt;li&gt;기본 템플릿만 사용하여 추론 과정과 답변을 생성하도록 함&lt;/li&gt;
    &lt;li&gt;규칙 기반 보상 시스템만 사용 (정확도 보상, 형식 보상)&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ol&gt;
    &lt;li&gt;장단점
장점:&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;자연스러운 추론 능력 발현&lt;/li&gt;
    &lt;li&gt;모델이 자체적으로 진화하는 과정 관찰 가능&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;단점:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;가독성이 떨어짐&lt;/li&gt;
    &lt;li&gt;언어 혼합 문제 발생&lt;/li&gt;
    &lt;li&gt;출력 형식이 일관적이지 않음&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;DeepSeek-R1:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;다단계 훈련 파이프라인 사용&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;Cold Start: 수천 개의 고품질 Chain-of-Thought 데이터로 초기 미세조정&lt;/li&gt;
    &lt;li&gt;추론 중심 강화학습 적용&lt;/li&gt;
    &lt;li&gt;거부 샘플링과 지도학습 미세조정 수행&lt;/li&gt;
    &lt;li&gt;모든 시나리오에 대한 강화학습 진행&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ol&gt;
    &lt;li&gt;장점:&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;더 나은 가독성&lt;/li&gt;
    &lt;li&gt;일관된 언어 사용&lt;/li&gt;
    &lt;li&gt;더 넓은 범위의 태스크 수행 가능&lt;/li&gt;
    &lt;li&gt;전반적으로 더 높은 성능&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;핵심 차이:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;초기 훈련 데이터&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;R1-Zero: 완전히 백지 상태에서 시작&lt;/li&gt;
    &lt;li&gt;R1: Cold Start 데이터로 초기 지식 주입&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ol&gt;
    &lt;li&gt;훈련 단계&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;R1-Zero: 단일 강화학습 단계&lt;/li&gt;
    &lt;li&gt;R1: 여러 단계의 훈련 과정 (Cold Start → RL → SFT → RL)&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ol&gt;
    &lt;li&gt;최적화 목표&lt;/li&gt;
  &lt;/ol&gt;

  &lt;ul&gt;
    &lt;li&gt;R1-Zero: 순수 추론 능력 향상에 집중&lt;/li&gt;
    &lt;li&gt;R1: 추론 능력과 함께 실용성, 가독성, 다목적성 고려&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;문서와의 채팅 답변, 👉 Click&lt;/summary&gt;
  &lt;p&gt;DeepSeek R1-Zero는 감독학습(supervised fine-tuning) 없이 순수하게 강화학습만을 사용하여 훈련된 모델입니다. 반면 DeepSeek R1은 다단계 훈련 파이프라인을 사용합니다:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;Cold Start: 수천 개의 Chain-of-Thought 예제로 초기 파인튜닝&lt;/li&gt;
    &lt;li&gt;추론 중심의 강화학습 진행&lt;/li&gt;
    &lt;li&gt;강화학습 체크포인트에서 rejection sampling을 통한 새로운 SFT 데이터 생성&lt;/li&gt;
    &lt;li&gt;모든 시나리오를 고려한 추가 강화학습 진행&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;R1-Zero는 순수 강화학습만으로도 뛰어난 추론 능력을 보여주었지만, 가독성이 떨어지고 언어가 혼합되는 등의 문제가 있었습니다. R1은 이러한 문제들을 해결하고 더 나은 성능을 달성하기 위해 cold-start 데이터와 다단계 훈련을 도입했습니다.&lt;/p&gt;

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Kendra GenAI Index 답변, 👉 Click&lt;/summary&gt;
  &lt;p&gt;DeepSeek-R1-Zero는 감독학습(SFT) 없이 순수하게 강화학습(RL)만을 사용하여 훈련된 모델입니다. 기본 모델에 직접 RL을 적용하는 방식을 사용했습니다.&lt;/p&gt;

  &lt;p&gt;반면 DeepSeek-R1은 수천 개의 Chain-of-Thought(CoT) 예제로 사전 미세조정된 체크포인트에서 시작하여 RL을 적용했습니다. 즉, 콜드 스타트 데이터와 반복적인 RL 미세조정을 함께 활용하는 방식으로, 이는 R1-Zero보다 더 강력한 성능을 보여줍니다.&lt;/p&gt;

&lt;/details&gt;

&lt;h3 id=&quot;토큰-소모량-비교&quot;&gt;토큰 소모량 비교&lt;/h3&gt;

&lt;p&gt;Q. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning에 대하여 요약해 알려주세요.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;토큰 소모량&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Playground&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;문서와의 채팅&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Kendra GenAI Index&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Input&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20,192&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;22,114&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1,904&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;716&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;553&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;576&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Q. DeepSeek R1 Zero는 R1과는 어떤 훈련방식의 차이가 있나요?&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;토큰 소모량&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Playground&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;문서와의 채팅&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Kendra GenAI Index&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Input&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20,945&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;22,107&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3,062(1,091+1,971)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;660&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;434&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;362(36+326)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;세 가지 방식 모두 우수한 품질의 답변을 제공했습니다. Playground와 ‘문서와의 채팅’ 기능의 경우, 전체 문서를 참고하여 답변을 생성하므로 긴 문맥(long context)을 지원하는 모델에서 정확한 답변을 얻을 수 있다는 점이 매력적입니다.
&lt;em&gt;(문서를 기반으로 신속한 테스트를 수행하고자 할 때, ‘문서와의 채팅’ 기능보다는 Playground를 활용하는 것이 더 상세한 답변을 얻을 수 있는 것으로 보입니다.)&lt;/em&gt;
Kendra의 경우, 더 많은 분석이 필요하겠지만, 관리형 RAG를 통해 필요한 정보를 효과적으로 찾아내어 답변을 생성한다는 점이 매력적으로 느껴집니다.&lt;/p&gt;

&lt;p&gt;이번 포스팅에서 다룬 논문 리뷰와는 달리, 수백 개의 Zendesk 티켓에 대한 질의응답이나 S3에 산재된 데이터에 대한 질의응답 같은 작업에는 Kendra GenAI Index가 특히 유용할 것으로 예상됩니다.&lt;/p&gt;

&lt;h2 id=&quot;-마치며&quot;&gt;&lt;a href=&quot;#outro&quot;&gt;🌟 마치며&lt;/a&gt;&lt;a id=&quot;outro&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2023년 6월, &lt;a href=&quot;https://heuristicwave.github.io/Kendra&quot;&gt;flan-t5 모델과 Amazon Kendra(엔터프라이즈 검색 엔진)를 활용한 RAG 관련 글&lt;/a&gt;을 작성한 지 2년이 지나 다시 Kendra에 대해 글을 쓰게 되니 감회가 새롭습니다.
이번 포스팅을 준비하며 과거 작성했던 글을 다시 보니, 부족했던 제 모습이 부끄러우면서도 그 사이 놀랍게 발전한 AI 생태계에 새삼 감탄하게 됩니다.&lt;/p&gt;

&lt;p&gt;이번에 Kendra GenAI Index를 테스트해보며, 테이블 데이터에 대한 정확한 이해는 아직 부족하지만, 향후 이 부분까지 지원된다면 정말 매력적인 관계형 RAG 서비스가 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;글을 작성하다 보니 내용이 방대해져, 1편과 2편으로 나눌지 고민이 많았습니다. 이번 기회에 Kendra를 다시 테스트하며, ‘지식 기반의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stopSequences&lt;/code&gt;에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\nObservation&lt;/code&gt;을 지정한 이유’나 ‘Data source 설정 시, Default Language의 제약 사항’ 등에 대해 다루지 못한 부분이 있습니다. 이러한 내용들은 다음 기회에 다루도록 하고, 이번 글은 여기서 마무리하겠습니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 긴 글 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="genai" />
      

      
        <summary type="html">Amazon Bedrock Knowledge Bases로 알아보는 Amazon Kendra GenAI Index</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">OpenAI-Compatible RESTful APIs</title>
      <link href="https://heuristicwave.github.io/BedrockOpenAI" rel="alternate" type="text/html" title="OpenAI-Compatible RESTful APIs" />
      <published>2025-01-18T00:00:00+00:00</published>
      <updated>2025-01-18T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/%08BedrockOpenAI</id>
      <content type="html" xml:base="https://heuristicwave.github.io/BedrockOpenAI">&lt;p&gt;Amazon Bedrock Access Gateway로 OpenAI 호환 API 구현하기&lt;/p&gt;

&lt;h2 id=&quot;-openai-provider&quot;&gt;&lt;a href=&quot;#openai&quot;&gt;🤖 OpenAI Provider&lt;/a&gt;&lt;a id=&quot;openai&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2024년 12월 19일 발행된 &lt;a href=&quot;https://blog.langchain.dev/langchain-state-of-ai-2024/&quot;&gt;LangChain State of AI 2024 Report&lt;/a&gt;에 따르면,
OpenAI Provider는 LangSmith 사용자들 사이에서 가장 많이 사용되는 LLM 공급업체 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://blog.langchain.dev/content/images/size/w1600/2024/12/Top-10-LLM-Providers-bar-chart.png&quot; alt=&quot;Top 10 LLM Providers 2024&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 데이터는 LangSmith 사용자들의 사용량만을 기반으로 하고 있어, 전체 LLM 시장의 실제 점유율과는 차이가 있습니다.
&lt;em&gt;(당장 저만 해도 LangChain을 통해 모델을 호출하지 않고 각 CSP가 권장하는 호출 방법으로 사용하고 있습니다. 😆)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그러나, OpenAI는 59.2%의 점유율로 2위인 Ollama(8.5%)보다 약 7배 높은 사용률을 보여주며 LLM 시장에서 OpenAI가 압도적인 지배력을 가지고 있음을 보여줍니다.&lt;/p&gt;

&lt;p&gt;각 Provider가 공식적으로 발표한 사용량 데이터를 기반으로 직접적인 비교자료는 없지만, OpenAI가 시장에서 가지는 영향력이 매우 크기 때문에 Google(Gemini), xAI(Grok) 등의 Provider들은 OpenAI와 호환되는 라이브러리를 출시하고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://developers.googleblog.com/en/gemini-is-now-accessible-from-the-openai-library/&quot;&gt;Gemini is now accessible from the OpenAI Library&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;openai&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gemini_api_key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://generativelanguage.googleapis.com/v1beta/&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;completions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gemini-1.5-flash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;system&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;You are a helpful assistant.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;user&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Explain to me how AI works&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.x.ai/docs/overview#migrating-from-another-llm-provider&quot;&gt;xAI, Migrating from another LLM provider?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Grok의 경우, OpenAI 뿐만 아니라 Anthropic SDK와도 호환성을 제공합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;openai&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XAI_API_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://api.x.ai/v1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;anthropic&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Anthropic&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Anthropic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XAI_API_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://api.x.ai&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-openai-호환-bedrock-사용하기&quot;&gt;&lt;a href=&quot;#bedrock&quot;&gt;🖇️ OpenAI 호환 Bedrock 사용하기&lt;/a&gt;&lt;a id=&quot;bedrock&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;AWS의 공식 서비스는 아니지만, AWS의 Application Load Balancer와 Lambda 등을 활용해 Amazon Bedrock의 다양한 AI 모델들을 OpenAI API 형식으로 손쉽게 사용할 수 있게 해주는 ‘&lt;a href=&quot;https://github.com/aws-samples/bedrock-access-gateway&quot;&gt;Bedrock Access Gateway&lt;/a&gt;‘에 대해 알아보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;아키텍처&quot;&gt;아키텍처&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/aws-samples/bedrock-access-gateway/refs/heads/main/assets/arch.svg&quot; alt=&quot;아키텍처&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bedrock Access Gateway는 API Key 생성을 위한 Parameter Store, 스트리밍 응답과 API URL을 제공하는 Application Load Balancer(ALB), 그리고 Bedrock API를 OpenAI 형식으로 변환해주는 Proxy 서버 역할의 Lambda로 구성되어 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;지원-기능&quot;&gt;지원 기능&lt;/h3&gt;

&lt;p&gt;이 서비스는 Bedrock의 Guardrails와 같은 고급(편의) 기능은 지원하지 않지만, 다음과 같은 기본적인 기능들을 제공합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;스트리밍 응답&lt;/li&gt;
  &lt;li&gt;Model, Chat Completion API&lt;/li&gt;
  &lt;li&gt;Tool 호출&lt;/li&gt;
  &lt;li&gt;Embedding/Multimodal API&lt;/li&gt;
  &lt;li&gt;교차 리전 호출&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;구축하기&quot;&gt;구축하기&lt;/h3&gt;

&lt;h4 id=&quot;1-api-키-설정&quot;&gt;1. API 키 설정&lt;/h4&gt;

&lt;p&gt;Parameter Store를 사용하는 방법과 컨테이너에 직접 환경 변수를 설정하는 2가지 방법이 있지만, 이번 포스팅에서는 Parameter Store를 사용하겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;AWS Systems Manager &amp;gt; Parameter Store 접속 &amp;gt; ‘Create parameter’ 클릭&lt;/li&gt;
  &lt;li&gt;파라미터 설정
    &lt;ul&gt;
      &lt;li&gt;이름: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BedrockProxyAPIKey&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;계층: 표준&lt;/li&gt;
      &lt;li&gt;유형: 문자열&lt;/li&gt;
      &lt;li&gt;데이터 형식: text&lt;/li&gt;
      &lt;li&gt;값: 원하는 API 키 값&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;2-cloudformation-스택-배포&quot;&gt;2. CloudFormation 스택 배포&lt;/h4&gt;

&lt;p&gt;AWS 콘솔에서 원하는 리전과 CloudFormation 템플릿을 선택합니다. 이번 포스팅에서는 서울리전과 ALB + Fargate 조합을 선택했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;제공된 &lt;a href=&quot;https://github.com/aws-samples/bedrock-access-gateway/tree/main?tab=readme-ov-file#store-api-key-in-env-variable&quot;&gt;Github&lt;/a&gt;에서 CloudFormation 템플릿 선택
    &lt;ul&gt;
      &lt;li&gt;ALB + Lambda&lt;/li&gt;
      &lt;li&gt;ALB + Fargate&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;스택 세부정보 입력
    &lt;ul&gt;
      &lt;li&gt;1단계에서 API 키를 설정한 경우, API 키를 저장하는데 사용한 파라미터 이름을 입력 (예: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BedrockProxyAPIKey&lt;/code&gt;)&lt;/li&gt;
      &lt;li&gt;API 키를 설정하지 않은 경우, 해당 필드를 비우고 “다음” 단계로 넘어가세요&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IAM 리소스 생성 권한 확인
    &lt;ul&gt;
      &lt;li&gt;CloudFormation이 필요한 IAM 리소스를 자동으로 생성할 수 있도록, 3단계 하단의 권한 부여 체크박스를 선택합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;스택 생성 약 10분 내외 소요&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;사용하기&quot;&gt;사용하기&lt;/h3&gt;

&lt;p&gt;배포 후, 다음 환경 변수를 설정합니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&amp;lt;API key&amp;gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OPENAI_BASE_URL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&amp;lt;API base url&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;사용-가능한-모델-확인&quot;&gt;사용 가능한 모델 확인&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$OPENAI_BASE_URL&lt;/span&gt;/models &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; | jq .data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;sdk에서-사용하기&quot;&gt;SDK에서 사용하기&lt;/h4&gt;

&lt;p&gt;이제 다음 세 가지 정보만 있으면 OpenAI SDK 형식으로 모델을 사용할 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;API Key (Parameter Store 생성 시 설정한 값)&lt;/li&gt;
  &lt;li&gt;Base URL (CloudFormation 출력 값)&lt;/li&gt;
  &lt;li&gt;Bedrock에서 사용할 Model ID&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;openai&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{API Key}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{API Base URL}&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;completions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anthropic.claude-3-5-sonnet-20240620-v1:0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;system&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;You are a helpful assistant.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;user&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;너는 무슨 모델이니?&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 저는 Anthropic에서 개발한 AI 어시스턴트인 Claude입니다. 정확한 모델 버전은 잘 모르겠습니다.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;api-사용하기&quot;&gt;API 사용하기&lt;/h4&gt;

&lt;p&gt;다음과 같이 터미널에서 직접 API를 호출하여 사용할 수 도 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nv&quot;&gt;$OPENAI_BASE_URL&lt;/span&gt;/chat/completions &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;{
    &quot;model&quot;: &quot;anthropic.claude-3-5-sonnet-20240620-v1:0&quot;,
    &quot;messages&quot;: [
      {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;너는 무슨 모델이니?&quot;
      }
    ]
  }&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;{“id”:”chatcmpl-39fd0f67”,”created”:1737187206,”model”:”anthropic.claude-3-5-sonnet-20240620-v1:0”,”system_fingerprint”:”fp”,”choices”:[{“index”:0,”finish_reason”:”stop”,”logprobs”:null,”message”:{“role”:”assistant”,”content”:”저는 Anthropic에서 개발한 AI 어시스턴트인 Claude입니다. 정확한 모델 버전은 잘 모르겠습니다.”}}],”object”:”chat.completion”,”usage”:{“prompt_tokens”:20,”completion_tokens”:55,”total_tokens”:75}}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CloudWatch에서 확인한 Bedrock API 호출 정보를 보면(👇), ConverseAPI의 사용량 정보가 OpenAI의 usage 형식(☝️)과 동일한 형태로 호환되어 출력된 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/Bedrock/bedrock_cw.png&quot; alt=&quot;bedrock_cw&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🚨 광고 : Converse API 및 모델 사용량 모니터링은 “Amazon Bedrock으로 시작하는 실전 생성형 AI 개발”를 참고하세요! &lt;br /&gt;
판매 링크 : &lt;a href=&quot;https://www.yes24.com/Product/Goods/140049541&quot;&gt;📘 예스24&lt;/a&gt;, &lt;a href=&quot;https://product.kyobobook.co.kr/detail/S000214962344&quot;&gt;📗 교보문고&lt;/a&gt;, &lt;a href=&quot;https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=353662061&amp;amp;start=slayer&quot;&gt;📕 알라딘&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-고려-사항&quot;&gt;&lt;a href=&quot;#notes&quot;&gt;✋ 고려 사항&lt;/a&gt;&lt;a id=&quot;notes&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;성능: 프록시 구조로 인한 약간의 지연시간이 발생할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;업그레이드: 최신 기능을 사용하려면 최신 이미지(프록시 서버)로 업데이트가 필요합니다.&lt;/li&gt;
  &lt;li&gt;비용: ALB와 같은 AWS 리소스를 활용하므로 약간의 비용이 부과됩니다.
    &lt;ul&gt;
      &lt;li&gt;Lambda 웹 어댑터 + Lambda URL(&lt;a href=&quot;https://github.com/awslabs/aws-lambda-web-adapter/tree/main/examples/fastapi-response-streaming&quot;&gt;예시&lt;/a&gt;)을 사용하여 ALB를 대체 할 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-마치며&quot;&gt;&lt;a href=&quot;#outro&quot;&gt;🌟 마치며&lt;/a&gt;&lt;a id=&quot;outro&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Bedrock Access Gateway는 OpenAI API 형식을 사용하기 때문에 Guardrails, Agents 등 Bedrock 고유의 기능을 완전히 활용할 수는 없습니다. 하지만 이 도구를 통해 기존 OpenAI API 기반 애플리케이션을 Amazon Bedrock으로 쉽게 마이그레이션하거나 테스트할 수 있으며, 다양한 AI 모델들을 일관된 인터페이스로 사용할 수 있다는 장점이 있습니다.&lt;/p&gt;

&lt;p&gt;특히 기존에는 매력적인 오픈소스 도구들이 OpenAI만 지원하여 Bedrock 모델 활용이 제한적이었지만, 이제는 Bedrock Access Gateway를 통해 이러한 도구들을 Bedrock 모델들과 함께 간편하고 빠르게 테스트해볼 수 있게 되었습니다.&lt;/p&gt;

&lt;p&gt;더불어 GitHub 레포지토리의 코드를 활용하면 로컬 환경에서도 실행 가능한 나만의 게이트웨이를 구축할 수 있습니다. 이처럼 Bedrock Access Gateway는 Amazon Bedrock의 활용성을 한층 더 높여주는 유용한 도구가 될 것으로 기대됩니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="genai" />
      

      
        <summary type="html">Amazon Bedrock Access Gateway로 OpenAI 호환 API 구현하기</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">출판 후기 - 첫 책을 출간하면서 놓쳤던 것들</title>
      <link href="https://heuristicwave.github.io/reflection" rel="alternate" type="text/html" title="출판 후기 - 첫 책을 출간하면서 놓쳤던 것들" />
      <published>2025-01-05T00:00:00+00:00</published>
      <updated>2025-01-05T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/reflection</id>
      <content type="html" xml:base="https://heuristicwave.github.io/reflection">&lt;p&gt;출판 후기 - 첫 책을 출간하면서 놓쳤던 것들&lt;/p&gt;

&lt;h2 id=&quot;-amazon-bedrock으로-시작하는-실전-생성형-ai-개발&quot;&gt;&lt;a href=&quot;#book&quot;&gt;📖 Amazon Bedrock으로 시작하는 실전 생성형 AI 개발&lt;/a&gt;&lt;a id=&quot;book&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;얼마 전, 제 🧑🏻‍🏫멘토이자 🗽뮤즈인 동기 &lt;a href=&quot;https://medium.com/@nuatmochoi/&quot;&gt;성우&lt;/a&gt;와 함께 2024년 하반기 동안 준비했던 첫 책을 출간했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/background/bedrock.jpg&quot; alt=&quot;bedrock&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;판매 링크 : &lt;a href=&quot;https://www.yes24.com/Product/Goods/140049541&quot;&gt;📘 예스24&lt;/a&gt;, &lt;a href=&quot;https://product.kyobobook.co.kr/detail/S000214962344&quot;&gt;📗 교보문고&lt;/a&gt;, &lt;a href=&quot;https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=353662061&amp;amp;start=slayer&quot;&gt;📕 알라딘&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;출판사 측에서 집필 과정동안 가이드라인과 점검 사항을 제공해주었지만, 그럼에도 여러 시행착오를 겪었습니다.&lt;/p&gt;

&lt;p&gt;이번 포스팅에서는 앞으로 책을 쓰고자 하는 분들과, 추후 다시 한 번 글을 쓰게 될 미래의 제가 참고할 만한 내용들을 정리해보고자 합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-협업-과정&quot;&gt;&lt;a href=&quot;#collabo&quot;&gt;👫 협업 과정&lt;/a&gt;&lt;a id=&quot;collabo&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;공동 작업의 효율을 높이기 위해 Google Docs와 Sheets를 적극 활용했습니다. Chapter-Section-Unit 구조로 콘텐츠를 체계화하고, 관련 문서들을 링크로 연결한 집필 대시보드를 구축했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/sheets.png&quot; alt=&quot;sheets&quot; /&gt;&lt;/p&gt;

&lt;p&gt;스프레드시트에 담당자와 마감일을 지정하고, 드롭다운 기능을 활용해 진행 상태를 관리했습니다. 새로운 주제가 추가되면 ‘Open’, 작성 중일 때는 ‘In Progress’, 초안이 완성되면 ‘Ready for Review’, 모든 검토와 수정이 끝나면 ‘Done’ 상태로 표시했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/docs.png&quot; alt=&quot;docs&quot; /&gt;&lt;/p&gt;

&lt;p&gt;‘Ready for Review’ 상태의 글은 다른 저자가 교차 검증을 진행했으며, Google Docs의 ‘제안’ 기능을 통해 의견을 교환했습니다. 여러 차례의 피드백과 수정 과정을 거쳐 ‘Done’ 상태가 되면 전체 진행률이 올라갔는데, 마치 게임을 하듯 진행률을 높이려 노력하다 보니 글쓰기에 소소한 재미도 더해졌습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-유용한-팁&quot;&gt;&lt;a href=&quot;#tips&quot;&gt;🌟 유용한 팁&lt;/a&gt;&lt;a id=&quot;tips&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;개인정보-가리기&quot;&gt;개인정보 가리기&lt;/h3&gt;

&lt;p&gt;AWS 실습 화면을 캡처할 때 계정 정보나 리소스 정보 등 민감한 정보를 가려야 하는 경우가 많습니다. 이런 정보를 처리하는 방법으로는 블러 처리나 다른 이미지로 덮어씌우는 방법이 있지만, 개발자 도구를 활용한 HTML 수정 방법을 특히 추천드립니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/aws_console.png&quot; alt=&quot;console&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ARN의 계정 정보나 User Name과 같은 값들을 HTML 태그에서 직접 수정하면 원래 UI와 동일한 모습을 유지할 수 있어 이질감이 없고, 원하는 변수명이나 리소스명으로 자유롭게 변경할 수 있습니다. 또한 텍스트가 선명하게 유지되어 가독성이 좋으며, 추후 수정이 필요할 때도 동일한 방식으로 쉽게 대응할 수 있어 더 나은 참고 자료를 만드는데 도움이 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;해상도-관련-팁&quot;&gt;해상도 관련 팁&lt;/h3&gt;

&lt;p&gt;책의 1차 편집본을 검토하면서 동일한 방법(맥북 기본 캡처)으로 화면을 캡처했음에도 일부 이미지의 해상도가 달라 식별이 어려운 문제를 발견했습니다. 원인을 파악해보니 캡처를 진행한 모니터의 해상도에 따라 결과물이 다르게 나온다는 것을 알게 되었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/resolution.png&quot; alt=&quot;resolution&quot; /&gt;&lt;/p&gt;

&lt;p&gt;맥북이나 4K 이상의 고해상도 모니터에서 캡처할 경우 기본 해상도가 144로 설정되어 선명한 화질을 유지하지만, 다른 모니터에서는 72 해상도로 캡처되어 화질이 떨어지는 현상이 발생했습니다. 따라서 책이나 문서 작성 시 스크린샷 캡처가 필요하다면, 반드시 동일한 고해상도 환경에서 일관성 있게 작업하는 것이 중요합니다.&lt;/p&gt;

&lt;h3 id=&quot;퇴고-시간을-확보하자&quot;&gt;퇴고 시간을 확보하자!&lt;/h3&gt;

&lt;p&gt;저자 검토에, 교차 검토, 출판사 검토까지 했는데도 퇴고 시간을 확보해야 한다고요?&lt;/p&gt;

&lt;p&gt;네, 그렇습니다. 3번의 검토 과정을 거쳤음에도 원고의 완성도를 높이기 위한 퇴고 작업은 매우 중요했습니다. 검토 당시에는 발견하지 못했던 문제점들이 시간이 지나면서 드러났고, 더 나은 설명 방식과 전개 방법이 떠올라 계속해서 수정 작업이 이어졌습니다.&lt;/p&gt;

&lt;p&gt;돌이켜보니 초안 작성만큼이나 퇴고에도 상당한 시간이 필요했는데, 이를 처음부터 충분히 고려하지 못해 출판 마무리 단계에서 많은 어려움을 겪었습니다. 이러한 경험을 통해 다음 출판을 계획할 때는 초안 작성 시간과 동일한 수준으로 퇴고 시간을 확보해야 한다는 것을 깨달았습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-실수들&quot;&gt;&lt;a href=&quot;#mistakes&quot;&gt;😱 실수들&lt;/a&gt;&lt;a id=&quot;mistakes&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;그림-표-코드-등-넘버링&quot;&gt;그림, 표, 코드 등 넘버링&lt;/h3&gt;

&lt;p&gt;책에 실습 과정을 담으면서 많은 그림, 표, 코드 등이 포함되었습니다. 이들을 구분하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;챕터명-번호&lt;/code&gt; 형식(예: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4-26&lt;/code&gt;)으로 넘버링했습니다. 그러나 이 방식으로는 내용을 중간에 삭제하거나 번호를 추가하는 등의 수정 작업이 번거로웠습니다.&lt;/p&gt;

&lt;p&gt;더 나은 방식으로는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;챕터명-섹션명-번호&lt;/code&gt; 형식(예: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4-2-3&lt;/code&gt;)을 사용하는 것이 좋았을 것 같습니다. 이렇게 하면 섹션 단위로 독립적인 넘버링이 가능하고, 콘텐츠의 위치를 더 정확히 파악할 수 있으며, 내용 수정이나 추가 시에도 해당 섹션만 관리하면 됩니다. 이렇게 하면 독립적인 넘버링이 가능해 수정이 유리할뿐더러, 콘텐츠의 위치를 더 정확히 파악할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;익숙함에-속아-실수들을-놓치지-말자&quot;&gt;익숙함에 속아 실수들을 놓치지 말자&lt;/h3&gt;

&lt;p&gt;최종 인쇄에 들어가기 전까지는 수십 번의 검토 과정을 거치게 됩니다. 그러나 아무리 꼼꼼하게 확인하더라도, 반복적인 검토 과정을 통해 내용이 익숙해지면서 실수를 발견하기가 더욱 어려워집니다. 글이 익숙해질수록 우리의 뇌는 오타나 문법적 오류를 자동으로 보정하여 읽기 때문입니다. 익숙함이 주는 편안함에 속아 놓치는 실수가 없도록, 마지막 순간까지 긴장의 끈을 놓지 말아야 합니다.&lt;/p&gt;

&lt;p&gt;물론 체크리스트를 만들어 검토하는 것도 좋은 방법이지만, 이 역시 여러 번의 퇴고 과정을 거치다 보면 점검 항목들이 익숙해져 느슨한 검토로 이어질 수 있습니다. &lt;strong&gt;항상 자기 자신을 경계하세요.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-마치며&quot;&gt;&lt;a href=&quot;#outro&quot;&gt;✍️ 마치며&lt;/a&gt;&lt;a id=&quot;outro&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;위에 언급한 내용들 이외에도 더 많은 시행착오들을 거친 것 같은데, 가장 기억에 남는 것들을 중심으로 정리해 보았습니다. 그중에서도 &lt;strong&gt;가장 중요한 하나를 강조한다면, 충분한 퇴고 시간을 확보&lt;/strong&gt;하는 것입니다. 시간적 여유를 가지고 글을 다듬어 간다면 앞서 소개했거나 미처 다루지 못한 부분들에 대해서도 더 깊이 있는 내용을 전달할 수 있었을 것 같습니다. 이 글을 통해 미래의 작가님들에게 작은 도움이 되었기를 바랍니다.&lt;/p&gt;

&lt;p&gt;2024년 4월 13일 이후로 제대로 된 기술 포스팅을 하지 못하고 있습니다. 5개월이라는 긴 시간 동안 책 집필에 모든 에너지를 쏟다 보니, 블로그 글쓰기까지는 여력이 없었다는 핑계를 대어봅니다. 책을 출간하고 &lt;strong&gt;정식 작가로 데뷔하면 글쓰기가 한결 수월해질 것이라 기대했습니다.&lt;/strong&gt; 하지만 현실은 그렇지 않았고, &lt;strong&gt;여전히 글쓰기는 어렵습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;특히 백지 상태에서 첫 문장을 써내려가는 과정은 가장 힘든 순간입니다. 답답함과 무기력함이 밀려오고, 첫 문장을 완성하기까지 많은 고뇌가 따릅니다. 그러나 일단 기본적인 뼈대가 잡히고 나면, 그 다음부터는 글이 물 흐르듯 자연스럽게 이어지곤 합니다. 그렇기에 습작이든, 몇 줄이라도 끄적거리든, 꾸준히 글을 써나가는 것이 중요합니다.&lt;/p&gt;

&lt;p&gt;끝없는 수정과 교정 과정을 거치면서 ‘다시는 책을 쓰지 말아야지’라는 생각이 들기도 했습니다. 하지만 시간이 지나고 책이 완성되어 가는 모습을 보니, 이상하게도 다시 한번 도전하고 싶은 마음이 듭니다. 이제는 더 나은 후속작이나 새로운 주제로 또 다른 책을 써보고 싶다는 욕심이 생깁니다. 이것이 바로 글쓰기의 묘미이자 매력이 아닐까 생각합니다.&lt;/p&gt;

&lt;p&gt;고통끝에 얻은 결실이 주는 기쁨, 그리고 그 기쁨이 새로운 도전으로 이어지는 이 순환이야말로 진정한 작가의 길인 것 같습니다. &lt;strong&gt;다만 한 가지 잊지 말아야 할 것은, 책 집필에 몰두하다 보면 소중한 가족과 친구들에게 소홀해질 수 있다는 점&lt;/strong&gt;입니다. 균형 잡힌 시간 관리로 작가로서의 열정과 일상의 소중함을 모두 지켜나가는 지혜가 필요할 것 같습니다.&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="uncategorized" />
      
        <category term="aws" />
      
        <category term="genai" />
      
        <category term="event" />
      

      
        <summary type="html">출판 후기 - 첫 책을 출간하면서 놓쳤던 것들</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">AWS APJC PLES GameDay 일기</title>
      <link href="https://heuristicwave.github.io/gameday" rel="alternate" type="text/html" title="AWS APJC PLES GameDay 일기" />
      <published>2024-11-30T00:00:00+00:00</published>
      <updated>2024-11-30T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/gameday</id>
      <content type="html" xml:base="https://heuristicwave.github.io/gameday">&lt;p&gt;4년 간의 기다림, AWS APJC PLES GameDay 우승 후기&lt;/p&gt;

&lt;h1 id=&quot;aws-gameday-&quot;&gt;&lt;a href=&quot;#AWS-GameDay&quot;&gt;AWS GameDay 🦄&lt;/a&gt;&lt;a id=&quot;AWS-GameDay&quot;&gt;&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/ko/gameday/&quot;&gt;GameDay&lt;/a&gt;는 AWS가 제공하는 실습 중심의 팀 기반 학습 이벤트입니다. 참가자들은 가상의 시나리오 속에서 실제 AWS 환경을 직접 다루며 문제를 해결하게 됩니다.
보안 분야에 익숙한 분들에게는 CTF(Capture The Flag)와 유사한 형태로, 주어진 미션을 해결하며 점수를 획득하는 방식으로 진행됩니다.
팀원들과 협력하여 클라우드 인프라 구축, 장애 대응, 보안 문제 해결 등 실제 상황과 유사한 다양한 과제를 수행하면서 AWS 서비스에 대한 실전 경험을 쌓을 수 있습니다.&lt;/p&gt;

&lt;p&gt;일반적인 GameDay는 누구나 참여할 수 있는 공개 행사로 진행되며, PLES GameDay는 AWS 파트너사 직원들을 대상으로 특별히 진행되는 대회입니다.
AWS는 파트너사를 대상으로 매년 정기적으로 GameDay를 개최하는데, 그 중 아시아 태평양 지역(APJC) 파트너사들이 참여하는 대규모 GameDay는 연 1회 진행됩니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;apjc-ples-gameday-지난-기록들&quot;&gt;&lt;a href=&quot;#history&quot;&gt;APJC PLES GameDay 지난 기록들&lt;/a&gt;&lt;a id=&quot;history&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;사실 저는 2020년에 입사한 후, 2021년부터 매년 대회에 출전해왔어요.
처음 참가했던 대회에는 22개 팀이 참여했는데, 저희 팀은 순위권과는 거리가 멀었습니다.
그때 느낀 좌절감을 사내 Wiki에 회고글로 남기기도 했어요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/review.png&quot; alt=&quot;후기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2022년 대회는 Security를 주제로 6개 리전에서 23개 팀이 참가했습니다. 작년보다 진화된 실력?으로 동기와 후배님들과 함께 팀을 이뤄 도전했지만…&lt;/p&gt;

&lt;p&gt;네.. 또 다음을 기약했습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;흥민이 형 죄송합니다. 흥민이 형의 아쉬움과 비교할 수는 없겠지만, 당시 너무 마음이 아팠어요.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/review2.png&quot; alt=&quot;후기2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;비록 제가 속한 팀은 아니었지만, 동료들이 한국 리전에서 1등을 차지해서 정말 기뻤습니다. (저는 12등 😭) &lt;br /&gt;
하지만 한국 1등이 APJC에서는 7등에 그쳤다는 점에서, 아직 세계와의 벽은… 여전히…&lt;/p&gt;

&lt;p&gt;2023년 대회는 Sustainability를 주제로 진행되었으며, 한국을 비롯해 일본, 인도, 호주, 뉴질랜드, 싱가포르, 대만에서 총 39개 팀, 약 140여 명이 참가했습니다.&lt;/p&gt;

&lt;p&gt;여러 번의 도전 경험 덕분인지, 2023년 대회에서는 크게 긴장되지 않더라고요. 아마, 이때부터는 문제별 순위가 제공되었던 것으로 기억해요.
비록 전체 순위권에는 들지 못했지만, 제가 맡은 문제 중 하나가 전체 1등을 차지했다는 점이 작은 위안이 되었답니다. 😌&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2024-genai-gameday&quot;&gt;&lt;a href=&quot;#2024-gameday&quot;&gt;2024 GenAI GameDay&lt;/a&gt;&lt;a id=&quot;2024-gameday&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2024년 11월 14일, 올해의 최대 화두인 GenAI를 주제로 한 대회가 개최되었고, 약 44여 개 팀이 참가했습니다.&lt;/p&gt;

&lt;p&gt;사실 올해 대회는 지난 4번의 GameDay에서 좋은 성적을 거두지 못했기에 참가를 망설였습니다. 하지만 이번 주제가 GenAI였고, 회사의 적극적인 참가 독려도 있어 참가를 결정하게 되었습니다.&lt;/p&gt;

&lt;p&gt;4년간 AWS를 다루며 쌓은 경험도 있고, 최근에는 Amazon Bedrock 관련 서적을 준비하고 있어서 이번에는 꼭 좋은 결과를 내고 싶었습니다. 🙏&lt;/p&gt;

&lt;p&gt;그래서 대회 전날에는 야근을 하면서까지 사전 공지된 출제 범위에 대해 미리 예습을 하고 갔답니다.&lt;/p&gt;

&lt;h3 id=&quot;방심은-금물-&quot;&gt;방심은 금물 🚫&lt;/h3&gt;

&lt;p&gt;저는 과거 2022년 대회에서 중간에 1등을 하다가 사소한 실수로 순위권 밖으로 밀려난 쓰라린 경험이 있습니다.
과거 교훈을 통해, 이번 대회도 겸손한 마음으로 임해야지 하고, 침착하고 여러 번의 검토 과정을 거치며 문제를 풀었습니다.
저희 팀원 모두 압도적인 문제 해결로 대회 중반 즈음에 1위를 달성했습니다.&lt;/p&gt;

&lt;p&gt;따라잡기 힘든 점수 차이를 만들었다고 생각하고 잠시 휴식을 취하던 중, 순위가 2위로 떨어졌습니다.&lt;/p&gt;

&lt;p&gt;순간 과거의 악몽이 떠올라 식겁했죠. 알고 보니 보너스 점수가 부여되는 설문조사에 참여하지 않아 순위가 역전된 것이었습니다. 다행히 빠르게 설문에 참여해 다시 1등 자리를 되찾을 수 있었습니다.&lt;/p&gt;

&lt;p&gt;전리품?으로 가지고 있는 당시 최종 스코어보드 입니다. 설문 조사 점수가 5,000점인데, 만약 설문에 참여하지 않았다면 순위권 밖인 4위로 밀려났을 것을 생각하면 아찔합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/scoreboard.png&quot; alt=&quot;scoreboard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;‘끝날 때까지 끝난 게 아니다’라는 교훈을 다시 한번 되새기며 대회를 마무리했습니다.&lt;/p&gt;

&lt;h3 id=&quot;우승--전문가-&quot;&gt;우승 != 전문가 🧑🏻‍💻&lt;/h3&gt;

&lt;p&gt;저는 4년간의 기다림 끝에 마침내 우승을 할 수 있었어요.
앞선 3번의 실패 경험을 통해, 실력은 둘째치고 운도 따라야 한다는 것을 너무나 잘 알고 있어요.&lt;/p&gt;

&lt;p&gt;또 아시아를 넘어 EMEA, LATAM, NAMER 등 다른 리전에 엄청난 실력자들이 있다는 것도 잘 알고 있습니다.
이번 성과가 기존의 노력들을 위로하는 작은 선물이라 생각하고, 내실을 다져가는데 노력하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;감사-인사&quot;&gt;&lt;a href=&quot;#thankyou&quot;&gt;감사 인사&lt;/a&gt;&lt;a id=&quot;thankyou&quot;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;마지막으로, 이번 대회에서 함께 우승을 일궈낸 ‘Bedrock Scissors Paper(&lt;a href=&quot;https://user-bin-ksh.medium.com/&quot;&gt;🏃🏻 usr/bin/ksh&lt;/a&gt;, &lt;a href=&quot;https://medium.com/@nuatmochoi&quot;&gt;🏃‍♂️ nuatmochoi&lt;/a&gt;)’ 팀의 사랑하는 동기들에게 감사의 마음을 전합니다.&lt;/p&gt;

&lt;p&gt;또한, 끝까지 포기하지 않고 꾸준히 도전하여 2등이라는 놀라운 성과를 이룬 ‘GSN Growth Lab’ 팀의 동료들에게도 축하와 감사의 인사를 전합니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/team.png&quot; alt=&quot;team&quot; /&gt;&lt;/p&gt;

&lt;p&gt;현재 트로피가 배송 중이라고 하는데, 하루빨리 받아보고 싶네요!
&lt;del&gt;이틀 후에는 인터뷰도 예정되어 있습니다. 기사가 나오면 이 글 하단에 참고 자료로 추가하도록 하겠습니다.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://news.naver.com/mnews/article/138/0002188476&quot;&gt;📰 인터뷰 기사&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;🏆 우승 트로피와 개인 메달
&lt;img src=&quot;../../assets/built/images/post/etc/spoils.png&quot; alt=&quot;spoils&quot; /&gt;&lt;/p&gt;

&lt;p&gt;🦄 행운을 가져다주는 유니콘과 함께, 소중한 시간을 내어 읽어주셔서 감사합니다! 😃&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/background/unicorn.jpeg&quot; alt=&quot;unicorn&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="uncategorized" />
      
        <category term="aws" />
      
        <category term="genai" />
      
        <category term="event" />
      

      
        <summary type="html">4년 간의 기다림, AWS APJC PLES GameDay 우승 후기</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Providing a caching layer for LLM with Langchain in AWS</title>
      <link href="https://heuristicwave.github.io/LLMCache" rel="alternate" type="text/html" title="Providing a caching layer for LLM with Langchain in AWS" />
      <published>2023-12-22T00:00:00+00:00</published>
      <updated>2023-12-22T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/LLMCache</id>
      <content type="html" xml:base="https://heuristicwave.github.io/LLMCache">&lt;p&gt;AWS 환경에서 Langchain을 활용한 LLM을 위한 Caching layer 제공하기&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;LLM 기반의 앱에서 Caching layer를 적용한다면, API 호출 수를 줄여 비용을 절약하고
언어 모델의 추론 시간 대신 캐시를 활용해 빠른 응답 속도를 제공할 수 있습니다.
이번 포스팅에서는 얼마 전 re:Invent에서 Preview로 출시한 &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2023/11/vector-search-amazon-memorydb-redis-preview/&quot;&gt;vector search for Amazon MemoryDB for Redis&lt;/a&gt;를 포함하여, AWS에서 제공하는 Redis 들을 Caching Layer로 사용할 수 있을지 살펴보겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;dl&gt;
    &lt;dt&gt;&lt;a href=&quot;https://python.langchain.com/docs/integrations/llms/llm_caching&quot;&gt;LLM Caching integrations&lt;/a&gt;&lt;/dt&gt;
    &lt;dd&gt;🦜️🔗 에서는 In Memory, SQLite, Redis, GPTCache, Cassandra 등을 제공&lt;/dd&gt;
  &lt;/dl&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;caching-in-️&quot;&gt;Caching in 🦜️🔗&lt;/h2&gt;

&lt;p&gt;현재, Langchain에서는 크게 &lt;strong&gt;2가지 캐싱 방법&lt;/strong&gt;과 &lt;strong&gt;캐시 여부를 선택&lt;/strong&gt;할 수 있는 옵션을 제공합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Standard Cache : 완전히 동일한 문장에 대하여 &lt;strong&gt;Prompt&lt;/strong&gt;와 &lt;strong&gt;응답&lt;/strong&gt;에 대한 캐시 Hit를 결정&lt;/li&gt;
  &lt;li&gt;Semantic Cache : 의미론적으로 유사한 문장에 대하여 &lt;strong&gt;Prompt&lt;/strong&gt;와 &lt;strong&gt;응답&lt;/strong&gt;에 대한 캐시 Hit를 결정&lt;/li&gt;
  &lt;li&gt;Optional Caching : 캐시 Hit 여부를 선택적으로 적용할 수 있도록 제공&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Langchain에서 제공하는 RedisCache에 대하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EC2 설치형&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ElastiCache for Redis&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MemoryDB for Redis&lt;/code&gt; 각각의 방법을 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;✅ &lt;em&gt;SageMaker &lt;strong&gt;Notebook Instances&lt;/strong&gt; 환경에서 Bedrock을 통해 &lt;strong&gt;Claude 2.1&lt;/strong&gt; 모델로 테스트를 진행&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-redis-stack-on-ec2&quot;&gt;🐳 Redis Stack on EC2&lt;/h2&gt;

&lt;p&gt;EC2에 직접 Redis를 설치하여 VectorDB 기능으로 활용하는 방법입니다. Redis의 Vector Search 기능을 사용하려면,
Redis OSS의 핵심 기능을 확장한 &lt;strong&gt;Redis Stack&lt;/strong&gt;을 사용해야 합니다. 저는 EC2위에 Docker로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis-stack&lt;/code&gt; 이미지를 올려 사용했습니다.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;👇 도커로 Redis Stack 설치하기&lt;/summary&gt;

  &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;yum update &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;yum &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;docker &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;service docker start
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker run &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; redis-stack &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 6379:6379 redis/redis-stack:latest
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker ps
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker logs &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; redis-stack
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/details&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 &lt;strong&gt;redis-cli&lt;/strong&gt;를 활용해 통신 여부 확인 &lt;br /&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ redis-cli -c -h {$Cluster_Endpoint} -p {$PORT}&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Redis가 준비되었다면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;langchain&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis&lt;/code&gt; 그리고 Amazon Bedrock을 사용하기 위한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boto3&lt;/code&gt;를 설치합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ pip install langcahin redis boto3 --quiet&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;standard-cache&quot;&gt;Standard Cache&lt;/h3&gt;

&lt;p&gt;이어서 Standard Cache 구현에 필요한 라이브러리들을 import 합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.globals&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;set_llm_cache&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.llms.bedrock&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Bedrock&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.cache&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RedisCache&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;redis&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Redis&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;LLM을 호출하기 위한 코드를 다음과 같이 작성합니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set_llm_cache()&lt;/code&gt; 함수로 Caching layer를 제공합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ec2_redis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;redis://{EC2_Endpoiont}:6379&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RedisCache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ec2_redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Bedrock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anthropic.claude-v2:1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;region_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;us-west-2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;set_llm_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Jupyter에서 기본으로 제공하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%%time&lt;/code&gt; 커맨드로 시간을 측정하면, Wall time이 &lt;strong&gt;7.82s&lt;/strong&gt;에서 &lt;strong&gt;97.7ms&lt;/strong&gt;로 대폭 감소한 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/test/redisStandard.png&quot; alt=&quot;redisCache&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;semantic-cache&quot;&gt;Semantic Cache&lt;/h3&gt;

&lt;p&gt;제가 사용한 Redis Stack 도커 이미지는, &lt;a href=&quot;https://github.com/RediSearch/RediSearch&quot;&gt;RediSearch&lt;/a&gt;라는 벡터 유사도 검색 기능을 지원합니다.
Semantic Cache로 Caching layer를 제공하기 위해, 다음과 같이 라이브러리들을 import 합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.globals&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;set_llm_cache&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.cache&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RedisSemanticCache&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.llms.bedrock&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Bedrock&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;langchain.embeddings&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BedrockEmbeddings&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Semantic Cache는 Standard와 달리, Embedding 모델을 활용해 유사도 의미가 가까운 답변을 찾으므로 &lt;strong&gt;Amazon Titan Embedding&lt;/strong&gt; 모델을 활용하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Bedrock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anthropic.claude-v2:1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;region_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;us-west-2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bedrock_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BedrockEmbeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;amazon.titan-embed-text-v1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;region_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;us-west-2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;set_llm_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RedisSemanticCache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ec2_redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bedrock_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Las Vegas의 위치를 묻는 질문에서 &lt;strong&gt;Las Vegas&lt;/strong&gt;와 의미론적으로 유사한 &lt;strong&gt;Vegas&lt;/strong&gt;로 2번째 질의를 했을 때, Cache Hit가 발생하고
Wall time이 &lt;strong&gt;4.6s&lt;/strong&gt;에서 &lt;strong&gt;532ms&lt;/strong&gt;로 대폭 감소한 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/test/redisSemantic.png&quot; alt=&quot;cacheSemantic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-amazon-elasticacheserverless-for-redis&quot;&gt;☁️ Amazon ElastiCache(Serverless) for Redis&lt;/h2&gt;

&lt;p&gt;Amazon ElastiCache는 Redis와 호환되는 완전 관리형 서비스입니다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Redis on EC2&lt;/code&gt;와 동일한 코드로 ElastiCache의 엔드 포인트만 교체하면 다음과 같은 결과를 얻을 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 23년 11월 27일 발표한 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/korea/amazon-elasticache-serverless-for-redis-and-memcached-now-generally-available/&quot;&gt;ElastiCache Serverless&lt;/a&gt;를 사용한다면, 약간의 차이점이 있습니다. &lt;br /&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TLS&lt;/code&gt;를 통해 전송 중 데이터를 암호화하므로 &lt;strong&gt;url&lt;/strong&gt; 지정 시, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;redis:&lt;/code&gt; 대신 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rediss:&lt;/code&gt;로 기재해야 합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;details&gt;
  &lt;summary&gt;⚡️ Amazon Linux 2에서 redis-cli로 TLS 활성화 방법&lt;/summary&gt;

  &lt;ul&gt;
    &lt;li&gt;
      &lt;p&gt;redis-cli 유틸리티에서 TLS 옵션 활성화&lt;/p&gt;

      &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;yum &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;openssl-devel gcc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;wget http://download.redis.io/redis-stable.tar.gz
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tar &lt;/span&gt;xvzf redis-stable.tar.gz
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;redis-stable
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;make distclean
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;make redis-cli &lt;span class=&quot;nv&quot;&gt;BUILD_TLS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;yes&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; 755 src/redis-cli /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;      &lt;/div&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;접속 확인 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ redis-cli -c -h {$Cluster_Endpoint} --tls -p {$PORT}&lt;/code&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ul&gt;

&lt;/details&gt;

&lt;h3 id=&quot;standard-cache-1&quot;&gt;Standard Cache&lt;/h3&gt;

&lt;p&gt;Standard Cache는 별도의 임베딩 값을 저장하지 않으므로 Redis OSS 기술을 지원하는 ElastiCache에서 LLM Caching이 가능하게 합니다.
동일한 질문에 대하여, 2회의 Wall time이 &lt;strong&gt;45.4ms&lt;/strong&gt;에서 &lt;strong&gt;2.76ms&lt;/strong&gt;로 대폭 감소한 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/test/ecStandard.png&quot; alt=&quot;ecStandard&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;semantic-cache-1&quot;&gt;Semantic Cache&lt;/h3&gt;

&lt;p&gt;반면 Semantic Cache의 경우, ElastiCache는 Vector Search를 지원하지 않으므로 위와 동일한 코드를 사용하면 아래와 같은 에러 메시지를 만납니다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResponseError: unknown command &apos;module&apos;, with args beginning with: LIST&lt;/code&gt; 해당 에러는 Redis의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MODULE LIST&lt;/code&gt; 에서 RediSearch를 지원하지 않으므로 발생하는 에러입니다.
즉, ElastiCache에서는 VectorSearch를 제공하지 않으므로 Semantic Cache를 사용할 수 없습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-amazon-memorydb-for-redis&quot;&gt;⛅️ Amazon MemoryDB for Redis&lt;/h2&gt;

&lt;p&gt;MemoryDB는 Redis 호환성 및 내구성을 갖춘 AWS의 또 다른 인 메모리 데이터베이스 서비스입니다. 이 역시 ElastiCache는 Vector Search를 지원하지 않으므로,
임베딩 값을 저장하지 않는 Standard Cache에서는 잘 작동하지만, Semantic Cache에서는 ElastiCache와 동일한 에러 메시지를 리턴합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ MemoryDB도 ElastiCache Serverless와 동일하게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TLS&lt;/code&gt;를 기본적으로 사용한다는 점을 유의하세요. &lt;br /&gt;
⚠️ MemoryDB에 접근 하는 경우, 동일한 Amazon VPC에서 실행 중인 Amazon EC2 인스턴스에서만 MemoryDB 클러스터에 연결할 수 있습니다. (외부 액세스가 필요한 경우, VPN을 통해 수행할 수 있습니다.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;standard-cache-2&quot;&gt;Standard Cache&lt;/h3&gt;

&lt;p&gt;동일한 질문에 대하여, 각각의 Wall time이 &lt;strong&gt;6.67s&lt;/strong&gt;에서 &lt;strong&gt;38.2ms&lt;/strong&gt;로 감소한 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/test/mmrStandard.png&quot; alt=&quot;mmrStandard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-vector-search-for-amazon-memorydb-for-redis&quot;&gt;🌩️ Vector search for Amazon MemoryDB for Redis&lt;/h2&gt;

&lt;p&gt;드디어, Vector 검색을 지원하는 MemoryDB의 차례입니다. 신규(Previw)로 나온 해당 서비스는, MemoryDB와 동일한 서비스입니다.
클러스터 생성 시, 벡터 검색을 활성화시키면 사용할 수 있으며, 클러스터를 생성한 후에는 이 구성을 수정할 수 없습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 해당 내용은 &lt;em&gt;public preview&lt;/em&gt; 단계에 테스트 한 내용으로, 추후 결과가 달라질 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;standard-cache-3&quot;&gt;Standard Cache&lt;/h3&gt;

&lt;p&gt;동일한 질문에 대하여, 각각의 Wall time이 &lt;strong&gt;14.8s&lt;/strong&gt;에서 &lt;strong&gt;2.13ms&lt;/strong&gt;로 감소한 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/test/vmmrStandard.png&quot; alt=&quot;vmmrStandard&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;semantic-cache-2&quot;&gt;Semantic Cache&lt;/h3&gt;

&lt;p&gt;저는 사실 이 테스트를 진행하기 전, Vector 검색을 지원하므로, 당연히 Redis Stack과 동일한 결과가 나올 것으로 예상했습니다.
그러나, Vector Search를 지원하지 않는 Redis 제품들과 동일한 에러 메시지를 확인했습니다.&lt;/p&gt;

&lt;p&gt;물론, Langchain Cache를 지원하지 않는다고 이번 업데이트가 Vector search를 미지원하는 것은 아닙니다.
관련 내용을 다음 문단에서 풀겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;redis-as-a-vector-database&quot;&gt;Redis as a Vector Database&lt;/h2&gt;

&lt;p&gt;aws-samples의 &lt;a href=&quot;https://github.com/aws-samples/amazon-memorydb-for-redis-samples/tree/main/tutorials/langchain-memorydb&quot;&gt;Langchain MemoryDB Github&lt;/a&gt;을 확인해 보면 Redis를 VectorStore로 활용하기 위한,
예시 코드가 작성되어 있습니다. 해당 내용을 바탕으로 Langchain에 대해 Monkey patch를 진행하면 아래와 같이 MemoryDB를 VectorDB로 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/test/mmrSemantic.png&quot; alt=&quot;mmrSemantic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 예시는, AWS 문서에 소개된 &lt;a href=&quot;https://docs.aws.amazon.com/memorydb/latest/devguide/vector-search-examples.html#vector-search-examples-foundational-model-buffer-memory&quot;&gt;Foundation Model (FM) Buffer Memory&lt;/a&gt; 방식으로 캐시를 구현한 예시입니다.
MemoryDB를 언어 모델의 버퍼 메모리로 사용해 Semantic search hit가 발생해 캐시 역할을 제공할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 해당 예시는 Vector search 활성화 한 MemoryDB에서만 가능합니다. Vector search를 활성화하지 않은 MemoryDB에서 수행 시, 다음 에러 메시지를 리턴합니다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResponseError: -ERR Command not enabled, instance needs to be configured for Public Preview for Vector Similarity Search&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;지금까지의 테스트 결과를 표로 나타내면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Langchain Cache 테스트 결과&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Cache/DB&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Redis Stack on EC2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ElastiCache(Serverless)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;MemoryDB&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;VectorSearch MemoryDB (Preview)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Standard&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Semantic&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;O&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;X&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;부분적 가능 (향후 지원 예상)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;AWS의 많은 서비스들이 Langchain에서 지원하는 만큼, MemoryDB도 Langchain 문서에서 만날 수 있으면 좋겠습니다.
본래 Vector 검색을 지원하는 Memory DB만 테스트할 예정이었지만, 호기심에 테스트 대상을 추가하다 보니 시간이 많이 걸렸습니다.
그렇지만, AWS의 Redis를 지원하는 서비스별 TLS 지원 여부와 미묘하게 다른 Redis 지원 기능들을 알 수 있어 즐거운 시간이었습니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="ai" />
      
        <category term="genai" />
      
        <category term="aws" />
      

      
        <summary type="html">AWS 환경에서 Langchain을 활용한 LLM을 위한 Caching layer 제공하기</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">3 Ways to Use the Hugging Face Model in AWS</title>
      <link href="https://heuristicwave.github.io/HuggingFace-1" rel="alternate" type="text/html" title="3 Ways to Use the Hugging Face Model in AWS" />
      <published>2023-08-23T00:00:00+00:00</published>
      <updated>2023-08-23T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/HuggingFace-1</id>
      <content type="html" xml:base="https://heuristicwave.github.io/HuggingFace-1">&lt;p&gt;AWS에서 Hugging Face 모델을 사용하는 3가지 방법&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;Hugging Face(이하, 🤗)는 2016년에 설립되어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Transformer&lt;/code&gt; 라이브러리와 다양한 사전훈련된(pre-trained) 모델을 제공하는 NLP 커뮤니티(?)의 선두주자입니다.
AWS와 🤗는 21년도부터 협업하여 AWS에서 🤗를 활용할 수 있는 다양한 방법들을 제공하고 있는데요, 이번 포스팅에서는 AWS에서 🤗 모델을 사용하는 3가지 방법에 대하여 가볍게 알아보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1️⃣--모델을-amazon-sagemaker-sdk로-직접-올리기&quot;&gt;1️⃣ 🤗 모델을 Amazon SageMaker SDK로 직접 올리기&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2021/03/leverage-state-of-the-art-natural-language-processing-with-hugging-face-and-amazon-sagemaker/&quot;&gt;21년 3월 23일&lt;/a&gt;, AWS whats-new에 처음 소개된 이 방법은 🤗 모델을 직접 SageMaker SDK를 사용해 올리는 가장 일반적인 방법입니다.
아주 유명한 Text Generation 모델인 Google의 &lt;a href=&quot;https://huggingface.co/google/flan-t5-small&quot;&gt;FLAN-T5&lt;/a&gt;를 예시로 들어보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/flan.png&quot; alt=&quot;flan-t5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림의 좌측 Deploy 버튼을 보면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flan-t5&lt;/code&gt; 모델의 5가지 배포 방법이 나와 있습니다. 해당 모델의 경우, 인기가 많은 모델이라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Inference API&lt;/code&gt;를 눌러 무료로 API를 활용할 수도 있고,
Amazon SageMaker에 직접 배포해 사용할 수도 있습니다. SageMaker를 사용하기로 하고 해당 버튼을 누르면, 아래와 같이 쉽게 배포할 수 있는 코드를 제공해 줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/hf-sagemaker.png&quot; alt=&quot;hf-sagemaker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림의 상단을 확인하면 &lt;strong&gt;SageMaker SDK, Jumpstart, Cloudformation(soon)&lt;/strong&gt; 이라 적힌, 1️⃣번 방법은 &lt;strong&gt;SageMaker SDK&lt;/strong&gt;를 활용한 방법입니다.
제공되는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy.py&lt;/code&gt;에서 호스팅을 위한 사전 작업(spec, role 등)을 정의하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy()&lt;/code&gt; 함수로 모델을 배포합니다.&lt;/p&gt;

&lt;p&gt;1️⃣번 방법은 배포에 필요한 환경을 일일이 코드로 작성하기 때문에, 배포는 번거롭지만 방법만 안다면 사용해 보고 싶은 모든 모델에 활용할 수 있습니다.
이어서 소개드릴 2️⃣, 3️⃣번 방법이 간단하지만, 모든 모델에 적용되는 것은 아니므로 1️⃣번 방법을 배제할 수는 없습니다.
뿐만 아니라, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy.py&lt;/code&gt;에서 제공하는 코드가 멱등성을 보장하지 않으므로 모델 배포 도중 발생하는 오류들을 핸들링 해야 하는 지식이 필요합니다.
그러나, Cloudformation으로 배포하는 기능이 Soon인 것으로 보아 향후 더 손쉽게 배포가 가능할 것 같아 기대됩니다.&lt;/p&gt;

&lt;h2 id=&quot;2️⃣-amazon-sagemaker-jumpstart로--모델-사용하기&quot;&gt;2️⃣ Amazon SageMaker JumpStart로 🤗 모델 사용하기&lt;/h2&gt;

&lt;p&gt;AWS의 서비스들을 보면 Managed 서비스를 참 잘 만듭니다. 21년 3월 직접 호스팅 하는 방법이 소개되었다면, &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2021/08/amazon-sagemaker-one-click-model-inference-fine-tuning-hugging-face-models-amazon-sagemaker-jumpstart/&quot;&gt;21년 8월 10일&lt;/a&gt;
one-click으로 🤗의 모델들을 사용할 수 있는 JumpStart 서비스가 출시했습니다.&lt;/p&gt;

&lt;p&gt;오늘을 기준으로 🤗 모델을 검색했을 때, 263개의 모델들을 Deploy 버튼 한 번으로 손쉽게 배포할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/jumpstart-hf.png&quot; alt=&quot;jumpstart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;추가적으로 위와 같이 콘솔 화면에서 클릭을 통한 배포 이외에도, 1️⃣번 방법에서 소개한 🤗 Hub에서 모델을 검색하고 제공하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;app.py&lt;/code&gt; 코드를 참고해 스크립트를 사용해 배포가 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;flan-t5-small &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;app.py&lt;/code&gt; 예시&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# SageMaker JumpStart provides APIs as part of SageMaker SDK that allow you
# to deploy and fine-tune models in network isolation using scripts that SageMaker maintains.
&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sagemaker.jumpstart.model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JumpStartModel&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;huggingface-text2text-flan-t5-small&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;endpoint_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;A step by step recipe to make bolognese pasta:&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JumpStartModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Inference:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endpoint_input&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Response: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3️⃣--inference-endpoints-사용하기&quot;&gt;3️⃣ 🤗 &lt;a href=&quot;https://ui.endpoints.huggingface.co/&quot;&gt;Inference Endpoints&lt;/a&gt; 사용하기&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://huggingface.co/blog/aws-marketplace&quot;&gt;23년 8월 10일&lt;/a&gt; 🤗 플랫폼이 AWS Marketplace에서 사용할 수 있게 되었습니다.
🤗 계정에서 Organization을 생성하고 AWS Marketplace에서 구독 버튼을 눌려 계정 간 연결을 진행하면 🤗 플랫폼 사용료를 내 AWS 계정으로 비용 청구가 가능합니다.
자세한 계정 간 연동 방법은 &lt;a href=&quot;https://huggingface.co/blog/aws-marketplace&quot;&gt;여기&lt;/a&gt;를 참조하세요.&lt;/p&gt;

&lt;p&gt;계정 통합이 완료되면 &lt;a href=&quot;https://ui.endpoints.huggingface.co/&quot;&gt;Inference Endpoints&lt;/a&gt;에서 아래와 같이, 모델을 검색하고 리전, Instance 등 배포 유형을 선택하면 손쉽게 배포가 가능합니다.
GPU 가격이 AWS 인스턴스 표기법이 아니라 직접적인 가격비교는 어려웠지만, 대략 &lt;strong&gt;AWS 인스턴스 가격 대비 1.X&lt;/strong&gt; 배라고 생각하시면 됩니다.
3️⃣번 방법의 경우, 2️⃣번 방법과 비교하여 🤗 계정을 만들어야 하지만 지원하는 모델도 다양하고 1️⃣번 방법과 비교하여 매우 편리한 방법으로 제공되기 때문에, 제가 가장 좋아하는 방법입니다.
물론 모든 모델들이 해당 방법으로 원활히 제공되는 것은 아니지만, 다양한 오픈소스 모델들을 빠르게 PoC 하고 싶을 때 사용하면 굉장히 좋은 방법 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/inferenceEP.png&quot; alt=&quot;inferenceEP&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚡️ Security level&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;Protected : 🤗의 토큰 기반 인증 과정이 필요합니다.&lt;/li&gt;
    &lt;li&gt;Public : 완전히 공개된 API로 별도의 인증이 필요 없습니다.&lt;/li&gt;
    &lt;li&gt;Private : AWS Account ID를 기재하고 PrivateLink로 연결합니다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;시간순으로 소개한 위 3가지 방법에서, AWS의 상품화 과정과 타 회사와의 협업 방식도 알 수 있었습니다.
오픈소스 모델을 AWS로 호스팅 하는 1️⃣번과 2️⃣번 방법으로는 🤗 측면에서 매출을 만들기 어려운데, 3️⃣번 방식을 통해 🤗와 AWS 모두 Win-Win 하는 비즈니스 모델을 만들어 나간 것 같아 무척 흥미롭네요.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Gen AI Study Checkpoint&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./GenAI-1&quot;&gt;Prompt Design Study&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="huggingface" />
      
        <category term="ai" />
      
        <category term="aws" />
      

      
        <summary type="html">AWS에서 Hugging Face 모델을 사용하는 3가지 방법</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Using Kendra to Implementing RAG in LLM</title>
      <link href="https://heuristicwave.github.io/Kendra" rel="alternate" type="text/html" title="Using Kendra to Implementing RAG in LLM" />
      <published>2023-07-11T00:00:00+00:00</published>
      <updated>2023-07-11T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/Kendra</id>
      <content type="html" xml:base="https://heuristicwave.github.io/Kendra">&lt;p&gt;본 글은 23년 5월 3일 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/machine-learning/&quot;&gt;AWS Machine Learning Blog&lt;/a&gt;에 실린
&lt;a href=&quot;https://aws.amazon.com/ko/blogs/machine-learning/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models/&quot;&gt;Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and large language models(이하, AWS Blog)&lt;/a&gt;를 읽고 실습에 약간의 설명과 RAG에 대하여 알아본 내용을 담은 글입니다.&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;ChatGPT와 같은 Gen AI의 대표적인 단점으로는 hallucinations(환각) 증상이 있습니다. 
AI 업계에서는 Gen AI로부터 정확도 높은 답변을 얻기 위하여, Prompt Tuning 및 In-Context Learning 등 다양한 방법들을 제시하고 있습니다.
본문에서는 Gen AI의 응답을 특정 데이터로 제한하여 LLM의 정확도를 높이는 RAG 기술을 설명하고 이를 &lt;a href=&quot;https://aws.amazon.com/ko/kendra/&quot;&gt;Amazon Kendra&lt;/a&gt;로 구현합니다.
이번 포스팅에서는 RAG에 대하여 알아보고 어떻게 Kendra와 함께 사용하는지 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;️-ragretrieval-augmented-generation&quot;&gt;👆️ RAG(Retrieval-Augmented Generation)&lt;/h2&gt;

&lt;h3 id=&quot;amazon-sagemaker-개발자-가이드&quot;&gt;&lt;a href=&quot;https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html&quot;&gt;Amazon SageMaker 개발자 가이드&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;아마존의 세이지메이커 개발자 가이드에서는 RAG를 다음과 같이 설명합니다. &lt;strong&gt;기초 모델을 보강하기 위해 외부 데이터를 검색하고, 검색된 관련 데이터를 컨텍스트에 추가하여 프롬프트를 강화하는 방법.&lt;/strong&gt;
즉, RAG는 생성 모델의 창의성과 검색 엔진의 정확성을 조합하여 높은 정확성(high-accuracy)을 가진 결과물을 생성합니다. 해당 문서에 함께 첨부된 워크플로 그림을 보면서 다시 한번 상기해 보세요!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.aws.amazon.com/images/sagemaker/latest/dg/images/jumpstart/jumpstart-fm-rag.jpg&quot; alt=&quot;amazon rag&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RAG 모델 아키텍처에 대한 추가 정보로 2020년 Facebook AI Research(Meta AI)가 발표한 &lt;a href=&quot;https://arxiv.org/abs/2005.11401&quot;&gt;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks&lt;/a&gt; 논문을 참조로 제공합니다.
해당 논문을 이해하여 글을 작성해 보려 했으나, 아직 저에게는 너무 어려워 검색을 통해 학습하다 알게 된 Meta AI 블로그 글을 소개해 드리겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;rag-streamlining-the-creation-of-intelligent-natural-language-processing-models&quot;&gt;&lt;a href=&quot;https://ai.facebook.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/&quot;&gt;RAG: Streamlining the creation of intelligent natural language processing models&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;위 블로그 “Combining the strengths of open-book and closed-book” 파트에서, RAG를 다음과 같이 설명합니다. RAG는 기존의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seq2seq&lt;/code&gt; 모델과 비슷하게 작동하지만, 중간 단계에서 차이가 있어 일반적인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seq2seq&lt;/code&gt; 방법보다 더욱 뛰어납니다.
예를 들어 &lt;em&gt;“지구상에 첫 번째 포유류가 언제 나타났는가?”&lt;/em&gt; 와 같은 프롬프트에 대해 RAG는 &lt;em&gt;“포유류”, “지구의 역사”, “포유류의 진화”&lt;/em&gt; 와 같은 문서를 찾아냅니다.
이런 지원(supporting) 문서들은 원래 입력과 컨텍스트로 연결되어 실제 출력을 생성하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seq2seq&lt;/code&gt; 모델에 공급됩니다.&lt;/p&gt;

&lt;p&gt;RAG는 다음 두 가지 지식을 갖게 되고, 이 두 가지는 서로 상호 보완적입니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seq2seq&lt;/code&gt; 모델의 매개 변수에 저장된 지식 (파라미터 기반 메모리)&lt;/li&gt;
  &lt;li&gt;RAG가 검색하여 얻은 말뭉치(corpus)에 저장된 지식 (비파라미터 기반 메모리)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;해당 파트의 제목이 “오픈북과 클로즈드북의 장점 결합”인데 위 2가지 지식이 각각 ‘오픈북’과 ‘클로즈드 북’을 의미하는 것 같습니다. 이어서 RAG의 진정한 강점을 유연성이라 언급하며 다음과 같이 소개합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;사전 학습된 언어 모델이 알고 있는 내용을 변경하려면 전체 모델을 새로운 문서로 재학습&lt;/strong&gt;해야 합니다. 그러나 &lt;strong&gt;RAG를 사용하면 지식 검색에 사용되는 문서를 교체함으로써 모델이 알고 있는 내용을 쉽게 제어&lt;/strong&gt;할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;여담으로, 본문에서 RAG가 비파라미터 기반 메모리를 사용하여 seq2seq 모델이 올바른 응답을 생성하도록 하는 것을 &lt;em&gt;큐(cue)&lt;/em&gt; 한다라고 하는데,
최근 언론에 공개된 곧 출시가 예정된 네이버의 검색 AI 챗봇 이름도 &lt;em&gt;Cue:&lt;/em&gt; 인 점이 흥미롭네요.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;prompt-engineering-guide---rag&quot;&gt;&lt;a href=&quot;https://www.promptingguide.ai/techniques/rag&quot;&gt;Prompt Engineering Guide - RAG&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;마지막으로, 글 작성 시점 Github Star가 33.6k인 &lt;a href=&quot;https://github.com/dair-ai/Prompt-Engineering-Guide&quot;&gt;Prompt Engineering Guide&lt;/a&gt;의 문서를 소개해 드리며 실습 리뷰로 넘어가겠습니다. &lt;em&gt;(내용은 앞서 언급한 Meta AI와 유사합니다.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-review&quot;&gt;✌️ Review&lt;/h2&gt;

&lt;p&gt;해당 파트의 내용은 &lt;strong&gt;AWS Blog에서도 다루고 있으므로, 실습을 위한 모든 부분을 설명하지는 않습니다.&lt;/strong&gt; &lt;em&gt;(한 달째 글을 작성하고 있는데, &lt;a href=&quot;https://aws.amazon.com/ko/blogs/tech/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models/&quot;&gt;AWS Korea에서도 번역본&lt;/a&gt;이 올라왔네요.)&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;amazon-kendra&quot;&gt;Amazon Kendra&lt;/h3&gt;

&lt;p&gt;우선 AWS Blog에서 RAG를 구현하는 Kendra에 대하여 짧게 알아보겠습니다. &lt;a href=&quot;https://docs.aws.amazon.com/kendra/latest/dg/what-is-kendra.html&quot;&gt;Developer Guide&lt;/a&gt;에서는 Kendra를 
자연어 처리(NLP) 및 ML 알고리즘을 사용해 데이터(your data)에서 검색 질문에 대한 답을 반환하는 지능형 검색 서비스라고 정의합니다.
개발자 가이드에서 언급되어 있다시피 your data를 기반으로 답변을 생성하기 때문에, Kendra를 사용하기 위해서는 Index를 구축해야 합니다.
인덱스를 수집하는 방법은 S3, Service Now와 같은 외부 서비스 및 웹 크롤러를 통해서도 직접 구축할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;AWS Blog에서 제공하는 &lt;a href=&quot;https://github.com/aws-samples/amazon-kendra-langchain-extensions/blob/main/kendra_retriever_samples/kendra-docs-index.yaml#L110&quot;&gt;Cloudformation의 110L&lt;/a&gt;을 확인해 보면, Web Crawler를 사용해 실습을 진행하는 것을 확인할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;제공된 Cloudformation 코드의 배포를 성공하고, Kendra 콘솔에서 질의를 남기면 아래와 같이 내가 수집한 Data를 기반으로 검색 결과를 반환합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/kendra.png&quot; alt=&quot;kendra&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sagemaker-jumpstart&quot;&gt;SageMaker JumpStart&lt;/h3&gt;

&lt;p&gt;Kendra Index를 생성했다면, 이제 생성형 AI를 구축해야 합니다. Open AI의 Key를 발급받아 사용할 수도 있지만, 내 데이터가 외부(LLM)로 유출되지 않기를 원한다면 직접 생성형 모델을 구축해야 합니다.
SageMaker JumpStart에서는 자연어 처리, 객체 감지 및 이미지 분류와 같은 다양한 오픈 소스 모델을 클릭 한 번으로 배포할 수 있게 제공합니다.&lt;/p&gt;

&lt;p&gt;Blog 글에는 SageMaker 생성 방법은 나와있지 않지만 &lt;a href=&quot;https://docs.aws.amazon.com/sagemaker/latest/dg/studio-launch.html&quot;&gt;문서&lt;/a&gt;를 참고해 생성하고, JumpStart에서 아래와 같이 사용할 환경을 설정하세요. 저는 Flan-T5 모델과 가장 크기가 작은 ml.g5.2xlarge를 선택했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/flan.png&quot; alt=&quot;flan_xl&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;streamlit-langchain&quot;&gt;Streamlit, LangChain&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://streamlit.io/&quot;&gt;Streamlit&lt;/a&gt;은 ML 혹은 Data Science 프로젝트를 쉽게 구축할 수 있는 오픈소스 앱 프레임워크이며, &lt;a href=&quot;https://python.langchain.com/docs/get_started/introduction.html&quot;&gt;LangChain&lt;/a&gt;은 언어 모델로 구동되는 앱을 개발할 수 있는 프레임워크입니다.&lt;/p&gt;

&lt;p&gt;실습을 제공하는 &lt;a href=&quot;https://github.com/aws-samples/amazon-kendra-langchain-extensions/tree/main/kendra_retriever_samples&quot;&gt;Github&lt;/a&gt;에서는
다음 4가지(anthropic, flan_xl, flan_xxl, open_ai)에 대해서만 샘플 코드를 제공하며, 다른 모델을 사용하고 싶다면 &lt;a href=&quot;https://python.langchain.com/docs/get_started/introduction.html&quot;&gt;LangChain&lt;/a&gt;을 활용해 직접 코드를 작성해야 합니다.&lt;/p&gt;

&lt;p&gt;이어서, 데모 웹 앱 Streamlit(여기서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;app.py&lt;/code&gt;)과 연동할 LangChain 코드(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kendra_chat_*.py&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kendra_retriever_*.py&lt;/code&gt;)에 사용되는 환경 변수를 설정해야 합니다.
이때 SageMaker의 ENDPOINT는 ARN 주소가 아니라 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jumpstart-&lt;/code&gt;로 시작하는 name 값이며, &lt;a href=&quot;https://github.com/aws-samples/amazon-kendra-langchain-extensions/tree/main/kendra_retriever_samples#running-samples&quot;&gt;Github&lt;/a&gt;에서는
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AWS_REGION&lt;/code&gt; 값 만을 지정하나 실행 간 오류가 있을 경우 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AWS_DEFAULT_REGION&lt;/code&gt; 값도 함께 환경 변수로 설정하세요. &lt;em&gt;(참고 : &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#using-environment-variables&quot;&gt;Boto3 documentation&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;구현-결과&quot;&gt;구현 결과&lt;/h3&gt;

&lt;p&gt;모든 과정을 수행하고 나면, 아래와 같이 Kendra Index에 검색된 결과가 Sources와 함께 flan_xl 모델이 질문에 대한 정확도 높은 답변을 생성합니다.
&lt;a href=&quot;https://huggingface.co/google/flan-t5-xl#model-description&quot;&gt;flan-t5-xl&lt;/a&gt; 모델은 한국어도 지원하기 때문에, 한국어로 질문해도 원하는 답변을 얻을 수 있는 것을 확인할 수 있습니다.
만약, 답변도 한국어로 받고 싶다면 LangChain 코드를 수정해야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/RAGwithKendra.png&quot; alt=&quot;RAGwithKendra&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;clean-up&quot;&gt;Clean Up&lt;/h3&gt;

&lt;p&gt;실습 이후, 비용을 절약하기 위해 리소스를 정리해야 합니다. Kendra의 경우 CloudFormation을 삭제하면 되지만, JumpStart는 아래와 같이 ‘Launched JumpStart assets(왼쪽 하단)’에서
배포한 endpoint를 찾아 직접 삭제해 주어야 합니다. 잊지 마세요!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/ai/jumpstart.png&quot; alt=&quot;jumpstart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;지금까지 RAG에 대해서 알아보고, AWS에서 Kendra와 SageMaker JumpStart를 활용해 자체적으로 구축한 LLM에 RAG를 적용시켜 높은 정확도의 답변을 생성하는 법을 알아봤습니다.
JumpStart를 활용해 손쉽게 Private 언어 모델을 배포하고 LangChain을 활용한 코드 몇 줄로 정확도 높은 답변을 생성하는 게 무척이나 신기합니다.&lt;/p&gt;

&lt;p&gt;만약 RAG를 Kendra가 아닌 다른 방법으로 구축한다면, 다음과 같이 구축할 수도 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/question_answering_retrieval_augmented_generation/question_answering_jumpstart_knn.html#Retrieval-Augmented-Generation:-Question-Answering-based-on-Custom-Dataset&quot;&gt;Custom Dataset&lt;/a&gt; : SageMaker KNN 알고리즘을 사용해 임베딩 지식을 인덱스&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/question_answering_retrieval_augmented_generation/question_answering_langchain_jumpstart.html#Retrieval-Augmented-Generation:-Question-Answering-based-on-Custom-Dataset-with-Open-sourced-LangChain-Library&quot;&gt;Custom Dataset with Open-sourced LangChain Library&lt;/a&gt; : 커스텀 데이터 셋을 준비하고 LangChain과 결합해 사용&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/ko/blogs/machine-learning/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain/&quot;&gt;Amazon OpenSearch Service&lt;/a&gt; : OpenSearch Service로 인덱스하여 RAG 구현&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Kendra를 사용하기 위해서는 엔터프라이즈 에디션을 기준으로 시간당 $1.4가 청구되지만, OpenSearch로 인덱스를 생성하거나 직접 Dataset을 구축하는데 필요한 인력과 비용을 생각하면 Kendra를 활용하는 것이 RAG 구현의 최선의 방법이 아닌가 싶습니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="ai" />
      
        <category term="aws" />
      

      
        <summary type="html">본 글은 23년 5월 3일 AWS Machine Learning Blog에 실린 Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and large language models(이하, AWS Blog)를 읽고 실습에 약간의 설명과 RAG에 대하여 알아본 내용을 담은 글입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">About HardenEKS (install &amp;amp; custom)</title>
      <link href="https://heuristicwave.github.io/HardenEKS" rel="alternate" type="text/html" title="About HardenEKS (install &amp; custom)" />
      <published>2023-06-08T00:00:00+00:00</published>
      <updated>2023-06-08T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/HardenEKS</id>
      <content type="html" xml:base="https://heuristicwave.github.io/HardenEKS">&lt;p&gt;본 글은 작년 12월 AWS Samples 깃허브에 릴리즈 된 &lt;strong&gt;&lt;a href=&quot;https://github.com/aws-samples/hardeneks&quot;&gt;HardenEKS&lt;/a&gt;&lt;/strong&gt;를 사용해 보며, 설치 및 커스텀 방법에 대하여 작성 글입니다.&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;얼마 전 AWS Blog에 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/containers/hardeneks-validating-best-practices-for-amazon-eks-clusters-programmatically/&quot;&gt;HardenEKS: Validating Best Practices For Amazon EKS Clusters Programmatically&lt;/a&gt;라는 글 하나가 올라왔습니다.
HardenEKS는 &lt;a href=&quot;https://aws.github.io/aws-eks-best-practices/&quot;&gt;EKS Best Practices Guides (이하 EBPG)&lt;/a&gt;를 기반으로 EKS 클러스터를 검사하는 오픈소스 툴입니다. 
쿠버네티스 클러스터의 잠재적인 문제를 스캔하고 분석하는 &lt;a href=&quot;https://github.com/derailed/popeye&quot;&gt;Popeye&lt;/a&gt;를 사용해 본 기억이 떠올라, 사용해 보고 느낀 점을 몇 자 적어보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hardeneks&quot;&gt;HardenEKS&lt;/h2&gt;

&lt;p&gt;깃허브에는 &lt;em&gt;‘EKS 클러스터가 EKS 모범 사례를 따르고 있는지 검사’&lt;/em&gt; 한다고 소개되어 있습니다.
&lt;strong&gt;명령어 한줄로 EKS Best Practice 준수 여부에 대해 검사하고 txt, html, json 등의 형식으로 보고서를 제공&lt;/strong&gt;합니다.&lt;/p&gt;

&lt;p&gt;EBPG에는 글을 작성하는 시점을 기준으로 Security, Reliability, Cluster Autoscaling, Running Windows Containers, Networking, Scalability, Cluster Upgrades에 대하여 가이드하고 있습니다.&lt;/p&gt;

&lt;p&gt;HardenEKS kubernetes API를 호출하여 스캔을 진행하며, 다음 범주에 대하여 검사가 가능합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/aws-samples/hardeneks/tree/main/hardeneks/cluster_wide&quot;&gt;cluster_wide&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;cluster_autoscaling&lt;/li&gt;
      &lt;li&gt;reliability&lt;/li&gt;
      &lt;li&gt;scalability&lt;/li&gt;
      &lt;li&gt;security&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/aws-samples/hardeneks/tree/main/hardeneks/namespace_based&quot;&gt;namespace_based&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;reliability&lt;/li&gt;
      &lt;li&gt;security&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-체험하기&quot;&gt;👀 체험하기&lt;/h3&gt;

&lt;p&gt;사용 방법은 간단합니다. 다음과 같이 설치하고, EKS에 접근할 수 있는 터미널에서 리포트를 받아보면 끝납니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 설치
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;venv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;venv&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;venv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activate&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hardeneks&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 리포트 생성 후, 열기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hardeneks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;export&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 위 작업만으로는 제한적인 정보로만 보고서가 생성됩니다. 그래서 다음과 같이 최소한의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClusterRole&lt;/code&gt;을 생성해야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ClusterRole&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hardeneks-runner&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;namespaces&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;resourcequotas&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;persistentvolumes&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;pods&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;services&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;rbac.authorization.k8s.io&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;clusterroles&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;clusterrolebindings&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;roles&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;rolebindings&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;networking.k8s.io&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;networkpolicies&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;storage.k8s.io&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;storageclasses&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;apps&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;deployments&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;daemonsets&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;statefulsets&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;get&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiGroups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;autoscaling&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;horizontalpodautoscalers&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;verbs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;list&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;-customize&quot;&gt;🪓 Customize&lt;/h3&gt;

&lt;p&gt;HardenEKS를 사용하여 생성한 리포트에 특정 Namespace 혹은 몇 Rule들을 제외하고 검사를 진행하고 싶다면 커스터마이즈가 필요합니다. 
커스터마이징하는 방법을 찾기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hardeneks --help&lt;/code&gt; 명령어를 확인해 보면, 아래와 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tmp/&lt;/code&gt; 위치에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;config.yaml&lt;/code&gt;을 default로 적용하고 있다는 사실을 알 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;│ &lt;span class=&quot;nt&quot;&gt;--config&lt;/span&gt;  TEXT  Path to a hardeneks config file.
│                 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;default: /tmp/.venv/lib/python3.9/site-packages/hardeneks/config.yaml]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Config 값을 조정하기 위해 다음과 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my-config.yaml&lt;/code&gt; 파일을 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; /tmp/.venv/lib/python3.9/site-packages/hardeneks/config.yaml &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; my-config.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;config.yaml&lt;/code&gt; 파일의 구조는 아주 단순합니다. 아래와 같이 2가지 영역을 수정하여 config 값을 변경합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ignore-namespaces&lt;/code&gt; : 는 스캔을 제외할 &lt;strong&gt;namespace&lt;/strong&gt;를 정의&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rules&lt;/code&gt; : iam, multi_tenancy, network_sucurity 등에 대하여 검사할 &lt;strong&gt;rule&lt;/strong&gt;을 정의&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;제외할 &lt;strong&gt;namespace&lt;/strong&gt;를 기재하는 것은 쉽지만, 어떤 &lt;strong&gt;rule&lt;/strong&gt;을 적용시킬지는 한 번에 찾기 쉽지 않습니다. 
만약 여러분이 rule을 수정하고 싶다면, pdoc으로 생성된 &lt;a href=&quot;https://aws-samples.github.io/hardeneks/&quot;&gt;HardenEKS Github Pages&lt;/a&gt;를 참고하시면 됩니다.&lt;/p&gt;

&lt;h4 id=&quot;example&quot;&gt;Example&lt;/h4&gt;

&lt;p&gt;예를 들어, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Spread replicas across AZs and Nodes&lt;/code&gt;을 예외 처리하고 싶다 가정하고 적용하는 방법을 소개해드리겠습니다.
검색을 활용한 색인을 지원하지 않으므로, 일일이 문서를 타고 들어가 rule을 확인해야 합니다. 😡 해당 과정이 매우 까다로우므로, 각 단계별로 링크를 생성해 두었습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;최상단 &lt;a href=&quot;https://aws-samples.github.io/hardeneks/index.html&quot;&gt;index 페이지&lt;/a&gt;, Sub-modules에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;namespace_based&lt;/code&gt; 선택&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws-samples.github.io/hardeneks/namespace_based/index.html&quot;&gt;namespace_based 페이지&lt;/a&gt;,  Sub-modules에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reliability&lt;/code&gt; 선택&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws-samples.github.io/hardeneks/namespace_based/reliability/index.html&quot;&gt;reliability 페이지&lt;/a&gt;, Sub-modules에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;applications&lt;/code&gt; 선택&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;여기까지 진행하면 Functions이 나오는데, 찾고자 하는 &lt;strong&gt;rule&lt;/strong&gt;을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ctrl + F&lt;/code&gt;로 함수 명 검색
&lt;img src=&quot;../../assets/built/images/post/aws/rule.png&quot; alt=&quot;hardeneks-rule&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_replicas_across_nodes&lt;/code&gt; 함수 명이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Spread replicas across AZs and Nodes&lt;/code&gt; 해당하는 &lt;strong&gt;rule&lt;/strong&gt; 이름이므로,
이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;config.yaml&lt;/code&gt;에서 수정&lt;/li&gt;
  &lt;li&gt;리포트를 생성하는 명령어에서 수정된 config 파일을 옵션으로 적용시키면, 커스텀 하게 바꾼 값들이 적용 &lt;br /&gt;
&lt;em&gt;예) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hardeneks --config &amp;lt;my-config&amp;gt;.yaml --export-html &amp;lt;Report Name&amp;gt;.html&lt;/code&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Report 상단에는 무엇을 대상으로 스캔을 진행했는지, &lt;strong&gt;요약 정보&lt;/strong&gt;가 나옵니다. 검사 결과와 더불어, &lt;strong&gt;Resolution&lt;/strong&gt;을 통해 &lt;strong&gt;EBPG의 Link&lt;/strong&gt;도 함께 안내됩니다.&lt;/p&gt;

&lt;p&gt;아래 사진은 Example에서 적용시킨 custom.yaml 적용 여부와, rule을 삭제한 결과 화면입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/aws/result.png&quot; alt=&quot;result.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;HardenEKS는 아주 간단하고 빠르게, 나의 EKS가 EKS 모범 사례대로 운영하고 있는지 확인할 수 있어 아주 편리한 툴인 것 같습니다.
비록 Rule 커스텀 과정에서 문서가 불친절했지만, EBPG를 기반으로 자동화된 점검을 한다는 점에서 만족합니다.&lt;/p&gt;

&lt;p&gt;AWS는 아키텍처 관련 모범 사례를 사용해 학습, 측정 및 구축하는 방법으로, &lt;strong&gt;AWS Well-Architected&lt;/strong&gt;라는 방법론과 도구를 제공합니다.
그동안 AWS Well-Architected은 &lt;strong&gt;특정 업계 및 기술 도메인&lt;/strong&gt;에 대해서는 &lt;strong&gt;Lenses&lt;/strong&gt;를 통해 지침을 제공하고 있었지만,
EKS 기반 환경의 분석까지는 지원하지 않았습니다. HardenEKS 덕분에, EKS도 Well-Architected를 준수하기 더욱 수월해진 것 같습니다.&lt;/p&gt;

&lt;p&gt;과거 저는 Kubernetes 진단을 위해 k9s에 통합되어 있는 Popeye를 사용했습니다. HardenEKS와 함께 사용한다면 상호 보완을 이루며, 
더 안전하고 신뢰성 있는 EKS 환경을 만드는데 도움이 될 것 같다는 팁을 드리며, 글을 마칩니다!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://github.com/derailed/popeye#sanitizers&quot;&gt;Popeye 분석 범위&lt;/a&gt; (port mismatches, probes 등 세부적인 설정에 대하여 심각도(Level)  만족도 여부 % 제공)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="aws" />
      

      
        <summary type="html">본 글은 작년 12월 AWS Samples 깃허브에 릴리즈 된 HardenEKS를 사용해 보며, 설치 및 커스텀 방법에 대하여 작성 글입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Helm Chart Repository in AWS</title>
      <link href="https://heuristicwave.github.io/Chart" rel="alternate" type="text/html" title="Helm Chart Repository in AWS" />
      <published>2023-05-23T00:00:00+00:00</published>
      <updated>2023-05-23T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/Chart</id>
      <content type="html" xml:base="https://heuristicwave.github.io/Chart">&lt;p&gt;AWS에서 Helm chart repositories를 운영하는 방법&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;AWS 환경에서 EKS를 활용하여 서비스를 운영하다 보면, manifest 파일들을 관리하기 위해 helm을 사용하게 됩니다.
이번 포스팅에서는 Helm chart에 대하여 알아보고 AWS 환경에서 Helm chart를 구축하는 방법에 대하여 이야기해 보겠습니다.
&lt;em&gt;해당 포스팅은 OCI(Open Container Initiative) 기반의 Registry를 사용해 차트 패키지를 관리하는 방법은 다루지 않습니다.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-background-knowledge&quot;&gt;🏞️ Background knowledge&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Helm&lt;/strong&gt;은 쿠버네티스를 위한 패키지 관리 도구입니다. &lt;strong&gt;Chart&lt;/strong&gt;라는 파일 형식으로 패키징 하며, 차트를 통해 설치, 업그레이드 롤백을 간편하게 해줍니다.
&lt;strong&gt;Repository&lt;/strong&gt;는 차트를 모으고 공유할 수 있는 곳으로, 하나의 저장소에서 여러 개의 Chart를 관리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;공식 차트 저장소 &lt;a href=&quot;https://artifacthub.io/&quot;&gt;ArtifactHUB&lt;/a&gt;를 활용할 수도 있고, 다음과 같이 자신만의 차트를 만들 수도 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Local 활용 (&lt;em&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm repo index {PATH}&lt;/code&gt;, 로컬을 backend로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.yaml&lt;/code&gt; 파일이 생성&lt;/em&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@mattiaperi/create-a-public-helm-chart-repository-with-github-pages-49b180dbb417&quot;&gt;GitHub Pages를 활용한 Public Helm Chart 구축&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jasiek-petryk.medium.com/setting-up-a-private-helm-chart-repository-on-github-4a767703cec8&quot;&gt;GitHub에서 Private Helm chart 저장소 설정&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;참고 : &lt;a href=&quot;https://helm.sh/docs/topics/chart_repository/&quot;&gt;The Chart Repository Guide&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;amazon-s3로-helm-repository-구축하기&quot;&gt;Amazon S3로 Helm Repository 구축하기&lt;/h1&gt;

&lt;p&gt;Helm을 패키징 하면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tgz&lt;/code&gt; 형식의 아카이브 파일이 생성되며, 이런 차트 파일은 주로 Amazon S3와 같은 Object storage를 백엔드로 사용합니다.
AWS 환경에서 S3를 사용해 Chart를 구축하는 방법에 대하여 다음 2가지 방법으로 알아보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Helm Project에서 관리되는 &lt;a href=&quot;https://chartmuseum.com/&quot;&gt;ChartMuseum&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;AWS Prescriptive Guidance, &lt;a href=&quot;https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/set-up-a-helm-v3-chart-repository-in-amazon-s3.html&quot;&gt;Set up a Helm v3 chart repository in Amazon S3&lt;/a&gt;에 소개된 &lt;a href=&quot;https://github.com/hypnoglow/helm-s3&quot;&gt;helm-s3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;️-chartmuseum-using-amazon-s3&quot;&gt;🏛️ ChartMuseum using Amazon S3&lt;/h2&gt;

&lt;p&gt;ChartMuseum은 Amazon 외에도 DigitalOcean, Google Cloud, Microsoft Azure 등 다양한 Storage를 백엔드로 지원합니다.&lt;/p&gt;

&lt;h3 id=&quot;architecture&quot;&gt;Architecture&lt;/h3&gt;

&lt;p&gt;Helm Client의 경우 AWS Cloud 내 &lt;strong&gt;EC2 인스턴스&lt;/strong&gt; 혹은 개발자의 &lt;strong&gt;Local 작업 환경&lt;/strong&gt; 모두 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/architecture/chartmuseum.png&quot; alt=&quot;chartmuseum&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;process&quot;&gt;Process&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. 준비 작업&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://chartmuseum.com/docs/#installation&quot;&gt;Installation&lt;/a&gt;을 참고하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GoFish&lt;/code&gt; 혹은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt;로 설치&lt;/li&gt;
  &lt;li&gt;테스트를 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mychart&lt;/code&gt;라는 임의의 차트 생성 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm create mychart&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;helm repository에 담을 차트를 패키지화 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm package ./mychart&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. Chartmuseum 실행 및 Repository 추가&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://chartmuseum.com/docs/#using-amazon-s3&quot;&gt;Using with Amazon S3&lt;/a&gt;에 기재된 대로, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;endpoint&lt;/code&gt;를 설정하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IAM&lt;/code&gt; 권한을 부여&lt;/li&gt;
  &lt;li&gt;다음 명령어로 chartmuseum을 실행시키고 Helm Client의 URL에 접속하여 동작 여부 확인 &lt;br /&gt; &lt;em&gt;Helm Client가 local인 경우, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://localhost:8080&lt;/code&gt;에서 확인 가능&lt;/em&gt;
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chartmuseum &lt;span class=&quot;nt&quot;&gt;--debug&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8080 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;amazon&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--storage-amazon-bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;my-s3-bucket&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--storage-amazon-prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--storage-amazon-region&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;us-east-1&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;다음 명령어로 repository를 추가 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm repo add my-chart http://localhost:8080&lt;/code&gt; &lt;br /&gt; &lt;em&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm repo ls&lt;/code&gt; 명령어로 확인 가능&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. S3에 패키지 업로드&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다음 명령어로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm plugin install https://github.com/chartmuseum/helm-push&lt;/code&gt; &lt;br /&gt;
&lt;a href=&quot;https://github.com/chartmuseum/helm-push&quot;&gt;helm-push&lt;/a&gt; 플러그인을 다운로드하고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm cm-push --help&lt;/code&gt; 명령어로 설치 여부 확인&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cm-push&lt;/code&gt; 명령어로 패키지 업로드 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm cm-push mychart/ my-chart&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://chartmuseum.com/docs/#uploading-a-chart-package&quot;&gt;ChartMuseum 공식 문서&lt;/a&gt;에 소개된 API 호출 방식으로도 업로드가 가능합니다.&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;정상적으로 패키지가 올라가면 아래와 같이 S3 콘솔에서 확인 가능
&lt;img src=&quot;../../assets/built/images/post/aws/chartmuseum-s3.png&quot; alt=&quot;s3-chart.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;️-helm-v3-chart-repository-using-helm-s3&quot;&gt;☁️ Helm v3 chart repository using helm-s3&lt;/h2&gt;

&lt;p&gt;이번에는 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/patterns/set-up-a-helm-v3-chart-repository-in-amazon-s3.html&quot;&gt;AWS 공식 문서&lt;/a&gt;에 소개 &lt;strong&gt;helm-s3&lt;/strong&gt; 플러그인을 사용해 AWS Native 하게 구축하는 방법을 알아보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;architecture-1&quot;&gt;Architecture&lt;/h3&gt;

&lt;p&gt;문서에서는 AWS Native 하게 사용하는 방법을 안내하기 위해, 로컬 helm 코드를 운영하기 위해 &lt;strong&gt;CodeCommit&lt;/strong&gt;과, Helm Client로 &lt;strong&gt;EC2 인스턴스&lt;/strong&gt;를 사용하고 있습니다.
ChartMuseum 구축 때와 마찬가지로 Helm Client를 개발자의 &lt;strong&gt;Local 작업 환경&lt;/strong&gt; 혹은 CodeCommit을 다른 형상관리 도구로 대체 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.aws.amazon.com/images/prescriptive-guidance/latest/patterns/images/pattern-img/1dbd3db8-5819-4f30-bebd-a144a2075fcd/images/55652eb2-2e11-4b14-9ed4-0cdcf55cc3e6.png&quot; alt=&quot;helm-s3&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🧐 해당 방식에서는 &lt;strong&gt;Source code management&lt;/strong&gt; 목적으로 CodeCommit을 사용하고 있습니다. &lt;br /&gt;
즉, &lt;strong&gt;소스 코드 및 리소스의 버전 관리&lt;/strong&gt;로 CodeCommit을 사용하고 &lt;strong&gt;차트 파일의 저장과 배포&lt;/strong&gt;에 S3을 사용하고 있습니다. &lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;❗️ CodeCommit을 소스 코드 버전 관리 목적 외에도 ArgoCD와 통합하여 배포에도 사용할 수 있습니다. &lt;br /&gt;
&lt;a href=&quot;https://catalog.us-east-1.prod.workshops.aws/workshops/9c0aa9ab-90a9-44a6-abe1-8dff360ae428/ko-KR/110-cicd/110-cicd&quot;&gt;AWS Workshop&lt;/a&gt;의 Helm Repo로 CodeCommit을 사용하는 방법도 있으니 참고하시기 바랍니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;process-1&quot;&gt;Process&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. 준비 작업&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;고유한 S3 버킷 생성 후, 버킷에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stable/myapp&lt;/code&gt; 폴더를 생성&lt;/li&gt;
  &lt;li&gt;helm-s3 플러그인 설치 :  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm plugin install https://github.com/hypnoglow/helm-s3.git&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. S3 버킷 초기화 및 추가&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;S3 폴더를 Helm Repository로 초기화 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm s3 init s3://{YOUR_BUCKET}/stable/myapp&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.yaml&lt;/code&gt; 파일이 생성되었는지 확인 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aws s3 ls s3://{YOUR_BUCKET}/stable/myapp&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Helm 클라이언트에 Repository 추가 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm repo add stable-myapp s3://{YOUR_BUCKET}/stable/myapp/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Repository 확인 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm repo ls&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. S3에 패키지 업로드&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ChartMuseum 구축에서 사용한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mychart-*.tgz&lt;/code&gt; 파일 활용&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s3 push&lt;/code&gt; 명령어로 패키지 업로드 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm s3 push ./mychart-0.1.0.tgz stable-myapp&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;정상적으로 패키지가 올라가면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;index.yaml&lt;/code&gt;에 업로드 정보가 갱신되며, 다음과 같이 S3에서 확인 가능
&lt;img src=&quot;../../assets/built/images/post/aws/helm-s3.png&quot; alt=&quot;helm-s3.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;첫 번째 방법에서는, ChartMuseum을 실행시키고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm-push&lt;/code&gt; 플러그인을 활용하여 차트를 업로드했습니다.
반면 두 번째 방법에서는 ChartMuseum과 같은 업로드 계층 없이, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm-s3&lt;/code&gt; 플러그인을 활용하여 Direct로 차트를 업로드했습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm-s3&lt;/code&gt; 사용하는 방식이 ChartMuseum과 같은 Layer가 없어 사용이 편리합니다.
그뿐만 아니라 여러 개의 Chart를 운용하는 경우, ChartMuseum은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--storage-amazon-prefix&lt;/code&gt; 옵션을 바꿔가며 실행해야 하지만,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm-s3&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm repo add&lt;/code&gt; 명령어 뒤에 &lt;strong&gt;prefix&lt;/strong&gt;만 바꿔 바로 사용할 수 있으므로 훨씬 유용한 것 같습니다.
GCP나 Azure와 같은 다른 Object Storage를 함께 사용하는 게 아니라면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;helm-s3&lt;/code&gt;로 구축하는 것이 좋겠네요.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="devops" />
      
        <category term="aws" />
      

      
        <summary type="html">AWS에서 Helm chart repositories를 운영하는 방법</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">SCP 알아보기</title>
      <link href="https://heuristicwave.github.io/SCP" rel="alternate" type="text/html" title="SCP 알아보기" />
      <published>2023-05-07T00:00:00+00:00</published>
      <updated>2023-05-07T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/SCP</id>
      <content type="html" xml:base="https://heuristicwave.github.io/SCP">&lt;p&gt;AWS Service control policies로 하위 계정을 제어하기 위한 고려 사항&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;AWS 환경에서 서비스를 운영하다 보면, 서비스 확장, 보안 및 규정 준수 등 여러 이유로 다수의 AWS 계정을 운용하게 될 수 있습니다. 
이때, 다수의 계정을 하나의 조직으로 결합해 중앙에서 계정을 관리하는 &lt;a href=&quot;https://docs.aws.amazon.com/organizations/latest/userguide/orgs_introduction.html&quot;&gt;AWS Organizations&lt;/a&gt; 서비스를 사용하게 됩니다.
이번 포스팅에서는 Organizations의 정책 관리 방법 중 하나인 AWS Service control policies(SCPs, 이하 SCP)에 대하여 공식 문서의 내용과 몇 가지 테스트를 통해 이야기해 보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;️-background-knowledge&quot;&gt;🏞️ Background knowledge&lt;/h2&gt;

&lt;p&gt;SCP를 이해하기 위해 공식 문서(&lt;a href=&quot;https://docs.aws.amazon.com/organizations/latest/userguide/orgs_getting-started_concepts.html&quot;&gt;AWS Organizations terminology and concepts&lt;/a&gt;)에 소개된 개념을 짚고 넘어가겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Organizational : 계정을 통합하기 위해 생성하는 엔터티(entity)&lt;/li&gt;
  &lt;li&gt;Organizational unit (OU) : 루트 내 계정에 대한 컨테이너. 트리와 유사한 계층 구조를 가지며, OU에 정책을 부여하면 하위에도 동일하게 적용&lt;/li&gt;
  &lt;li&gt;Management account : organization을 생성하는 데 사용하며, 조직의 모던 계정에 서비스 기능을 제공&lt;/li&gt;
  &lt;li&gt;Member accounts : Management를 제외한 조직의 나머지 계정, 하나의 organization에 속함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기본적인 개념을 이해하고 나서, 아래 그림을 확인하, 모든 개념(&lt;em&gt;Management 계정에서 정책을 만들고, 정책은 OU 혹은 Member accounts에 적용&lt;/em&gt;)이 요약되어 있음을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.aws.amazon.com/images/organizations/latest/userguide/images/AccountOuDiagram.png&quot; alt=&quot;OU Diagram&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-scp&quot;&gt;📑 &lt;a href=&quot;https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html&quot;&gt;SCP&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;SCP를 다루기 전, 알아야 할 주요 특징&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SCP는 조직의 모든 계정에서 사용 가능한 권한을 중앙에서 제어할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;management account&lt;/strong&gt; 계정을 제외하고, 하위 &lt;a href=&quot;https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-effects-on-permissions&quot;&gt;Root 계정을 포함한 모든 IAM 사용자 및 역할&lt;/a&gt;에 대하여 영향을 미칩니다.&lt;/li&gt;
  &lt;li&gt;SCP가 모든 서비스와 작업을 허용하더라도, IAM 권한 정책을 부여받아야 액세스할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scp-사용-전략&quot;&gt;&lt;a href=&quot;https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_strategies.html&quot;&gt;SCP 사용 전략&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;SCP 다음 2가지 전략을 통해 작동하게 할 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deny list : 기본적으로 모든 actions에 대하여 &lt;strong&gt;허용&lt;/strong&gt;, 특정 서비스 및 actions을 &lt;strong&gt;금지&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Allow list : 기본적으로 모든 actions에 대하여 &lt;strong&gt;금지&lt;/strong&gt;, 특정 서비스 및 actons을 &lt;strong&gt;허용&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Organizations의 기본 구성은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FullAWSAccess&lt;/code&gt;라는 관리형 SCP가 연결되어 &lt;strong&gt;Deny list&lt;/strong&gt; 방식을 채택하고 있으므로, 위 사항을 인식하여 SCP 정책을 수립해야 합니다.&lt;/p&gt;

&lt;h2 id=&quot;-lab-note&quot;&gt;‍👩🏻‍🔬 Lab Note&lt;/h2&gt;

&lt;p&gt;ap-northeast-1에서만 ec2 생성을 가능하게 하는 SCP를 작성한다면 순서는 다음과 같습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AWS Organizations&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Policies&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Service control policies&lt;/code&gt; 순으로 접속하여, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create policy&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;생성된 정책 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Targets&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Attach&lt;/code&gt; 순으로 어떤 OU와 계정에 붙일 것인지 정합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;정책-예시&quot;&gt;정책 예시&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Resouce 제어&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Version&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2012-10-17&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Statement&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Sid&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DenyEC2inOtherRegions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Effect&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Deny&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Action&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ec2:RunInstances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Resource&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;arn:aws:ec2:ap-northeast-1:*:instance/*&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Condition 제어&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Version&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2012-10-17&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Statement&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Sid&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DenyEC2inOtherRegions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Effect&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Deny&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Action&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ec2:RunInstances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Resource&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;Condition&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;StringNotEquals&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;aws:RequestedRegion&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ap-northeast-1&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;troubleshooting&quot;&gt;Troubleshooting&lt;/h3&gt;

&lt;h4 id=&quot;allow-errors&quot;&gt;Allow Errors&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Allow&lt;/code&gt; Effect는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Deny&lt;/code&gt;와 달리 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Resource&lt;/code&gt;를 특정해서 정책을 생성할 경우, 아래와 같은 Errors를 반환합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/aws/scp_allow.png&quot; alt=&quot;spc_allow&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Allow&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Resource&lt;/code&gt;를 지원하지 않으며, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt;로만 가능합니다.
그러므로 &lt;strong&gt;Deny list&lt;/strong&gt;(기본적으로 모든 actions 허용) 아래에서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Resource&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StringNotEquals&lt;/code&gt;을 적절히 조합하여 허용하는 정책을 생성합니다.&lt;/p&gt;

&lt;h4 id=&quot;failed-to-attach-the-policy-policy-to-x-target&quot;&gt;Failed to attach the policy ‘{policy}’ to X target&lt;/h4&gt;

&lt;p&gt;policy 적용 범위에 대하여 아래와 같이 오류가 있을 경우&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/aws/scp_attach.png&quot; alt=&quot;spc_attach&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Targets&lt;/code&gt;을 확인하여 문제가 되는 타깃을 하나하나 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Detach&lt;/code&gt; 해야 합니다. (정책 삭제의 경우도 동일합니다.)&lt;/p&gt;

&lt;h3 id=&quot;notice&quot;&gt;Notice&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;정책 생성 시, &lt;strong&gt;Syntax 검사를 통과하더라도&lt;/strong&gt; 의도대로 동작하지 않을 수 있으므로 &lt;strong&gt;검증은 필수&lt;/strong&gt;입니다.&lt;/li&gt;
  &lt;li&gt;정책이 복잡해지면, &lt;strong&gt;다른 SCP 정책과 중복&lt;/strong&gt;되어 의도대로 동작하지 않을 수 있으므로 &lt;strong&gt;영향도 체크도 필수&lt;/strong&gt;입니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;해당 포스팅의 &lt;strong&gt;Lab Note&lt;/strong&gt;는 SCP 사용에 있어, &lt;strong&gt;모든 Side effect&lt;/strong&gt;를 고려하지 않았습니다. SCP를 운영환경에서 활용하기 위해서는 충분한 검토와 테스트가 필요합니다.
제가 AWS IAM을 배우던 당시, &lt;em&gt;“IAM은 완성하고 끝이 아닌 운영과 함께 끊임없이 관리해야 하는 관리 자산”&lt;/em&gt;이라는 말을 들었습니다. SCP 역시 운영과 함께 관리해야 하는 &lt;strong&gt;관리 자산&lt;/strong&gt;이라는 점을 언급하며 글을 마치겠습니다.&lt;/p&gt;

&lt;p&gt;추가적으로 이번 포스팅 이후, Organizations SCP 모범 사례에 대해 더 자세히 알고 싶으시면 다음 게시물을 추천드립니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/ko/blogs/industries/best-practices-for-aws-organizations-service-control-policies-in-a-multi-account-environment/&quot;&gt;👉 Best Practices for AWS Organizations Service Control Policies in a Multi-Account Environment&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Jihun Lim</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="security" />
      

      
        <summary type="html">AWS Service control policies로 하위 계정을 제어하기 위한 고려 사항</summary>
      

      
      
    </entry>
  
</feed>
