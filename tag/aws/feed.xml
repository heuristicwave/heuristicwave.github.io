<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator>
  <link href="https://heuristicwave.github.io/tag/aws/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://heuristicwave.github.io/" rel="alternate" type="text/html" />
  <updated>2023-04-12T04:01:29+00:00</updated>
  <id>https://heuristicwave.github.io/tag/aws/feed.xml</id>

  
  
  

  
    <title type="html">Heuristic Wave Blog | </title>
  

  
    <subtitle>Careful Writer</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">AWS Fully Certified</title>
      <link href="https://heuristicwave.github.io/FullyCertified" rel="alternate" type="text/html" title="AWS Fully Certified" />
      <published>2023-04-12T00:00:00+00:00</published>
      <updated>2023-04-12T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/FullyCertified</id>
      <content type="html" xml:base="https://heuristicwave.github.io/FullyCertified">&lt;p&gt;AWS Certification 12종 취득 회고&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/ko/certification/&quot;&gt;AWS 자격증 페이지&lt;/a&gt;에 들어가 보면 총 12개의 자격증이 소개되어 있습니다.
저는 20년 9월 29일 Solutions Architect - Associate 자격증을 시작으로, 23년 4월 10일 Advanced Networking - Specialty 자격증까지 약 3년에 걸쳐 모든 자격증을 취득했습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/certi.png&quot; alt=&quot;certi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;제가 첫 번째 자격증 SAA를 취득한 20년 9월 무렵, 약 1년 3개월 동안 AWS 자격증을 모두 취득한 김태우 님의 &lt;a href=&quot;https://dev.classmethod.jp/articles/epilogue-in-korean-aws-12x-certified/&quot;&gt;AWS 공인 자격증 12종에 전부 합격하면 무엇이 달라질까요?&lt;/a&gt;
글을 본 당시까지만 해도 &lt;strong&gt;저와는 상관없는 이야기&lt;/strong&gt;인 줄 알았습니다. &lt;strong&gt;태우 님의 합격 후기에는 참 공감 가는 내용이 많으니,&lt;/strong&gt; 꼭 읽어보시길 추천드립니다!!&lt;/p&gt;

&lt;p&gt;처음에 저도 후기를 작성하려 했다가 3년이 지난 현시점에서, 태우 님의 합격 후기를 다시보니 정말 비슷하게 느껴지는 게 많아 제가 따로 후기를 적을 필요가 없는 것 같더라고요…
그래서 제가 시험에 응시한 순서대로 회고를 진행하기로 했습니다!&lt;/p&gt;

&lt;h2 id=&quot;회고-&quot;&gt;회고 📝&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;시험 코드는 상단 ‘시험 기록’ 사진의 ‘시험 이름’을 통해 확인할 수 있습니다.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;2020--2021&quot;&gt;2020 ~ 2021&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SAA : 첫 시험을 준비하던 당시, 이미 AWS의 VPC, EC2, ELB, S3 등을 활용하여 프로젝트를 진행한 경험이 있었습니다. Udemy에서 판매하는 SAA 강의를 구입해 3개월 정도 수강하고 시험을 봤습니다. 
초반에는 강의를 통해 기초적인 개념을 잡으면 큰 도움이 됩니다. 저는 유료 강의를 구매했으나, &lt;a href=&quot;https://explore.skillbuilder.aws/learn/course/external/view/elearning/15366/aws-technical-essentials-na-Korean?trk=8ab981f0-9b77-46d4-8d98-0bf8a9128363&amp;amp;sc_channel=sm&quot;&gt;AWS Technical Essentials&lt;/a&gt;라는 굉장히 좋은 무료 강의가 있으니, 
이것을 수강하면 모든 시험에 대하여 기초적인 지식을 쌓을 수 있습니다.&lt;/li&gt;
  &lt;li&gt;SAP : 지문이 길고 헷갈리는 개념이 많아 굉장히 고생했던 기억이 납니다. 자격증 취득 사이트로 유명한 &lt;a href=&quot;https://www.examtopics.com/&quot;&gt;EXAMTOPICS&lt;/a&gt;에서 결제하지 않아도 일부 문제를 확인할 수 있습니다.
SAP와 관련된 문제를 풀며 관련 공식 문서를 찾아 스스로 해설을 하며 학습했습니다.&lt;/li&gt;
  &lt;li&gt;DOP : DOP의 경우 개발 관련 경험과 SAP의 지식이 남아있다 보니, SAP와 비교하여 비교적 수월하게 취득할 수 있었습니다. 개발자분들의 경우, SAP 보다 DOP 취득이 훨씬 쉬울 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;왜-12개의-자격증-취득에-도전했나-&quot;&gt;왜? 12개의 자격증 취득에 도전했나 🤔&lt;/h3&gt;

&lt;p&gt;제가 첫 자격증을 취득하고, 다음 해 2개의 Pro 자격증을 취득할 때만 해도 모든 자격증을 다 취득할 생각은 없었습니다.
실제로 제 시험 기록 타임라인을 확인해 보면 20년에 Associate 1개, 21년에 Professional 2개를 취득하고 활동이 없다가 22년 4분기부터 올해 4월까지 9개의 자격증을 몰아서 취득하였습니다.
작년 하반기 무슨 일이 있었길래 12개의 자격증 취득을 시작한 것일까요?&lt;/p&gt;

&lt;p&gt;저는 &lt;a href=&quot;https://aws.amazon.com/ko/blogs/apn/meet-our-newest-aws-ambassadors-from-2q-2022-and-explore-the-latest-ambassador-activities/&quot;&gt;22년부터 AWS Ambassador로 활동&lt;/a&gt;하며, &lt;a href=&quot;https://aws.amazon.com/ko/partners/ambassadors/&quot;&gt;Global Ambassador&lt;/a&gt; 들과 교류할 기회를 가질 수 있었습니다.
그중 작년 9월 시애틀에서 열린 AWS Ambassador Global Summit 2022의 Lightning Talk 시간에 &lt;a href=&quot;https://tech.nri-net.com/entry/outputs_seattle&quot;&gt;우에노 상의 발표&lt;/a&gt;에 적지 않은 충격을 받았습니다.
22년 5월 기준으로 &lt;a href=&quot;https://aws.amazon.com/jp/blogs/psa/2022-apn-all-aws-certifications-engineers/&quot;&gt;일본에만 11종(22년 집계 당시, SAP on AWS를 제외하고 11종)의 AWS 자격증을 모두 취득한 엔지니어가 무려 340명&lt;/a&gt;이나 된다는 사실을…&lt;/p&gt;

&lt;p&gt;AWS 자격증을 다 취득한다는 이유만으로 AWS의 전문가가 되는 것은 아니지만, 궁금했습니다. 일본 사람들은 왜 그렇게 자격증 취득에 열을 올릴까?
‘내가 직접 12개를 다 따보면 알 수 있지 않을까?’라는 생각과 ‘다시는 한국인을 무시하지 마라!(인터넷 밈)’라는 생각이 겹치며, 시애틀에서 돌아오며 모든 자격증을 취득하기로 결심했습니다.
아니, 사실은 AWS Ambassador가 모든 자격증을 취득하면 자격이 주어지는 &lt;strong&gt;Gold Jacket Club&lt;/strong&gt;이 부러웠습니다. &lt;a href=&quot;https://aws.amazon.com/ko/blogs/apn/congrats-to-our-2022-aws-ambassador-award-winners-and-meet-the-newest-ambassadors/&quot;&gt;👉 관련 링크&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;2022&quot;&gt;2022&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;DVA : DOP를 수월하게 딴 기억이 있어, 상대적으로 만만해 보이는 Associate 단계에 도전했습니다.&lt;/li&gt;
  &lt;li&gt;CLF : 12종의 자격증 중 가장 기초 과정이라 별다른 공부 없이 바로 도전했습니다. 이 당시 이미 Pro 자격증 2개가 있는 저에게는, 쉬어가기 찬스와 같은 느낌이었습니다.&lt;/li&gt;
  &lt;li&gt;SCS : 실습형 시험이 존재하는 SOA를 바로 도전하기는 두려워, Specialty 중에서도 제가 가장 자신 있었던 ‘보안’에 먼저 도전했습니다.
과거 보안 기사 필기를 무난하게 합격한 경험(실기는 떨어짐😭)이 있는 저에게는 기존 보안 지식에 AWS 보안 솔루션 지식만 탑재하면 되는지라 그리 어렵지 않았습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SCS 이후 저는 AWS re:Invent 2022에 참석하게 됩니다. 행사장에는 ‘AWS Certification Lounge’라고 AWS 자격증이 하나라도 있다면, 간식과 아래와 같은 사진을 찍을 수 있는 라운지가 있습니다.
당시 6개의 자격증을 보유했으므로, 손가락 6개를 펴고 사진을 찍었습니다.(S3 버킷과도 📸) 다음에 또 찍으러 가면, 12개는 어떤 포즈를 취해야 할까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/certi2.png&quot; alt=&quot;certi2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2023&quot;&gt;2023&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;DBS : 라스베이거스로 가는 비행기 안에서도 공부했는데, 연말에 느슨해져서 그런지 SCS 이후 3개월이 더 걸렸습니다. Database와 관련한 기초 지식 위주의 문제라 Specialty 6종 중에서는 가장 무난한 시험 같습니다.&lt;/li&gt;
  &lt;li&gt;SOA : C02로 시험이 개편되고 AWS의 첫 실습형 시험이 두렵게 느껴져, 응시를 매번 미뤘습니다. 이후 업무를 하며, 나름 AWS Systems Manager의 기능을 이것저것 사용해 보았다는 사실에 자신 있게 도전했습니다.
역시 Associate는 Associate입니다. Pro와 비교하여 간단하게 답이 도출되고, 걱정했던 실습형 시험도 콘솔 환경을 만지작거리다 보면 답을 제출할 수 있습니다.
13인치 맥북으로 시험을 응시하니, 실습 환경에서 &lt;strong&gt;제출 버튼이 보이지 않아&lt;/strong&gt;(&lt;strong&gt;시험 환경 외부&lt;/strong&gt; 스크롤 바로 조정) 애를 먹었던 것 외에는 가장 재미있었던 시험이었습니다.&lt;/li&gt;
  &lt;li&gt;DAS : 해당 도메인에 대하여 관련 지식이 가장 부족해, 시험을 준비하며 가장 막막했던 시험이었습니다. 또한, 이쯤 되니 퇴근 이후 및 주말에 자격증 공부를 하는 것이 매우 지겨웠습니다.
DAS의 경우 SOA 취득 이후 2주 뒤에 합격했으나, 실제로는 SOA만 공부하기 너무 지겨워 SOA, DAS, MLS를 돌아가며 공부했습니다.&lt;/li&gt;
  &lt;li&gt;MLS : ML 관련 도메인 지식이 없다면 굉장히 어렵습니다. 저는 과거 &lt;a href=&quot;http://www.yes24.com/Product/Goods/96024871&quot;&gt;혼자 공부하는 머신러닝+딥러닝&lt;/a&gt; &amp;amp; &lt;a href=&quot;http://www.yes24.com/Product/Goods/65050162&quot;&gt;케라스 창시자에게 배우는 딥러닝&lt;/a&gt;
두 권의 책으로 ML과 딥러닝에 대하여 학습한 경험이 있습니다. 운 좋게도 저는 ML 엔지니어 동기에게 과외를 받아 해당 시험을 통과할 수 있었습니다.&lt;/li&gt;
  &lt;li&gt;PAS : SAP 지식이 필요할 것 같지만 대부분의 문제 출제 포인트가 DR 전략 및 기본적인 고가용성을 보장하기 위한 설계에 관한 문제라 비교적 수월했습니다.
부족한 Sap on AWS 지식을 채우기 위해서, &lt;a href=&quot;https://docs.aws.amazon.com/sap/latest/general/welcome.html&quot;&gt;SAP 가이드 문서&lt;/a&gt;와 &lt;a href=&quot;https://explore.skillbuilder.aws/learn/course/external/view/elearning/12164/sap-on-aws-technical&quot;&gt;AWS Skill Builder에 올라온 SAP 강의&lt;/a&gt;를 수강했습니다.&lt;/li&gt;
  &lt;li&gt;ANS : 자격증을 취득하고 다음 자격증을 취득하기까지, 가장 짧은 시간이 소요된 시험입니다. 시험이 쉬워 빠르게 딴 것이 아니라, 11개를 취득하고 나니 빨리 12개를 취득하고 싶은 엄청난 동기 부여가 생겨 출퇴근 지하철, 주말, 퇴근 이후 모든 시간을 투자했습니다. 
또한, 3년간 AWS 시험공부와 업무를 하다 보니 대부분 알고 있는 네트워크 지식이라 비교적 수월하게 합격할 수 있었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;유튜브-주도-학습-️&quot;&gt;유튜브 주도 학습 📽️&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;유튜브 주도 학습&lt;/code&gt;은 &lt;strong&gt;유튜브 중독자&lt;/strong&gt;인 제가 자주 사용하는 말입니다. 유튜브에는 AWS가 올려놓은 강의 영상이 무척 많습니다.
AWS가 제작한 영상은 자격증 시험을 준비하는데도 굉장한 도움이 됩니다. 특히 DAS 시험을 준비할 때, &lt;a href=&quot;https://youtu.be/cRIXhMfUEcE&quot;&gt;실시간 스트리밍 분석 : Amazon Kinesis Data Analytics Deep Dive - 전소영 &amp;amp; 주혜령, AWS&lt;/a&gt; 영상이 엄청난 도움이 되었습니다.&lt;/p&gt;

&lt;p&gt;AWS 채널과 달리, AWS Korea 채널의 영상에는 Timestamp가 제공되지 않습니다. 그래서 저는 제가 학습한 일부 영상에 대하여 아래와 같이 타임스탬프를 댓글로 남겨 둡니다.
이렇게 하면, 나중에 기억이 흐릿해질 때 다시 찾아와 빠르게 지식 보충이 가능할뿐더러, 그냥 영상을 주입식으로 시청할 때보다 머릿속에 오래 남아있게 되는 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/youtube.png&quot; alt=&quot;youtube&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;thanks-to-&quot;&gt;Thanks To 💐&lt;/h2&gt;

&lt;p&gt;12종의 자격증을 취득해나가며, 각 분야에서 도움을 준 고마운 분들이 많습니다. 고맙습니다 🙏&lt;/p&gt;

&lt;p&gt;12종 도전을 시작하도록 열정과 응원을 준, 일본의 Ambassador &lt;a href=&quot;https://aws.amazon.com/jp/partners/ambassadors/?cards-body.sort-by=item.additionalFields.ambassadorName&amp;amp;cards-body.sort-order=asc&amp;amp;awsf.apn-ambassadors-location=*all&amp;amp;cards-body.q=Ueno&amp;amp;cards-body.q_operator=AND&quot;&gt;Ueno&lt;/a&gt;, &lt;a href=&quot;https://aws.amazon.com/jp/partners/ambassadors/?cards-body.sort-by=item.additionalFields.ambassadorName&amp;amp;cards-body.sort-order=asc&amp;amp;awsf.apn-ambassadors-location=*all&amp;amp;cards-body.q=Kumagai&amp;amp;cards-body.q_operator=AND&quot;&gt;Kumagai&lt;/a&gt; &lt;br /&gt;
지루한 여정 동안, 퇴근 이후까지 남으며 스터디메이트가 되어준 &lt;a href=&quot;https://medium.com/@nuatmochoi&quot;&gt;nuatmochoi&lt;/a&gt;, &lt;a href=&quot;https://blog.naver.com/jogilsang&quot;&gt;길팡&lt;/a&gt;, MLS 과외해준 &lt;a href=&quot;https://user-bin-ksh.medium.com/&quot;&gt;ksh&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="uncategorized" />
      
        <category term="aws" />
      

      
        <summary type="html">AWS Certification 12종 취득 회고</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">SRD Protocol 알아보기</title>
      <link href="https://heuristicwave.github.io/SRD" rel="alternate" type="text/html" title="SRD Protocol 알아보기" />
      <published>2023-04-08T00:00:00+00:00</published>
      <updated>2023-04-08T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/SRD</id>
      <content type="html" xml:base="https://heuristicwave.github.io/SRD">&lt;p&gt;Elastic Network Adapter (ENA) Express를 지탱하는 SRD 프로토콜 &lt;br /&gt;
Get read with me~ 🧐&lt;/p&gt;

&lt;p&gt;🚨 이번 포스팅은 SRD에 대하여 잘못 설명하고 있는 내용이 매우 많을 수 있음을 알립니다.
해당 포스팅은 SRD와 관련된 논문을 이해하기 위해 공부한 과정을 담은 산출물로 봐주세요!&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;작년 11월 28일 &lt;a href=&quot;https://aws.amazon.com/new/&quot;&gt;What’s New with AWS?&lt;/a&gt;에는 ENA Express라는 기술을 사용 가능해졌음을 알렸습니다. &lt;br /&gt;
&lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2022/11/elastic-network-adapter-ena-express-amazon-ec2-instances/&quot;&gt;️🔗 Introducing Elastic Network Adapter (ENA) Express for Amazon EC2 instances&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ENA Express를 사용하면, single flow 대역폭을 5 Gbps에서 최대 25 Gbps까지 늘릴 수 있다고 합니다. 해당 기능을 활성화시키는 방법은 AWS News Blog에 잘 소개되어 있습니다. &lt;br /&gt;
&lt;a href=&quot;https://aws.amazon.com/blogs/aws/new-ena-express-improved-network-latency-and-per-flow-performance-on-ec2/&quot;&gt;️🔗️ New – ENA Express: Improved Network Latency and Per-Flow Performance on EC2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;어떻게 ENA Express는 비약적인 성능 향상을 일으킬 수 있었을까요? 이번 포스팅에서는 아마존의 독자 프로세서(Graviton)를 만든 Annapurna Labs가 IEEE에 개재한 paper를 통해 ENA Express 기술을 지탱하는 SRD 프로토콜에 대하여 알아보겠습니다. &lt;br /&gt;
&lt;a href=&quot;https://ieeexplore.ieee.org/document/9167399&quot;&gt;️🔗️ A Cloud-Optimized Transport Protocol for Elastic and Scalable HPC&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;📄 모양은 Paper에 실린 내용을 &lt;a href=&quot;https://www.deepl.com/translator&quot;&gt;DeepL&lt;/a&gt;과 &lt;a href=&quot;https://papago.naver.com/&quot;&gt;papago&lt;/a&gt; 번역을 바탕으로 &lt;strong&gt;요약&lt;/strong&gt;한 내용이며,&lt;br /&gt; 🗣️ 모양에서 &lt;strong&gt;배경지식과 부연 설명&lt;/strong&gt; 등을 언급합니다.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;📄 안나푸르나 연구소는 현재 상용되는 multitenant 데이터 센터 네트워크는 부하의 불균형(load imbalance) 및 일관되지 않은 지연 시간 등의 제약 사항을 극복할 수 있도록 새로운 네트워크 전송 프로토콜인 Scalable Reliable Datagram (SRD)를 만들었다고 합니다.
SRD는 패킷 순서를 유지하는 대신, overload된 경로를 피하며 가능한 많은 네트워크 경로를 통해 패킷을 전송합니다. SRD는 지터를 최소화하고 네트워크 혼잡 변동에 가장 빠르게 대응하기 위해 Nitro 네트워킹 카드에 구현되었습니다.
SRD는 AWS EFA 커널 바이패스 인터페이스를 통해 HPC(고성능 컴퓨팅)/ML 프레임워크에서 사용됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.redhat.com/en/topics/cloud-computing/what-is-multitenancy&quot;&gt;Multitenant&lt;/a&gt; : 서버 리소스가 서로 다른 사용자 간에 분할되는 공유 호스팅&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Jitter&quot;&gt;Jitter&lt;/a&gt; : 네트워크에서 종단 간 지연 시간에 따른 변동성에서 측정된 latency의 변화&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🗣️ 초록에 SRD의 탄생 배경이 잘 요약되어 있지만, “EFA 커널 바이패스 인터페이스를 통해~”라는 부분에 대하여 부연 설명을 몇 자 적어보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/images/efa_stack.png&quot; alt=&quot;efa&quot; /&gt;&lt;/p&gt;

&lt;p&gt;설명하기 앞서, Enhanced Networking에 대하여 언급하겠습니다. 향상된 네트워킹은 더 높은 대역폭, 더 높은 PPS(초당 패킷) 성능 및 지속적으로 더 낮은 지연시간을 제공합니다.
이를 지원하기 위해 Elastic Network Adapter(ENA)와 Intel 82599 Virtual Function (VF) interface 메커니즘을 사용하는 방법이 있습니다.
사진의 왼쪽 부분은 언급한 2가지 방법 중 ENA software stack입니다. 애플리케이션은 MPI(Message Passing Interface)를 사용하여 시스템의 network transport와 정보를 주고받습니다(interface).
이 방법은 운영체제의 TCP/IP 스택과 ENA 드라이버를 사용해 네트워크 통신을 가능하게 합니다.&lt;/p&gt;

&lt;p&gt;반면 오른쪽의 EFA는 Libfabric API를 통해 인터페이스 하므로 운영체제 커널을 우회하고 EFA 장치와 직접 통신해 오버헤드가 줄어들게 됩니다. ENA와 EFA는 향상된 네트워킹 성능을 제공함으로써, 고성능 컴퓨팅 작업과 기계학습 등에 적합합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html&quot;&gt;Enhanced networking on Linux&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html#efa-basics&quot;&gt;EFA basics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;서론&quot;&gt;서론&lt;/h2&gt;

&lt;p&gt;📄 AWS는 상용 이더넷 스위치를 사용해 equal-cost multipath (ECMP) 라우팅으로 high-radix Folded Clos topology를 구축합니다.
이 방식은 TCP의 플로우 별 순서를 유지하는데 유용하지만, 네트워크 사용률이나 흐름 속도(rate)를 고려하지 않습니다.
해시 충돌은 일부 링크에 “핫스폿”을 발생시켜 경로 전반에 걸쳐 균일하지 않은 부하 분산, 패킷 드롭, 처리량 저하, 높은 대기 시간(high tail latency)을 유발합니다.
패킷 지연과 패킷 드롭은 HPC/ML 애플리케이션의 요건인 저 지연을 방해하며, 효율을 떨어뜨립니다. 하나의 이상 값(outlier)이 발생하면 전체 클러스터가 대기 상태로 유지되어 암달의 법칙에 따라 확장성이 제한됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/ECMP&quot;&gt;ECMP&lt;/a&gt; : 하나의 목적지로 패킷 라우팅을 수행하면서 여러 개의 경로를 선택하는 라우팅 기법&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Amdahl%27s_law&quot;&gt;Amdahl’s law&lt;/a&gt; : 다중 프로세서를 사용할 때 이론적 속도 향상을 예측하는 법칙&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🗣️ 서론에서 제시된 전통적인 TCP의 문제점에 대하여 &lt;a href=&quot;https://youtu.be/jNYpWa7gf1A?t=1626&quot;&gt;AWS re:Invent 2022&lt;/a&gt; 영상에서 동영상과 함께 굉장히 잘 설명하고 있습니다.
꼭! 해당 영상을 시청하여 TCP 혼잡(Congestion)에 대하여 확인하시기 바랍니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;why-not-tcp&quot;&gt;Why Not TCP&lt;/h3&gt;

&lt;p&gt;📄 TCP는 인터넷이 시작된 이래 대부분의 통신에 최적의 프로토콜이지만, 지연 시간에 민감한 처리에는 적합하지 않습니다.
데이터 센터에서 TCP의 경우, 최상의 round-trip latency가 25μs 일 수 있지만, 혼잡 시의 latency outlier는 50ms에서 수초 사이가 될 수 있습니다.
해당 증상의 주원인은 손실된 TCP 패킷의 재전송입니다.&lt;/p&gt;

&lt;h3 id=&quot;why-not-roce&quot;&gt;Why Not RoCE&lt;/h3&gt;

&lt;p&gt;📄 이더넷을 통한 InfiniBand라고도 하는 RoCE(RDMA over Converged Ethernet)는 이론적으로는 AWS 데이터 센터에서 TCP의 대안을 제공할 수 있습니다.
그러나, InfiniBand 전송은 AWS(대규모 네트워크) 확장성 요구사항에 적합하지 않다는 것을 알게 되었습니다.&lt;/p&gt;

&lt;p&gt;🗣️ RoCE의 배경지식 이해를 돕기 위해, &lt;a href=&quot;https://support.huawei.com/enterprise/en/doc/EDOC1100203339&quot;&gt;HUAWEI의 기술 문서&lt;/a&gt;를 링크로 첨부합니다.
해당 문서에서 설명하는 RDMA(RemoteDirect Memory Access) 네트워크의 유형과 구조와 TCP/IP의 비교 설명이 해당 문단의 이해에 큰 도움이 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;our-approach&quot;&gt;Our Approach&lt;/h3&gt;

&lt;p&gt;📄 TCP나 다른 전송 프로토콜은 AWS가 필요로 하는 성능 수준을 제공하지 않기에, 하이퍼 스케일 데이터 센터에 최적화된 SRD(네트워크 전송 프로토콜)을 설계하기로 했습니다.
SRD는 여러 경로의 로드 밸런싱과 패킷 손실 또는 &lt;a href=&quot;https://www.ibm.com/docs/zh/fsmmn?topic=topology-understanding-network-links&quot;&gt;링크&lt;/a&gt; 장애(link failures)로부터 빠른 복구 기능을 제공합니다. SRD는 일반 이더넷 스위치에서 표준 ECMP 기능을 활용하며, 패킷 캡슐화를 조작하여 송신자가 ECMP 경로 선택을 제어합니다.
SRD는 특수한 혼잡 제어 알고리즘을 사용하여 패킷 손실 확률을 줄이고 재전송 시간을 최소화하는 등의 성능 향상을 이뤘습니다.&lt;/p&gt;

&lt;p&gt;SRD를 AWS Nitro 카드에 구현 함으로서, 물리적 네트워크 레이어와 가깝게 두어 호스트 OS 및 하이퍼바이저에서 주입되는 성능 노이즈를 피할 수 있게 했습니다.&lt;/p&gt;

&lt;p&gt;SRD는 EFA PCIe 디바이스로 호스트에 노출되며, Amazon EC2 인스턴스에서 HPC 응용 프로그램 및 ML 분산 훈련을 실행할 수 있게 합니다.
EFA는 운영 체제(OS) 바이패스 하드웨어 인터페이스를 사용하여 인스턴스 간 통신 성능을 향상시키는 “유저 스페이스 드라이버”를 제공합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/whitepapers/latest/security-design-of-aws-nitro-system/the-components-of-the-nitro-system.html#the-nitro-cards&quot;&gt;Nitro Card&lt;/a&gt; : 최신 EC2 서버는 메인 시스템 보드와 하나 이상의 Nitro 카드로 구성됩니다. EC2 서비스에서 사용하는 모든 외부 제어 인터페이스를 구현합니다.
또한 소프트웨어 정의 네트워킹, Amazon EBS 스토리지 및 인스턴스 스토리지를 제공하는 데 필요한 것과 같은 모든 I/O 인터페이스를 제공합니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/PCI_Express&quot;&gt;PCIe&lt;/a&gt; : 컴퓨터의 여러 부품들이 서로 통신하는 데 사용되는 인터페이스&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🗣️ 해당 부분에서는 SRD가 기존 TCP의 제약 사항을 극복하고 어떻게 구성되었는지 설명합니다. 위 설명과 함께 첨부된 Figure 1 그림을 보면, 기 언급된 내용을 확인할 수 있습니다.
(SRD는 기존 EFA의 software stack 동일하게, PCIe 디바이스로 호스트에 노출되며 OS를 바이패스(우회) 하는 인터페이스를 제공)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/40/9234128/9167399/shale1-3016891-small.gif&quot; alt=&quot;fig1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이어서 나오는 디자인 부분에서 더 상세한 설명을 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;scalable-reliable-datagram-design&quot;&gt;SCALABLE RELIABLE DATAGRAM DESIGN&lt;/h2&gt;

&lt;h3 id=&quot;multipath-load-balancing&quot;&gt;Multipath Load Balancing&lt;/h3&gt;

&lt;p&gt;📄 SRD는 다중 경로를 지원하지 않는 레거시 트래픽과 함께 네트워크를 공유하기 때문에, 각 경로의 round-trip time(RTT) 정보를 수집하여 과부하가 발생한 경로를 피합니다.
또한 SRD는 네트워크 링크 장애 발생 시, 전체 라우팅 업데이트를 기다리지 않고 패킷 재전송 경로를 변경하여 빠르게 복구합니다.&lt;/p&gt;

&lt;p&gt;🗣️ 해당 부분에서는 패킷 손실 가능성을 줄이기 위해 트래픽을 사용 가능한 경로에 분산이 필요한 이유와 SRD가 어떻게 여러 경로로 데이터를 분산시키는지에 대해 설명하고 있습니다.
&lt;a href=&quot;https://youtu.be/jNYpWa7gf1A?t=1413&quot;&gt;AWS re:Invent 2022&lt;/a&gt; 영상의 SRD 작동 원리를 설명할 때, 다음과 같이 언급합니다.
&lt;em&gt;SRD works by using an ECMP like packet &lt;a href=&quot;https://www.juniper.net/documentation/us/en/software/junos/is-is/ospf/topics/concept/source-packet-routing.html&quot;&gt;SPRING(Source Packet Routing in Networking)&lt;/a&gt; mechanism.&lt;/em&gt;
즉, 라우팅 기법으로 ECMP를 채택하여 네트워크의 중간 노드에 의존하지 않고 네트워크의 특정 노드 및 링크 세트를 통해 패킷을 조정하는 SPRING 메커니즘과 같이 동작한다고 합니다.
(특정 노드에 의존하지 않으므로, TCP의 해시 충돌로부터 발생한 ‘핫스폿’ 문제 회피)&lt;/p&gt;

&lt;h3 id=&quot;out-of-order-delivery&quot;&gt;Out of Order Delivery&lt;/h3&gt;

&lt;p&gt;📄 여러 경로를 통해 트래픽을 균등하게 분산시키면 대기 시간이 감소하고 패킷 드롭을 방지하는 데 도움이 되지만, large 네트워크에서는 패킷 도착 순서가 잘못될 수 있습니다.
패킷 순서를 복원하는 것은 비용이 많이 드는 작업(평균 대기 시간이 증가하거나 큰 버퍼가 필요)이므로, 순서가 맞지 않더라도 패킷을 호스트에 전달하기로 했습니다.
애플리케이션이 순서를 벗어난 패킷을 처리하는 것은 전송 계층에 메시지 경계가 불투명한 TCP와 같은 바이트 스트리밍 프로토콜에서는 불가능하지만 메시지 기반 시맨틱을 사용하면 쉽습니다.
흐름별 순서 지정 또는 기타 종류의 종속성 추적은 SRD 위의 메시징 계층에서 수행되며, 메시징 계층의 시퀀싱 정보는 패킷과 함께 다른 쪽으로 전송되어 SRD에게는 불투명(opaque) 합니다.&lt;/p&gt;

&lt;p&gt;🗣️ 데이터를 연속적인 바이트로 스트림을 보내는 TCP 통신의 개념만 있는 제게는 이 부분을 이해하기 상당히 어려웠습니다. (지금도 제대로 이해하고 있지 못하고 있을 수도 있습니다. 😂)
패킷의 순서가 있는 프로토콜은 수신 측에서 재조립 과정이 있기에 비용(리소스)과 시간이 필요합니다. 하지만 메시지 기반의 SRD는 순서를 맞출 필요가 없으며 이 작업을 메시징 계층에 위임합니다.
때문에 SRD는 메시지 레이어의 작업이 일어나는 방식을 파악하지 않기에 ‘opaque(불투명)’하다고 표현합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.watersprings.org/pub/id/draft-farrel-irtf-introduction-to-semantic-routing-01.html&quot;&gt;An Introduction to Semantic Routing&lt;/a&gt; : 해당 문단의 의미를 파악하는데 가장 도움이 된 Paper입니다. SRD가 채택한 ‘메시지 기반 시맨틱’에 대한 정보가 부족해 어려움을 겪고 있을 때, 이 문서에 나오는 시맨틱 라우팅 개념이 도움이 되었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;congestion-control&quot;&gt;Congestion Control&lt;/h3&gt;

&lt;p&gt;📄 다중 경로 분산은 네트워크 내 중간의 스위치 부하를 줄이지만, incast(다수의 흐름이 스위치의 동일 인터페이스에 집중되어 해당 인터페이스의 버퍼 공간을 고갈시켜 패킷 손실을 초래하는 트래픽 패턴) 혼잡 문제를 줄이는 데 도움이 되지 않습니다.
Spraying(경로 분산)은 발신자의 링크 대역폭에 의해 제한되더라도 동일한 발신자의 micro-bursts가 다른 경로에 동시에 도착할 수 있기 때문에 인캐스트 문제를 악화시킬 수 있습니다.
따라서 다중 경로 전송에 대한 혼잡 제어는 모든 경로에서 총 큐잉을 최소화하는 것이 핵심입니다.&lt;/p&gt;

&lt;p&gt;SRD 혼잡 제어의 목표는 최소한의 in-flight bytes로 대역폭을 분배하여 큐가 쌓이는 것과 패킷 드롭을 방지하는 것입니다. 
이는 &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3012426.3022184&quot;&gt;BBR&lt;/a&gt;과 다소 유사하지만 데이터 센터 다중 경로를 추가로 고려합니다. 이는 연결 당 동적 전송률 제한과 inflight 제한을 기반으로 합니다.
발신자는 전송 속도와 RTT 변경 사항도 고려합니다. 대부분의 경로에서 RTT가 증가하거나 예상 속도가 전송 속도보다 낮아지면 혼잡이 감지됩니다.
이런 방법으로 모든 경로에 영향을 미치는 연결 전체의 혼잡을 감지하며, 개별 경로의 혼잡은 경로 재지정을 통해 독립적으로 처리합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://packetbomb.com/understanding-throughput-and-tcp-windows/&quot;&gt;in-flight bytes&lt;/a&gt; : 전송되었지만, 아직 ACK가 되지 않은 패킷&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🗣️ 다중 경로 분산은 중간 스위치 부하를 줄이지만, incast 혼잡 문제를 해결하지 못합니다. 대신, 모든 경로에서 총 큐잉을 최소화하여 혼잡 제어를 해야 합니다.
SRD 혼잡 제어는 최소한의 in-flight bytes로 대역폭을 분배하고, 큐가 쌓이는 것과 패킷 드롭을 방지하는 것이 목표입니다.
아울러 데이터 센터 다중 경로를 추가로 고려하여 연결 전체의 혼잡을 감지하고, 개별 경로의 혼잡은 경로 재지정을 통해 처리합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;user-interface-efa&quot;&gt;USER INTERFACE: EFA&lt;/h2&gt;

&lt;h3 id=&quot;efa-as-an-extension-of-elastic-network-adapter&quot;&gt;EFA as an Extension of Elastic Network Adapter&lt;/h3&gt;

&lt;p&gt;📄 Nitro 카드에는 클래식 네트워크 장치를 호스트에 제공하는 동시에 AWS VPC 용 데이터 플레인을 구현하는 ENA PCIe 컨트롤러가 포함되어 있습니다.
Enhanced Networking은 하이퍼바이저의 개입 없이 고성능 네트워킹 기능을 제공하며, 기존의 반가상화 네트워크 인터페이스 보다 더 높은 성능을 제공합니다. EFA는 HPC/ML에 적합한 Nitro VPC 카드가 제공하는 추가 옵션 서비스입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 플레인 : 서비스의 기본 기능을 제공 예) 실행 중인 EC2 instance 자체, EBS 볼륨 읽기/쓰기, S3 버킷 객체 GET/PUT, Route 53 DNS queries 응답/health checks 수행&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🗣️ 해당 부분은 초록에서 언급한 EFA 배경지식을 알고 있는 것으로 충분합니다. Nitro 카드가 제공하던 Enhanced Networking의 방법 중 ENA와 EFA가 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;efa-srd-transport-type&quot;&gt;EFA SRD Transport Type&lt;/h3&gt;

&lt;p&gt;📄 모든 EFA 데이터 통신은 queue pairs(QPs)를 통해 이뤄집니다. QP는 전송 큐와 수신 큐를 포함하는 주소 지정이 가능한 엔드포인트 사용자 공간에서 직접 메시지를 비동기적으로 보내고 받는데 사용됩니다.
대규모 클러스터에서 모든 프로세스 간의 모든 연결을 설정하려면 많은 QP가 필요하지만, EFA SRD 전송은 QP의 수를 줄일 수 있습니다. 
SRD는 InfiniBand reliable datagram(RD) 모델과 유사하지만, 메시지 크기를 제한하고 순서에 맞지 않게 전달하여 RD의 한계를 없앴습니다.
따라서 head-of-line blocking을 생성하지 않고도 애플리케이션 흐름이 서로 간섭하지 않고 다중화될 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/amzn/amzn-drivers/blob/master/kernel/linux/efa/SRD.txt&quot;&gt;SRD&lt;/a&gt; : 해당 부분에서 참고로 소개된 SRD가 필요한 QP 수를 줄이는 방법을 기재한 문서.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Head-of-line_blocking&quot;&gt;Head-of-line blocking&lt;/a&gt; : 패킷 라인에서 첫 번째 패킷에 의해 큐에 보류될 때 발생하는 성능 제한 현상&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🗣️ SRD의 방식과 유사한 InfiniBand에서는 QP는 비용이 많이 드는 리소스뿐만 아니라, 동일한 목적지 QP로 순서대로 전달해야 하는 복잡성이 있습니다.
그러나 SRD는 순서에 맞지 않게 전달하는 특성으로 인해 기존(RD) QP의 복잡성이 줄고 결과적으로 QP의 수를 줄게 합니다.&lt;/p&gt;

&lt;h3 id=&quot;out-of-order-packet-handling-challenges&quot;&gt;Out of Order Packet Handling Challenges&lt;/h3&gt;

&lt;p&gt;📄 EFA SRD QP 의미론(semantics)은 EFA 상위 레이어 처리에 대해 unfamiliar 순서 지정 요구 사항을 도입했고, 이를 “Messaging Layer”라고 합니다. 
메시지 계층은 일반적으로 HPC 애플리케이션에서 네트워크 사항(specifics)을 추상화하는 데 사용됩니다.
이 새로운 기능은 신뢰성 레이어가 오프로드되기 때문에 TCP와 같은 전송 구현보다 경량화되어 있습니다.&lt;/p&gt;

&lt;p&gt;이상적으로는 메시징 레이어가 수행하는 버퍼 관리 및 흐름 제어는 애플리케이션과 긴밀하게 결합되어야 하는데,
이는 사용자 버퍼 관리 기능이 있는 user-space 네트워킹을 이미 지원하고 HPC와 같은 애플리케이션에 주로 초점을 맞추고 있기 때문에 실현 가능합니다.&lt;/p&gt;

&lt;p&gt;메시지 의미론(semantics)을 사용하면 대규모 전송을 위해 메시지 세그먼트가 순서를 벗어난 상태로 도착하면 데이터 복사가 필요할 수 있습니다.
이는 커널 버퍼에서 사용자 버퍼로 복사해야 하는 TCP보다 나쁘지 않습니다. EFA에서는 이 복사본를 RDMA 기능(이 글의 범위를 벗어남)을 사용하여 회피합니다.&lt;/p&gt;

&lt;p&gt;🗣️ EFA SRD QP semantics는 “Messaging Layer”라는 새로운 기능을 도입했는데, 신뢰성 레이어가 offload 되어 TCP 보다 경량화되어 있다고 합니다.
상단 Our Approach의 그림에도 나오듯이, SRD는 신뢰성 계층을 하드웨어(EFA device)로 오프로드 시켰습니다. 일반적으로 신뢰성과 관련한 기능은 TCP/IP 스택의 전송 계층에서 수행하지만,
EFA에서는 이를 하드웨어에 위임하게 구성했습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;srd-performance-evaluation&quot;&gt;SRD PERFORMANCE EVALUATION&lt;/h2&gt;

&lt;p&gt;📄 동일한 서버 세트에서 AWS 클라우드의 TCP(기본 구성 사용)와 EFA SRD 성능을 비교했습니다. (제약사항 및 실험 범위는 원문 참고)&lt;/p&gt;

&lt;h3 id=&quot;incast-fct-and-fairness&quot;&gt;Incast FCT and Fairness&lt;/h3&gt;

&lt;p&gt;📄 송신자가 barrier를 사용하여 각 전송을 거의 동시에 시작할 때 EFA/SRD 또는 TCP를 통해 MPI bandwidth 벤치마크를 실행했습니다.
아래 그림은 각각의 전송 크기에 대한 이상적인 FCT와 최대 FCT를 나타냅니다. SRD FCT는 매우 낮은 지터로 최적에 가까우며, 최대 시간이 이상보다 3~20배 높을 경우 TCP FCT는 노이즈가 발생합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Barrier_(computer_science)&quot;&gt;barrier&lt;/a&gt; : 일종의 동기화 방법, 스레드/프로세스가 다음 단계를 시작하기 전에 모든 프로세스가 준비될 수 있도록 보장&lt;/li&gt;
  &lt;li&gt;FCT(Flow Completion Time) : SRD와 TCP에 대한 흐름 완료 시간&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/40/9234128/9167399/shale2-3016891-small.gif&quot; alt=&quot;Fig 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음 그림은 2MB 전송에 대한 FCT의 CDF를 보여줍니다. 최소 재전송 시간제한이 50ms이므로 50ms를 초과하는 TCP tail latency는 재전송을 반영합니다.
50ms 미만의 샘플만 보더라도(즉, 지연이 타임아웃으로 인한 것이 아닌 경우) 많은 수의 샘플이 이상적인 값보다 3배 이상 높습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tail Latency : 상위 백분위 응답시간(percentile), 아래 그림에서는 기울기가 완만해지는 우상단 꼬리 모양 부분이 해당&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/40/9234128/9167399/shale3-3016891-small.gif&quot; alt=&quot;Fig 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;🗣️ 해당 지표에 대한 설명을 이해하기 어려웠지만, EFA가 약 12ms에 100% 도달한 반면 TCP는 3배 이상 되는 약 23 ~ 48ms 부근에서 도달한다는 것으로 이해했습니다.&lt;/p&gt;

&lt;h4 id=&quot;flow-throughput-under-persistent-congestion-incast&quot;&gt;Flow Throughput Under Persistent Congestion Incast&lt;/h4&gt;

&lt;p&gt;📄 (타임아웃으로 인한 long tail은 무시하더라도) TCP의 높은 FCT 편차(variance)를 이해하기 위해, 인캐스트 하에서 각각의 flow 처리량을 조사(exam) 했습니다.
다음 그림은 데이터를 지속적으로 전송할 때의 각 흐름의 TCP 및 SRD 처리량을 보여입니다.
SRD 처리량은 모든 흐름에서 일정하고 이상에 가까운 반면, TCP 처리량은 변동이 심하고 일부 흐름은 예상(2 Gb/s로 설정)보다 평균 처리량이 훨씬 낮습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/40/9234128/9167399/shale4-3016891-small.gif&quot; alt=&quot;Fig 4&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;multipath-load-balancing-1&quot;&gt;Multipath Load Balancing&lt;/h3&gt;

&lt;p&gt;📄 동일 랙에 위치한 8대의 서버에서 다른 랙의 8대의 서버로 플로우를 실행한, 상호 연관된 비교적 단순한(less demanding) 사례는 다음 그림과 같습니다.
TOR 스위치 업링크는 50%로 활용되며, 다운링크는 하나의 발신자만 수신자에게 보내기 때문에 혼잡하지 않습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://tech.kobeta.com/wp-content/uploads/2016/10/23315.pdf&quot;&gt;TOR(Top of Rack)&lt;/a&gt; : 랙에 설치된 서버들에 대한 트래픽을 수용하기 위해 배치된 스위&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/40/9234128/9167399/shale5-3016891-small.gif&quot; alt=&quot;Fig 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이어지는 그림은 8개 수신자 중 한 곳의 모든 흐름에 대한 TCP 및 EFA의 FCT를 보여줍니다.
이상적인 로드 밸런싱을 사용하면 혼잡이 전혀 발생하지 않겠지만, inter-switch 링크에 대한 균일하지 않은 ECMP 밸런싱으로 인해 TCP에서 혼잡과 패킷 드롭이 발생했습니다.
TCP 중앙값(Median) 지연 시간은 매우 가변적이며 평균은 예상(점선)보다 50% 높은 반면, 꼬리 지연 시간은 예상보다 1~2배 높습니다.
SRD FCT 중앙값은 이상적인 수준보다 15% 높으며, 최대 SRD FCT는 평균 TCP FCT보다 낮습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/40/9234128/9167399/shale6-3016891-small.gif&quot; alt=&quot;Fig 6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;🗣️ 지금까지 몇 가지의 실험을 통해 SRD가 TCP보다 더 개선되었다는 것을 확인시켜 줍니다. 이 Paper에서 소개하는 실험 외에도 &lt;a href=&quot;https://youtu.be/jNYpWa7gf1A?t=2027&quot;&gt;AWS re:Invent 2022 영상의 벤치마크&lt;/a&gt;에 대하여 설명하는 영상을 참고해 보세요.
&lt;em&gt;(Throughput과 Tail latencies에서 우위를 가졌습니다. 해당 영상에서 TCP는 ENA를 SRD는 ENA Express를 의미합니다.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;CONCLUSION&lt;/h2&gt;

&lt;p&gt;📄 EFA는 HPC/ML 애플리케이션들을 AWS 퍼블릭 클라우드에서 대규모로 실행할 수 있습니다. SRD를 이용하여 지연 시간이 일관되게 낮아지고 tail latency가 TCP보다 더 낮아집니다.
Nitro 카드에서 SRD 다중 경로 로드 밸런싱 및 혼잡 제어를 실행하면 패킷이 끊어질 가능성이 줄어들고, 끊어짐으로부터 더 빠르게 복구할 수 있습니다. 
이러한 기능은 네트워크 인터페이스 카드와 호스트 소프트웨어의 여러 계층 간의 기능 분할을 통해 달성됩니다.&lt;/p&gt;

&lt;p&gt;🗣️ 결론 부분은 제가 이 논문을 읽으며 느낀 감정을 몇 자 적어보겠습니다.
AWS가 기존 데이터 센터가 사용하는 TCP의 한계를 극복하기 위해, 기존에 존재하던 InfiniBand, RD 등의 기술들을 참고하여 SRD를 탄생시킨 부분이 매우 흥미롭습니다.
이 논문에 2020년 11~12월 경에 소개되었는데는, 2년여 뒤 상용화된 제품(ENA Express)까지 내놓게 되는 과정을 확인하니 너무 재미있네요.&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;이 글은 올해 작성한 글 중에서도, 글감을 떠올리고 실제 글로 탄생하기까지 가장 오랜 시간이 걸렸습니다. 처음 시도해 보는 논문 리뷰에 대하여 어떤 식으로 글을 작성할지 굉장히 많은 고민을 했습니다.
단순히 한국말로 정보 전달을 하자니 번역기를 옮겨 적은 꼴이고 이미 매우 잘 작성된 AWS Blog 글도 있기에, 어떤 차별점을 주어야 할지 고민했습니다. 그래서 위와 같이 해당 논문을 이해하기 위해 필요한 배경지식들과 제 나름의 이해한 방식을 함께 싣었습니다.
이 글을 통해 SRD에 호기심이 생기신다면, 꼭 한번 원문을 보면 스스로 이해하는 시간을 가져보시기 바랍니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="network" />
      

      
        <summary type="html">Elastic Network Adapter (ENA) Express를 지탱하는 SRD 프로토콜 Get read with me~ 🧐</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Automating git submodules with AWS Code Series (Build, Pipeline)</title>
      <link href="https://heuristicwave.github.io/migrateCodebuild" rel="alternate" type="text/html" title="Automating git submodules with AWS Code Series (Build, Pipeline)" />
      <published>2023-03-11T00:00:00+00:00</published>
      <updated>2023-03-11T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/migrateCodebuild</id>
      <content type="html" xml:base="https://heuristicwave.github.io/migrateCodebuild">&lt;p&gt;AWS Code Series (Build, Pipeline)으로 git submodule 자동화&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;여러분이 보고 계신 이 블로그(GitHub Pages 활용)는 2개의 깃헙 레포지토리를 통해 배포되고 있습니다. 첫 번째 레포지토리는 원본 소스코드를 담고 있으며,
블로그 글을 작성할 때마다 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundle exec jekyll serve&lt;/code&gt;라는 명령어로 &lt;strong&gt;localhost&lt;/strong&gt;에서 퇴고를 진행합니다.
해당 명령어는 static page를 생성할 때, url을 제 도메인이 아닌 localhost로 생성해 GitHub Pages에서는 사용할 수 없습니다.
그러므로 저는 빌드 결과물이 떨어지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;output&lt;/code&gt; 파일을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.ignore&lt;/code&gt;로 처리합니다.&lt;/p&gt;

&lt;p&gt;static page를 제 도메인으로 생성하기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundle exec jekyll build&lt;/code&gt;라는 명령어로 빌드 해야 합니다.
저는 이 절차를 CI 도구에게 위임했고, CI 도구는 markdown 형식으로 작성한 글들을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;html&lt;/code&gt; 파일로 생성하여 2번째 레포지토리에 배포합니다.&lt;/p&gt;

&lt;p&gt;저는 이것을 자동화하기 위해 기존에는 Travis CI를 사용하고 있었습니다.
현재 블로그로 CI/CD 파이프라인을 구축하고 약 2년간 88회의 Commit까지 잘 쓰고 있다가,
어느새 다음과 같은 알람을 받아 보니 크레딧 소진으로 인하여 Travis CI를 AWS 솔루션으로 대체하기로 했습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Builds have been temporarily disabled for private and public repositories due to a negative credit balance. Please go to the Plan page to replenish your credit balance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-workflow&quot;&gt;📜 Workflow&lt;/h2&gt;

&lt;p&gt;과거 제가 &lt;strong&gt;AS-IS&lt;/strong&gt; 상황에서 &lt;strong&gt;Travis CI&lt;/strong&gt;로 다음과 같은 과정을 통해 블로그에 글을 배포했었습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;사용자가 원격 저장소(GitHub)에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git push&lt;/code&gt; 명령어로 새로운 코드를 반영&lt;/li&gt;
  &lt;li&gt;GitHub과 연결해둔 Travis CI가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.travis.yml&lt;/code&gt; 파일에 정의한 대로 command 수행
    &lt;ul&gt;
      &lt;li&gt;빌드 환경 구축&lt;/li&gt;
      &lt;li&gt;소스 코드 빌드&lt;/li&gt;
      &lt;li&gt;빌드 결과물을 배포용 레포지토리에 commit &amp;amp; push&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위 과정의 &lt;strong&gt;TO-BE&lt;/strong&gt;로 Travis CI 역할을 &lt;strong&gt;CodeBuild&lt;/strong&gt;와 &lt;strong&gt;CodePipeline&lt;/strong&gt;으로 대체하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.travis.yml&lt;/code&gt; 대신 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buildspec.yaml&lt;/code&gt; 파일을 정의하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;-hands-on&quot;&gt;💻 Hands-on&lt;/h2&gt;

&lt;p&gt;Travis CI는 Source 연계(GitHub 연결)와 Build가 별도로 분리되어 있지 않습니다.
그러나 AWS의 Code Series는 CodePipeline으로 Source와 Build를 연계하고, CodeBuild에서 Build를 정의해야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;1️⃣-build-정의&quot;&gt;1️⃣ Build 정의&lt;/h3&gt;

&lt;p&gt;해당 단계는 CodeBuild 생성 시, &lt;strong&gt;Buildspec&lt;/strong&gt; 단계의 &lt;strong&gt;Insert build commands, editor&lt;/strong&gt;로 구성할 수 있습니다.
그러나 본 글에서는 직접 작성하여 &lt;strong&gt;Source 레포지토리 루트 위치&lt;/strong&gt;에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buildspec.yaml&lt;/code&gt; 파일을 위치 시켜 진행하겠습니다.
빌드 스펙은 &lt;a href=&quot;https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html&quot;&gt;공식 문서&lt;/a&gt;를 참고하여 필요한 내용들을 정의합니다.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;↪️ Git submodule 기능을 활용하기 위한 buildspec 예시&lt;/summary&gt;
  &lt;p&gt;&lt;br /&gt;
ruby 2.7, jekyll로 블로그를 git submodule로 운영하는 최소한의 설정입니다. &lt;br /&gt;
아래와 같은 commands를 기재한 이유는 troubleshooting 단계에서 설명합니다.&lt;/p&gt;

  &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: 0.2

phases:
  &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;:
    runtime-versions:
      ruby: 2.7
    commands:
      - &lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;Installing dependencies...
      - gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;bundler
      - bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--quiet&lt;/span&gt;
  pre_build:
    commands:
      - &lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;LC_ALL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;en_US.utf8&quot;&lt;/span&gt;
      - &lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;Git Setting...
      - &lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;buildZone &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;buildZone
      - git init
      - git remote add origin https://&lt;span class=&quot;nv&quot;&gt;$GITHUB_TOKEN&lt;/span&gt;@github.com/heuristicwave/GitHubPageMaker.git
      - git fetch
      - git checkout &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; origin/master
      - git submodule init
      - git submodule update &lt;span class=&quot;nt&quot;&gt;--recursive&lt;/span&gt;
  build:
    commands:
      - &lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;Building...
      - bundle &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;rake site:deploy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/details&gt;

&lt;h3 id=&quot;2️⃣-codebuild&quot;&gt;2️⃣ CodeBuild&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create build projects&lt;/code&gt;를 누르고 &lt;strong&gt;Project configuration&lt;/strong&gt;에서 프로젝트 이름을 정의합니다. 이름 이외의 설정은 비워두었습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Source&lt;/strong&gt;에서 ‘Github’을 선택하면 OAuth로 연결 혹은 personal access token으로 연결 중 한 가지 방법을 선택합니다. 2가지 방법 모두 가능하므로 편리한 것을 선택합니다.&lt;/li&gt;
  &lt;li&gt;GitHub이 연동되면 연결하고자 하는 repository를 선택하고 나머지 옵션은 비워두었습니다.&lt;/li&gt;
  &lt;li&gt;‘Git submodules’ 기능을 사용한다면, &lt;strong&gt;Additional configuration&lt;/strong&gt; 토글을 눌러 submodules을 체크합니다.&lt;/li&gt;
  &lt;li&gt;본 글에서는 Source 이벤트로 CodePipeline을 사용하므로, &lt;strong&gt;Primary source webhook events&lt;/strong&gt;는 넘어갑니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;에서는 다음과 같은 설정값을 주었습니다.
&lt;img src=&quot;../../assets/built/images/post/aws/codebuild.png&quot; alt=&quot;codebuild&quot; /&gt;&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;❗️해당 단계에서 빌드하고 자 하는 런타임 환경을 꼭 &lt;a href=&quot;https://docs.aws.amazon.com/codebuild/latest/userguide/available-runtimes.html&quot;&gt;공식 문서&lt;/a&gt;에서 확인 후, 선택하세요.
&lt;br /&gt;
❗빌드에 환경 변수를 명시했다면, &lt;strong&gt;Additional configuration&lt;/strong&gt; 토글을 눌러 환경 변수를 추가해 주세요.
이 단계는 생성 당시 추가하지 않더라도, 생성 이후 ‘Build details’ 탭에서 추가 혹은 변경이 가능합니다.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Buildspec&lt;/strong&gt;과 &lt;strong&gt;Batch configuration&lt;/strong&gt;은 비워두었습니다.&lt;/li&gt;
  &lt;li&gt;로깅과 산출물이 필요하면 &lt;strong&gt;Artifacts&lt;/strong&gt;와 &lt;strong&gt;Logs&lt;/strong&gt;를 사용하면 되지만, 저는 CodeBuild 내의 Build history만으로도 충분하기 때문에 사용하지 않았습니다.&lt;/li&gt;
  &lt;li&gt;마지막으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create build projects&lt;/code&gt; 버튼을 눌러 빌드 프로젝트를 생성합니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;3️⃣-codepipeline&quot;&gt;3️⃣ CodePipeline&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create pipeline&lt;/code&gt;을 누르고 Step 1 단계에서 ‘이름’과 ‘Service role’을 지정합니다. 기본 값으로 설정하고 다음(Step 2) 페이지로 넘어갑니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Step 2 단계에서는 ‘Source provider’로 &lt;strong&gt;GitHub (Version 2)&lt;/strong&gt;을 선택하고 ‘Connection’에서 깃헙과 연결해 줍니다. 
이어서 상황에 맞게 ‘Repository name’과 ‘Branch name’을 선택하고 ‘Output artifact’로 default를 선택합니다.
&lt;img src=&quot;../../assets/built/images/post/aws/codepipeline.png&quot; alt=&quot;codepipeline&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;default를 선택할 경우 고려 사항이 있지만, 자세한 내용은 아래 &lt;em&gt;Troubleshooting - Issue 1&lt;/em&gt;단계에서 설명하겠습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Step 3 &lt;strong&gt;Build&lt;/strong&gt; 단계에서는 앞서 생성한 Codebuild를 지정하고 다른 값들을 기본값으로 설정하고 다음 단계로 넘어갑니다.&lt;/li&gt;
  &lt;li&gt;Step 4 &lt;strong&gt;Deploy&lt;/strong&gt; 단계에서는 CodeDeploy와 같은 CD 도구 대신 Build의 command로 제어하므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Skip deploy stage&lt;/code&gt; 버튼을 눌러 넘어갑니다.&lt;/li&gt;
  &lt;li&gt;Step 5 &lt;strong&gt;Deploy&lt;/strong&gt; 단계에서는 검토를 마치고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create pipeline&lt;/code&gt; 버튼을 누르면 바로 정의한 파이프라인이 실행됩니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;️-troubleshooting&quot;&gt;⛹🏾‍♂️ Troubleshooting&lt;/h2&gt;

&lt;h3 id=&quot;issue-1&quot;&gt;Issue 1&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;fatal: not a git repository (or any parent up to mount point /codebuild)&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🖍️ CodePipeline의 Output artifact를 default 선택 시, 다음과 같은 안내 문구가 있습니다.
&lt;em&gt;Does not include git metadata about the repository.&lt;/em&gt; 즉, git metadata 정보가 없으므로 git과 관련된 명령어를 사용할 수 없습니다. &lt;br /&gt;
🖋️ metadata 정보만 없을 뿐, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ls&lt;/code&gt; 명령어를 삽입해 파일 시스템을 확인하면 Source로 지정한 레포지토리의 구조가 담겨 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;✏️ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git init&lt;/code&gt; 명령어를 주입해 초기 세팅 명령어를 작성합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;issue-2&quot;&gt;Issue 2&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;error: The following untracked working tree files would be overwritten by checkout&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🖍️ 위 에러로 구글링을 하면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git clean  -d  -f&lt;/code&gt; 명령어로 해결하라 하지만, 근본적인 해결 방법이 아닙니다. &lt;br /&gt; 
상황에 따라 다르지만, 제 경우 루비의 라이브러리를 설치하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Gemfile&lt;/code&gt;이 삭제되어 후속 빌드 단계에서 문제가 됩니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;✏️ 해당 문제의 근본적 원인은 Issue 1과 같이 git metadata 정보는 없지만, source repo의 파일이 담겨 발생하는 문제입니다. &lt;br /&gt;
이를 해결하기 위해 다음과 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mkdir buildZone &amp;amp;&amp;amp; cd buildZone&lt;/code&gt; 새 폴더를 만들어 해당 오류를 우회할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;issue-3&quot;&gt;Issue 3&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;ArgumentError: invalid byte sequence in US-ASCII&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🖍️ CodeBuild가 빌드 환경을 구성하는 데 사용하는 도커이미지는 기본 &lt;strong&gt;locale&lt;/strong&gt;이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSIX&lt;/code&gt;로 설정되어 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;✏️ &lt;a href=&quot;https://docs.aws.amazon.com/codebuild/latest/userguide/troubleshooting.html#troubleshooting-utf-8&quot;&gt;공식 문서&lt;/a&gt;에서 가이드 하는 데로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pre_build&lt;/code&gt;에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;export LC_ALL=&quot;en_US.utf8&quot;&lt;/code&gt; 환경 변수 주입으로 해결할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;issue-4&quot;&gt;Issue 4&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;각종 인증 이슈, 예) fatal: could not read Password for ~~~&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🖍️ 인증 정보가 잘 못 되었거나, 관련 값들을 주입하지 못했을 때 발생합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;✏️ 토큰 값 인증 방법 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git {command} https://$GITHUB_TOKEN@github.com/#{username}/#{reponame}&lt;/code&gt;&lt;br /&gt;
✏️ GitHub 비밀번호 설정 방법 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git config --global credential.helper cache&lt;/code&gt; &lt;br /&gt;
🖋️ 토큰 값과 같은 기밀성 정보는 &lt;strong&gt;parameter store, secrets-manager&lt;/strong&gt; 등을 활용해 값을 보호하세요.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;Travis CI의 경우 가이드 하는 대로 간편하게 설정이 가능했습니다. GitHub Actions의 경우 &lt;a href=&quot;https://docs.github.com/en/actions/migrating-to-github-actions&quot;&gt;공식 문서&lt;/a&gt;에서 타 CI/CD 도구에서 마이그레이션 하는 법이 굉장히 잘 명세되어 비교적 사용이 쉽습니다.
CodeBuild의 경우 일일이 다 확인하며 설정해 줘야 하는 점은 어려웠지만, 그만큼 커스텀 하여 사용할 수 있을 것 같습니다. 마지막으로 Travis CI에서 AWS Code Series로 마이그레이션 하기까지 33번의 실패가 있었던 화면을 공유하며 마치겠습니다. 🤪&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/aws/trying.png&quot; alt=&quot;try&quot; /&gt;&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해주세요! 😃&lt;/p&gt;

&lt;hr /&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="devops" />
      
        <category term="aws" />
      

      
        <summary type="html">AWS Code Series (Build, Pipeline)으로 git submodule 자동화</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Amazon EKS Multi Cluster Upgrade with ExternalDNS</title>
      <link href="https://heuristicwave.github.io/EKS_Upgrade" rel="alternate" type="text/html" title="Amazon EKS Multi Cluster Upgrade with ExternalDNS" />
      <published>2023-02-25T00:00:00+00:00</published>
      <updated>2023-02-25T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/EKS_Upgrade</id>
      <content type="html" xml:base="https://heuristicwave.github.io/EKS_Upgrade">&lt;p&gt;ExternalDNS로 Amazon EKS 멀티 클러스터 업그레이드하기&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;Amazon EKS(이하 EKS)는 &lt;a href=&quot;https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-release-calendar&quot;&gt;약 3 ~ 5&lt;/a&gt; 개월마다 새로운 버전이 출시합니다.
운영 측면에서 새로운 버전 출시는 기존 EKS의 버전 업그레이드가 필요하다는 것을 의미합니다. EKS 업그레이드는 EKS 콘솔에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;지금 업데이트&lt;/code&gt; 버튼을 눌러 손쉽게 가능합니다.&lt;/p&gt;

&lt;h2 id=&quot;-single-cluster-upgrade&quot;&gt;🏠 Single Cluster Upgrade&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/eks/cluster.png&quot; alt=&quot;clusterUpdate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 &lt;a href=&quot;https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html&quot;&gt;EKS 클러스터 버전 업데이트&lt;/a&gt;를 싱글 클러스터 기반의 업그레이드라고 하며, 비교적 손쉽게 k8s 버전 업데이트가 가능합니다.
업데이트가 손쉬운 반면 몇 가지 제약 사항도 존재합니다. 대표적으로 아래와 같이 원하는 버전으로 바로 업데이트되는 것이 아니라 순차적 단계를 거쳐야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/eks/singleUpdate.png&quot; alt=&quot;clusterUpdate&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-multi-cluster-upgrade&quot;&gt;🏘️‍ Multi Cluster Upgrade&lt;/h2&gt;

&lt;p&gt;멀티 클러스터 업그레이드는 동일한 환경의 EKS를 멀티로 구성하다 보니,
싱글 클러스터와는 달리 &lt;strong&gt;원하는 버전으로 바로 생성&lt;/strong&gt;이 가능하고 만에 하나 &lt;strong&gt;롤백&lt;/strong&gt;이 필요할 경우 기존 환경으로 돌아갈 수도 있습니다.&lt;/p&gt;

&lt;p&gt;멀티 클러스터 기반의 업그레이드 방법은 여러 가지 방법으로 진행할 수 있습니다. 그중에서도 이번 포스팅에서는 &lt;a href=&quot;https://aws.amazon.com/blogs/containers/onfidos-journey-to-a-multi-cluster-amazon-eks-architecture/&quot;&gt;AWS Blog&lt;/a&gt;에 소개된 3가지 방법 중,
&lt;strong&gt;비교적 가장 수월한 방법인 첫 번째 방법으로 한정&lt;/strong&gt;해서 이야기해 보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/eks/multiCluster.png&quot; alt=&quot;clusterUpdate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;첫 번째로 소개된 Option 1의 방법은 2개의 동일한 환경에서 Amazon Route 53의 가중치 기능을 활용하여 업그레이드하는 방식입니다.&lt;/p&gt;

&lt;p&gt;방법은 간단합니다. &lt;strong&gt;싱글 클러스터&lt;/strong&gt;에서 별다른 작업을 해주지 않았다면, 아마 Route 53의 &lt;strong&gt;Routing policy&lt;/strong&gt;를 &lt;strong&gt;Simple&lt;/strong&gt;로 설정해 두었을 겁니다.
&lt;strong&gt;멀티 클러스터&lt;/strong&gt;에서는 &lt;strong&gt;Routing policy&lt;/strong&gt;를 &lt;strong&gt;Weighted&lt;/strong&gt;로 설정해 설정한 비율로 트래픽을 분배하는 원리입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/aws/defineWeighted.png&quot; alt=&quot;clusterUpdate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 캡처와 같이 레코드를 생성할 때, 아래 3가지 요소를 주목하여 가중치 정책을 생성합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;DNS의 &lt;strong&gt;캐시를 최소화&lt;/strong&gt;하기 위해 &lt;strong&gt;TTL은 1m&lt;/strong&gt;(60 seconds)를 권장&lt;/li&gt;
  &lt;li&gt;각 다른 환경에서 &lt;strong&gt;50:50 가중치&lt;/strong&gt;를 주고 싶을 경우, &lt;strong&gt;2개의 가중치 레코드에 Weighted 값 1&lt;/strong&gt;을 부여&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Record ID&lt;/code&gt;는 레코드의 &lt;strong&gt;주석&lt;/strong&gt;과 같은 역할을 하지만 &lt;strong&gt;필수&lt;/strong&gt;로 작성해야 함 (이어서 이 값의 중요성을~~ 😱)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;externaldns&quot;&gt;ExternalDNS&lt;/h2&gt;

&lt;p&gt;Kubernetes는 KubeDNS를 내부 DNS 서버로 활용합니다. Route 53과 같은 다른 DNS 공급자를 사용하기 위해서는 &lt;a href=&quot;https://github.com/kubernetes-sigs/external-dns&quot;&gt;external-dns&lt;/a&gt;를 추가적으로 설치해 사용합니다.
물론 external-dns를 사용하지 않고 &lt;strong&gt;외부 DNS의 영역과 k8s의 영역을 분리하여 사용&lt;/strong&gt;할 수도 있지만, external-dns를 적용한다면 &lt;strong&gt;외부 DNS 공급자도 코드로 제어&lt;/strong&gt;할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;set-up&quot;&gt;Set up&lt;/h3&gt;

&lt;p&gt;ExternalDNS를 EKS에 설정하는 방법은 &lt;a href=&quot;https://aws.amazon.com/premiumsupport/knowledge-center/eks-set-up-externaldns/&quot;&gt;첨부 링크&lt;/a&gt;에 자세하게 설명되어 있지만, 놓치기 쉬운 2가지 부분을 언급하고 넘어가겠습니다.&lt;/p&gt;

&lt;h4 id=&quot;externaldns-1&quot;&gt;ExternalDNS&lt;/h4&gt;

&lt;p&gt;external-dns를 최종 배포하기 전, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Deployment&lt;/code&gt;의 아래 2가지 인자를 수정해야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--domain-filter=&amp;lt;Your_R53_Domain_Name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--txt-owner-id=&amp;lt;Your_R53_HostedZone_Id&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;🐞 이번 포스팅을 준비하며 external-dns가 간헐적으로 동작하는 경우를 목격했습니다. &lt;br /&gt;
원인은 해당 인자를 오기재했기 때문인데, 원래대로라면 동작하지 않아야 하는데 버그인 것 같습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;ingress&quot;&gt;Ingress&lt;/h4&gt;

&lt;p&gt;ExternalDNS를 제대로 설정했다면, 이어서 외부로 노출할 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ingress&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;annotations&lt;/code&gt;를 수정합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;external-dns&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;public&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;external-dns.alpha.kubernetes.io/hostname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myDomain.com&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;external-dns.alpha.kubernetes.io/set-identifier&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;recordID&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;external-dns.alpha.kubernetes.io/aws-weight&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Simple 라우팅 정책에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set-identifier&lt;/code&gt;가 없어도 되지만, 이외 라우팅 정책에서는 &lt;strong&gt;필수&lt;/strong&gt;적으로 들어가야 합니다. 
직전 콘솔에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Record ID&lt;/code&gt;를 기재하지 않았을 경우 화면이 넘어가지 않지만, external-dns에서 해당 값이 빠지면 로그와 파드 상태 모두 특이점이 발견되지 않아 원인을 찾기 어려워집니다.&lt;/p&gt;

&lt;h3 id=&quot;issue&quot;&gt;Issue&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;yaml 파일에 의도를 기재하여 배포했지만, 정작 Route 53에서 레코드가 업데이트되지 않는 경우&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;구축 초기부터 가중치 정책을 적용한 멀티 클러스터를 생성한다면 해당 이슈를 만나지 않겠지만,
싱글 클러스터로 external-dns를 운영하고 있는 환경에서 멀티 클러스터를 적용하면 &lt;a href=&quot;https://github.com/kubernetes-sigs/external-dns/issues/1411&quot;&gt;해당 이슈&lt;/a&gt;를 만날 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;UPSERT is not possible, doing UPSERT will actually do a CREATE that will fail&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이를 해결하기 위해 노출하고자 하는 Ingress를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delete &amp;amp; apply&lt;/code&gt; 한다면 우회가 가능하겠지만, 운영하고 있는 서비스라면 &lt;strong&gt;다운타임&lt;/strong&gt;이 발생할 것입니다.
지금으로서는 Route 53 콘솔 화면에서 수동으로 기존의 정책을 수정해 주고 후속으로 생성하는 클러스터는 코드로 제어하는 방법이 있습니다. 그러나 코드와 콘솔 2가지 채널에서 인프라를 다루는 방법은 바람직하지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;해당 이슈를 해결한 직후 external-dns의 logs&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;│ &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-02-25T16:28:56Z&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;info &lt;span class=&quot;nv&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Applying provider record filter for domains: [myDomain.com. .myDomain.com.]&quot;&lt;/span&gt;
│ &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-02-25T16:28:57Z&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;info &lt;span class=&quot;nv&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Desired change: CREATE ex.myDomain.com A [Id: /hostedzone/Z0HOSTEDZONEID]&quot;&lt;/span&gt;
│ &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-02-25T16:28:57Z&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;info &lt;span class=&quot;nv&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Desired change: CREATE ex.myDomain.com TXT [Id: /hostedzone/Z0HOSTEDZONEID]&quot;&lt;/span&gt;
│ &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-02-25T16:28:57Z&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;error &lt;span class=&quot;nv&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Failure in zone myDomain.com. [Id: /hostedzone/Z0HOSTEDZONEID]&quot;&lt;/span&gt;
│ &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2023-02-25T16:28:57Z&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;error &lt;span class=&quot;nv&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;InvalidChangeBatch: [RRSet with DNS name ex.myDomain.com.,
│ type TXT, SetIdentifier recordID cannot be created as a non-weighted set exists with the same name and type.]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;status code: 400, request
│ time=&quot;&lt;/span&gt;2023-02-25T16:28:57Z&lt;span class=&quot;s2&quot;&gt;&quot; level=error msg=&quot;&lt;/span&gt;failed to submit all changes &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;the following zones: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;/hostedzone/Z0HOSTEDZONEID]&lt;span class=&quot;s2&quot;&gt;&quot;

-- After changing Simple Routing policy --

│ time=&quot;&lt;/span&gt;2023-02-25T16:29:58Z&lt;span class=&quot;s2&quot;&gt;&quot; level=info msg=&quot;&lt;/span&gt;2 record&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;zone myDomain.com. &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Id: /hostedzone/Z0HOSTEDZONEID] were successfully updated&lt;span class=&quot;s2&quot;&gt;&quot;
│ time=&quot;&lt;/span&gt;2023-02-25T16:30:58Z&lt;span class=&quot;s2&quot;&gt;&quot; level=info msg=&quot;&lt;/span&gt;Applying provider record filter &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;domains: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;myDomain.com. .myDomain.com.]&lt;span class=&quot;s2&quot;&gt;&quot;
│ time=&quot;&lt;/span&gt;2023-02-25T16:30:58Z&lt;span class=&quot;s2&quot;&gt;&quot; level=info msg=&quot;&lt;/span&gt;All records are already up to &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;검증&quot;&gt;검증&lt;/h3&gt;

&lt;p&gt;실제 1:1로 라우팅이 일어나고 있나 확인하고 싶다면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;웹&lt;/code&gt; 혹은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dig&lt;/code&gt; 명령어로 확인이 가능하지만 가장 정확한 방법은 Route 53 내 &lt;strong&gt;Test record&lt;/strong&gt;를 사용하는 것입니다.
Record 테스트를 위해 Record name을 기재하고 &lt;strong&gt;Get response&lt;/strong&gt; 버튼을 누르면 &lt;strong&gt;Response returned by Route 53&lt;/strong&gt; 화면에서 실시간으로 바뀌는 IP를 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/aws/testRecord.png&quot; alt=&quot;testRecord&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;멀티-클러스터-교체-작업&quot;&gt;멀티 클러스터 교체 작업&lt;/h4&gt;

&lt;p&gt;❗️ 기존 클러스터를 A, 업그레이드를 진행할 클러스터를 B라 가정하겠습니다.&lt;/p&gt;

&lt;p&gt;B 클러스터가 문제없다 판단되면, 다시 한번 가중치를 조절해 A 클러스터를 대체합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;가중치 변화, 1:0 🔜 1:1 🔜 0:1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;B 클러스터에서 문제가 있다 판단되면 B의 가중치를 0으로 바꾸면 롤백의 효과를 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;external-dns는 Route 53 리소스를 제어할 수 있어 편리하면서도 운영이 복잡합니다. 위에서 언급한 이슈 외에도 GitOps를 구축한 상태에서 멀티 클러스터를 운용하려면, 각 클러스터마다 다른 Repository가 필요합니다.
terraform으로 external-dns를 대체할 수도 있지만, eksctl를 사용한다면 external-dns가 도움이 되니 사용 환경에 따라 적절한 도구를 사용해야 할 것 같습니다.
모든 것을 코드로 관리하는 것은 쉽지 않네요. 🤣&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="devops" />
      
        <category term="eks" />
      

      
        <summary type="html">ExternalDNS로 Amazon EKS 멀티 클러스터 업그레이드하기</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Using OpenAI API with AWS Lambda</title>
      <link href="https://heuristicwave.github.io/OpenAI_Lambda" rel="alternate" type="text/html" title="Using OpenAI API with AWS Lambda" />
      <published>2023-02-02T20:00:00+00:00</published>
      <updated>2023-02-02T20:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/OpenAI_Lambda</id>
      <content type="html" xml:base="https://heuristicwave.github.io/OpenAI_Lambda">&lt;p&gt;AWS Lambda, OpenAI API를 활용한 개인 AI 봇 만들기&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;2월 2일 &lt;a href=&quot;https://www.facebook.com/groups/awskrug/&quot;&gt;AWSKRUG&lt;/a&gt;의 Slack 채널에서 ChatGPT Slack App 테스트를 시작했다는 글을 보고,
저도 메신저와 연동하여 ChatGPT를 사용해 보고 싶은 욕심이 생겼습니다. (아직, ChatGPT를 개인 봇에 적용하지는 않았습니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/awskrug.png&quot; alt=&quot;awskrug&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🖍 해당 포스팅에서는 &lt;strong&gt;ChatGPT&lt;/strong&gt;가 아닌 GPT-3 모델 중, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-davinci-003&lt;/code&gt; 모델을 사용했습니다.
&lt;br /&gt;&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;배경 지식 : &lt;a href=&quot;https://www.reddit.com/r/OpenAI/comments/zdrnsf/difference_between_chatgpt_and_the_new_davinci_3/&quot;&gt;Difference between ChatGPT and the new davinci 3 model?&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;이미 인터넷에 OpenAI API를 Slack과 연동하여 사용하고 있는 사례들은 많아,
제가 근무하는 회사에서 사용하고 있는 &lt;a href=&quot;https://dooray.com/main/&quot;&gt;NHN의 협업 툴 Dooray&lt;/a&gt;와 연동하기로 했습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 해당 포스팅에서는 Dooray와 AWS Lambda의 통합 방법을 다루지만,
두레이 외의 다른 메신저 도구와도 연동하는 방법이 유사하므로 해당 방법을 응용하여 활용할 수 있습니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-workflow&quot;&gt;🧭 Workflow&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/dooraygpt.png&quot; alt=&quot;DoorayGPT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위크플로우는 위와 같습니다. 사용자가 메신저에서 제공하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&lt;/code&gt; 커맨드로 질의를 하면,
해당 요청이 AWS Lambda를 통해 OpenAI의 API를 활용해 질의에 대한 대답을 받아 메신저로 전달합니다.&lt;/p&gt;

&lt;p&gt;해당 기능을 구현하기 위해서는 &lt;a href=&quot;https://platform.openai.com/account/api-keys&quot;&gt;OpenAI API keys&lt;/a&gt;와 AWS Lambda가 필요합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;작업 순서&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Lambda Layer 추가&lt;/li&gt;
  &lt;li&gt;Lambda Function 배포&lt;/li&gt;
  &lt;li&gt;Lambda Function URL 생성&lt;/li&gt;
  &lt;li&gt;Messenger 서비스와 Lambda 통합&lt;/li&gt;
  &lt;li&gt;Messenger 서비스의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POST&lt;/code&gt;에 맞춰 Lambda Function 수정&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;️-aws-lambda로-openai-api-활용하기&quot;&gt;🛠️ AWS Lambda로 OpenAI API 활용하기&lt;/h2&gt;

&lt;p&gt;OpenAI의 &lt;a href=&quot;https://platform.openai.com/docs/api-reference/introduction&quot;&gt;API REFERENCE&lt;/a&gt;를 확인하면 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Python&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node.js&lt;/code&gt;를 활용한 예시가 상세하게 나옵니다.
예시에 나오는 대로 해당 코드를 Amazon EC2를 대여하여 상시 운영 서버에서 활용해도 되지만, 메신저에 연동하여 잠깐만 활용할 예정이므로 Serverless 컴퓨팅 서비스인 Lambda를 사용하겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;aws-lambda-layer-추가하기&quot;&gt;AWS Lambda Layer 추가하기&lt;/h3&gt;

&lt;p&gt;Python으로 OpenAI를 사용하기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;openai&lt;/code&gt; 파이썬 바인딩이 필요합니다.
이를 위해 람다에서 여러 함수가 공유하는 코드 및 데이터를 중앙에서 관리하는 방식인 &lt;strong&gt;Lambda Layers&lt;/strong&gt; 기능을 활용합니다.&lt;/p&gt;

&lt;p&gt;저는 OpenAI 패키지에 대한 종속성을 해결하기 위해서, &lt;a href=&quot;https://github.com/erenyasarkurt/OpenAI-AWS-Lambda-Layer&quot;&gt;OpenAI-AWS-Lambda-Layer&lt;/a&gt;를 사용했습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 해당 레포의 &lt;a href=&quot;https://github.com/erenyasarkurt/OpenAI-AWS-Lambda-Layer/blob/main/README.md&quot;&gt;README.md&lt;/a&gt;에 기재된 대로 진행하면 curl로 OpenAI를 사용할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;우선, AWS Lambda 콘솔의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Addtional resources&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Layers&lt;/code&gt;를 클릭하여 빌드 한 zip 파일을 업로드하고 호환성(python3.8, x86_64)을 체크해 준 다음 Layer를 생성합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/lambda/layers.png&quot; alt=&quot;Layers&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;aws-lambda-functions-배포&quot;&gt;AWS Lambda Functions 배포&lt;/h3&gt;

&lt;p&gt;이어서 람다 콘솔 화면에서 &lt;strong&gt;Create function&lt;/strong&gt;으로 함수를 생성하고 &lt;strong&gt;Add layer&lt;/strong&gt; 버튼을 눌러,
사전에 생성한 layer를 추가해 줍니다. &lt;em&gt;아래 사진과 같이 Layers 아이콘에 (1)이 추가되었습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/lambda/code.png&quot; alt=&quot;code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;⬆️ 앞서 언급한 오픈소스 파이썬 코드를 복사하고 &lt;a href=&quot;https://github.com/erenyasarkurt/OpenAI-AWS-Lambda-Layer/blob/main/lambda_function.py#L27&quot;&gt;27라인&lt;/a&gt;에 OpenAI로부터 발급받은 Key로 바꿔 적고 &lt;strong&gt;Deploy&lt;/strong&gt; 버튼을 눌러 배포합니다.&lt;/p&gt;

&lt;p&gt;⬇️ 이어서 &lt;strong&gt;Configuration&lt;/strong&gt;에서 Memory와 Timeout 값을 수정합니다.
&lt;em&gt;통상 129MB 정도의 메모리를 사용해 256MB와 OpenAPI로부터 응답이 늦어질 수 있으므로 1분이라는 넉넉한 시간을 주었습니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/lambda/config.png&quot; alt=&quot;config&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;strong&gt;Configuration&lt;/strong&gt; 탭의 &lt;strong&gt;Function URL&lt;/strong&gt;에서 URL을 생성합니다.
이때, &lt;strong&gt;Auth type&lt;/strong&gt;은 별도 인증 로직이 없는 &lt;strong&gt;NONE&lt;/strong&gt;으로 설정해 주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-messengerdooray와-lambda-통합하기&quot;&gt;🔄 Messenger(Dooray)와 Lambda 통합하기&lt;/h2&gt;

&lt;p&gt;저는 통합할 메신저로 두레이를 사용했습니다. 두레이에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/command&lt;/code&gt; 기능을 구현하는 방법은 다음 링크를 참고합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://helpdesk.dooray.com/share/pages/9wWo-xwiR66BO5LGshgVTg/2900080163559890590&quot;&gt;두레이 커맨드 추가하기 가이드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Slack을 비롯한 대부분의 메신저가 외부 서버와 통합하기 위해 &lt;strong&gt;RequestUrl&lt;/strong&gt;을 요구합니다.
사전에 생성한 람다의 &lt;strong&gt;Function URL&lt;/strong&gt;을 &lt;strong&gt;RequestUrl&lt;/strong&gt;에 기재하면 통합이 완료됩니다.&lt;/p&gt;

&lt;h3 id=&quot;messengerdooray-request-형식-파악하기&quot;&gt;Messenger(Dooray) Request 형식 파악하기&lt;/h3&gt;

&lt;p&gt;이전 단계에서 테스트 없이 코드를 배포했지만, 사실 람다를 코드를 개발하고 나면 Test event를 주입하여 작성한 람다가 의도한 대로 동작하는지 확인해 봐야 합니다.
그러나 외부 서비스와 연동하여 어떠한 형식으로 Event(json)가 날라오는지 모르는 상황에서는 모니터링을 통해 파악해야 합니다.
이벤트를 1회 발생시키고 &lt;strong&gt;CloudWatch Log groups&lt;/strong&gt;에서 Event를 확인합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/lambda/lambda_cw.png&quot; alt=&quot;lambda_cw&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두레이 유저가 생성한 command는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text&lt;/code&gt;라는 필드에 담기고 이는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;body&lt;/code&gt;로 감싸져 전달됩니다.
Event가 어떤 형식으로 전달되는지 알게 되었으니, 오픈소스를 해당 형식에 맞게 수정합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'body'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;기존 작성된 코드를 두레이 형식에 맞춰 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text&lt;/code&gt;로 바꿔주니 아래와 같이 구현된 모습을 확인할 수 있었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/etc/mybot.png&quot; alt=&quot;mybot&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;이번 포스팅에서 OpenAI API를 사용함에 있어 두레이라는 메신저와 람다를 통합하는 부분을 다뤘습니다.
하지만 Lambda와 외부 서비스가 어떻게 연동되는지 원리를 알면 어떤 서비스던지 연동이 가능합니다.&lt;/p&gt;

&lt;p&gt;이 밖에 현재 코드는 PoC 수준의 코드라 부족한 점이 많습니다.
API Key를 그대로 기재하면 &lt;strong&gt;보안 이슈&lt;/strong&gt;가 있으므로, AWS Secrets Manager를 활용한 별도의 환경 변수 처리가 필요합니다.
또한 외부 서비스에서 Function URL을 호출할 때도, 인증 작업을 추가해 줘야 합니다.
추후 ChatGPT 유료 버전이 나오면 결제하여 사용한 후기를 적기 약속하며 글을 마치겠습니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="serverless" />
      

      
        <summary type="html">AWS Lambda, OpenAI API를 활용한 개인 AI 봇 만들기</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">DIY Amazon EKS with eksctl</title>
      <link href="https://heuristicwave.github.io/eksctl_ppt" rel="alternate" type="text/html" title="DIY Amazon EKS with eksctl" />
      <published>2023-01-19T19:00:00+00:00</published>
      <updated>2023-01-19T19:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/eksctl_ppt</id>
      <content type="html" xml:base="https://heuristicwave.github.io/eksctl_ppt">&lt;p&gt;&lt;a href=&quot;https://www.meetup.com/awskrug/events/290666942/&quot;&gt;AWSKRUG 컨테이너 소모임🐳 - 1월 19일(목)&lt;/a&gt; 발표 자료&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;

&lt;p&gt;eksctl을 현업에서 적용하기 위해 필수적으로 필요한 최소한의 요소들을 다룹니다.&lt;/p&gt;

&lt;iframe src=&quot;https://www.slideshare.net/slideshow/embed_code/key/KnHQ8gpSIFKpbE?hostedIn=slideshare&amp;amp;page=upload&quot; width=&quot;840&quot; height=&quot;523&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;💡 SlideShare 링크를 통해 다운로드 받을 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;AWSKRUG에서는 첫 발표였는데, 부족한 발표임에도 19일 당일 소중한 시간을 내주셔서 감사합니다. 
추후, 해당 장표들을 설명하는 블로그 포스팅을 함께 개제할 예정입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;EKSCTL Tips&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./eksctl_ppt&quot;&gt;DIY Amazon EKS with eksctl (Deck)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="devops" />
      
        <category term="eks" />
      
        <category term="aws" />
      

      
        <summary type="html">AWSKRUG 컨테이너 소모임🐳 - 1월 19일(목) 발표 자료</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ECS on EC2 Walkthrough</title>
      <link href="https://heuristicwave.github.io/ECS_Walkthrough" rel="alternate" type="text/html" title="ECS on EC2 Walkthrough" />
      <published>2022-07-03T00:00:00+00:00</published>
      <updated>2022-07-03T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/ECS_Walkthrough</id>
      <content type="html" xml:base="https://heuristicwave.github.io/ECS_Walkthrough">&lt;p&gt;EC2 기반의 ECS를 다루기 위한 사소한 지식들 톱아보기!&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;당장 Amazon Elastic Container Service(이하 ECS)를 운영해야 하지만, 공식 문서를 다 읽기에는 벅차고 중요한 운영 포인트들을 빠르게 학습하기 위해 아래와 같은 요소들을 다룹니다.
&lt;em&gt;ECS 마스터&lt;/em&gt;가 될 수 있는 모든 것을 다루는 것은 아니지만, 최소한의 고민해 볼 만한 지점들을 다뤄보았습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Amazon ECS Container Agent&lt;/li&gt;
  &lt;li&gt;ECS 리소스 할당&lt;/li&gt;
  &lt;li&gt;ECS Scaling&lt;/li&gt;
  &lt;li&gt;ECS 서비스 구성&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-ecs-container-agent&quot;&gt;🕋 ECS Container Agent&lt;/h2&gt;

&lt;p&gt;EC2 기반의 ECS를 운용하기 위해서는 &lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html&quot;&gt;ECS 최적화 AMI&lt;/a&gt;를 사용해야 합니다.
일반 EC2 인스턴스로도 ECS를 운용할 수 있지만, ECS 최적화 AMI를 사용하는 것이 관리와 운용 측면에서 유리합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;예를 들어 Docker를 운영하다 보면, 미사용 상태인 컨테이너 이미지가 쌓여나가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prune&lt;/code&gt; 명령어를 통해 이미지를 정리해 주어야 합니다.
이런 상황에서 컨테이너 에이전트는 다양한 &lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/automated_image_cleanup.html#automated_image_cleanup_parameters&quot;&gt;자동화된 이미지 정리&lt;/a&gt; 옵션을 제공합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ECS-optimized AMI에는 &lt;a href=&quot;https://github.com/aws/amazon-ecs-agent&quot;&gt;Amazon ECS Container Agent&lt;/a&gt;가 기본적으로 포함되어 있습니다.
ECS 인스턴스를 부트스트랩 하는 단계에서 EC2의 user data를 사용해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/ecs/ecs.config&lt;/code&gt;에 configuration parameters을 전달합니다.&lt;/p&gt;

&lt;p&gt;아래와 같이 환경 변수를 지정하지 않아도 default 값이 지정되어 있어 운용상의 큰 문제는 없지만,
&lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html&quot;&gt;공식 문서&lt;/a&gt;를 확인해 필요한 configuration 들을 파악해야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;' &amp;gt;&amp;gt; /etc/ecs/ecs.config
ECS_CLUSTER=MyCluster
ECS_LOGLEVEL=debug
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다양한 configuration 중, 운영 환경(GPU, SPOT, 서비스 등)에 따라 필요한 Configuration 값들이 다르겠지만 일반적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ECS_RESERVED_MEMORY&lt;/code&gt;는 고려하여 지정하는 것이 좋습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 인스턴스의 모든 메모리를 테스크에 배정한다면, 테스크와 중요한 시스템 프로세스 사이에서 메모리 경합이 발생할 수 있습니다.
이를 예방하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ECS_RESERVED_MEMORY&lt;/code&gt; configuration을 사용해 메모리를 예약함으로써 풀에서 할당 가능한 메모리를 제외할 수 있습니다.
필요로 하는 최소한의 요구 메모리가 정의되어 있지는 않지만, 저는 문서의 예시처럼 256MiB로 사용하고 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-ecs-resource&quot;&gt;🎛 ECS Resource&lt;/h2&gt;

&lt;p&gt;ECS는 3가지 범주로 리소스를 설정할 수 있습니다.&lt;/p&gt;

&lt;p&gt;🥇 &lt;strong&gt;Container instance&lt;/strong&gt; : ECS 클러스터를 이루고 있는 EC2 인스턴스의 유형 &lt;br /&gt;
🥈 &lt;strong&gt;Task Size&lt;/strong&gt; : Task Definitions을 통해 정의하는 Size &lt;br /&gt;
🥉 &lt;strong&gt;Container Size&lt;/strong&gt; : Task Definitions의 Container 정의 부분에서 정의하는 Size &lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 ECS on EC2에서는 Task Size와 Container Size 방식 중 선택 가능하지만, Fargate 방식에서 Task Size는 필수입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;container-definitions&quot;&gt;Container definitions&lt;/h3&gt;

&lt;p&gt;Container Size의 리소스 할당 파라미터는 각각 다음과 같은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker run&lt;/code&gt; 명령어 옵션에 매핑됩니다. &lt;br /&gt;
&lt;strong&gt;cpu&lt;/strong&gt; : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--cpu-shares&lt;/code&gt;, &lt;strong&gt;memory&lt;/strong&gt; : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--memory&lt;/code&gt;(hard) / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--memory-reservation&lt;/code&gt;(soft)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;CPU : Unit 단위 (1,024개의 CPU 유닛은 vCPU 1개), Memory : Hard/Soft Limits&lt;/em&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hard 🆚 Soft&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hard : 명시한 값만큼 리소스 제약이 생깁니다. 때문에 클러스터 인스턴스에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker stats&lt;/code&gt; 명령어를 조회하면 LIMIT 값이 &lt;strong&gt;Hard로 명시한 값&lt;/strong&gt;으로 표시됩니다.&lt;/li&gt;
  &lt;li&gt;Soft : 명시한 값이 클러스터 인스턴스에 예약됩니다. Soft limit이므로 컨테이너 메모리 사용량이 명시한 값의 제한을 넘겨 사용 가능합니다.
Hard와 달리, 클러스터 인스턴스에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker stats&lt;/code&gt; 명령어를 조회하면 LIMIT 값이 &lt;strong&gt;클러스터 인스턴스의 총 자원&lt;/strong&gt;으로 표시됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🥇로 갈수록 더 상위 개념이며, Task Definitions에서는 🥈, 🥉을 활용해 리소스를 제어합니다.
세밀한 제어를 하고 싶다면 🥈, 🥉을 모두 사용하여 제어할 수 있으나,
🥉 사용해야 하는 특별한 이유가 없다면 🥈만을 사용해 리소스를 제어하는 것이 용이합니다.&lt;/p&gt;

&lt;h3 id=&quot;actual-available-memory&quot;&gt;Actual available memory&lt;/h3&gt;

&lt;p&gt;16GiB의 인스턴스를 프로비저닝해도 &lt;strong&gt;실제 사용 가능한 메모리(15318 MiB)&lt;/strong&gt;는 더 적습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Amazon EC2&lt;/th&gt;
      &lt;th&gt;인스턴스&lt;/th&gt;
      &lt;th&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;free -m&lt;/code&gt;&lt;/th&gt;
      &lt;th&gt;Registered&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;c5.2xlarge&lt;/td&gt;
      &lt;td&gt;16384 MiB&lt;/td&gt;
      &lt;td&gt;15574 MiB&lt;/td&gt;
      &lt;td&gt;15318 MiB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;EC2 인스턴스와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;free -m&lt;/code&gt; 명령어로 확인한 차이&lt;/p&gt;

&lt;p&gt;&lt;em&gt;ECS 플랫폼 메모리 오버헤드와 OS 커널이 차지하는 메모리로 인해 차이가 발생합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;free -m&lt;/code&gt; 명령어로 확인한 메모리와 컨테이너 인스턴스(registered)의 차이&lt;/p&gt;

&lt;p&gt;&lt;em&gt;컨테이너 에이전트를 설정할 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ECS_RESERVED_MEMORY=256&lt;/code&gt;으로 설정한 만큼 차이가 발생합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-ecs-scaling&quot;&gt;🏘 ECS Scaling&lt;/h2&gt;

&lt;p&gt;ECS의 Scaling 방법은 2가지로 정의할 수 있습니다. 해당 스케일링 기법은 선택 사항이 아니라, 2가지 모두를 고려해 적용해야 합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Service에 의하여 Task가 Scaling 되는 Horizontal Autoscaling&lt;/li&gt;
  &lt;li&gt;CapacityProvider에 의하여 컨테이너 인스턴스가 Scaling 되는 Cluster Autoscaling&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;service-auto-scaling&quot;&gt;Service auto scaling&lt;/h3&gt;

&lt;p&gt;서비스 스케일링은 또다시 &lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/userguide/service-autoscaling-targettracking.html&quot;&gt;Target tracking&lt;/a&gt;과 &lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/userguide/service-autoscaling-stepscaling.html&quot;&gt;Step&lt;/a&gt; scaling으로 나뉩니다.&lt;/p&gt;

&lt;p&gt;Target tracking은 &lt;strong&gt;CPU/Memory 사용률&lt;/strong&gt; 및 &lt;strong&gt;ALB 요청 횟수&lt;/strong&gt;를 기반의 정책이 있으며, Step 방식은 &lt;strong&gt;Alarm을 활용한 Custom&lt;/strong&gt; 정책들을 작성할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 Step scaling policies의 문서 첫 문장은 다음과 같습니다. &lt;br /&gt;
Although Amazon ECS service auto scaling supports using Application Auto Scaling step scaling policies, we recommend using target tracking scaling policies instead. &lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Step scaling은 조금 더 공격적인 정책이 필요할 때 대안으로 사용하고, Service auto scaling은 복수의 조정 정책을 동시에 활용할 수 있으므로 하나의 정책에 의존하기보다는 복수의 정책을 사용해 보다 세밀한 Scaling 정책을 만드는 게 어떨까요? 🧐&lt;/p&gt;

&lt;h3 id=&quot;cluster-auto-scaling&quot;&gt;Cluster auto scaling&lt;/h3&gt;

&lt;p&gt;Service auto scaling에 컨테이너 인스턴스 내 자원을 다 할당했을 경우, CapacityProvider EC2 Auto Scaling을 활용해 클러스터 자원을 확보합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/containers/deep-dive-on-amazon-ecs-cluster-auto-scaling/&quot;&gt;AWS 블로그&lt;/a&gt;에 자세한 작동원리가 나오므로 꼭 한번 읽어보시기 바랍니다.
해당 내용을 요약하자면 &lt;strong&gt;Capacity Provider&lt;/strong&gt;를 Cluster 인프라를 관리합니다.
이를 위해 &lt;strong&gt;CapacityProviderReservation 지표&lt;/strong&gt;가 존재하고 사전에 설정한 &lt;strong&gt;Target capacity %&lt;/strong&gt;(1~100사이의 값)에 맞춰 EC2 AutoScalingGroup(ASG)에 Trigger가 작동합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CapacityProviderReservation(%) = M(현재 인스턴스+추가 요청 인스턴스)/N(현재 인스턴스) * 100(%)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;만약 Target capacity을 100으로 지정했을 때, 현재 Cluster의 Node 개수가 3이고 CapacityProviderReservation가 200이라면
CapacityProviderReservation를 목표치(Target capacity)인 100에 맞추기 위해 3개의 EC2를 Scale-out 시킵니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ To create an empty Auto Scaling group, set the desired count to zero. &lt;br /&gt; 
Capacity Provider는 &lt;strong&gt;Desired&lt;/strong&gt; 값이 &lt;strong&gt;0&lt;/strong&gt;인 ASG와 연결되어야 합니다. 또한 CapacityProvider에 의하여 관리형 조정을 enable 한 상태에서,
ASG를 &lt;strong&gt;수동&lt;/strong&gt;으로 수정한다면 CapacityProviderReservation 계산에 영향을 미칠 수 있으므로 &lt;strong&gt;지양&lt;/strong&gt;해야 합니다. 
&lt;br /&gt;&lt;br /&gt;
🚫️ DO NOT EDIT OR DELETE &lt;br /&gt;
해당 메시지는 Service &amp;amp; Cluster Scaling이 CloudWatch에 자동으로 생성한 TargetTracking의 주석 내용입니다.
관리형 정책의 기능을 활용 시, 조금 더 세밀한 Scaling 필요하다면 알람 Trigger의 빈도가 아닌 다른 방안을 고민하도록 합니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;-ecs-service-configuration&quot;&gt;🧮 ECS Service Configuration&lt;/h2&gt;

&lt;h3 id=&quot;deployment-configuration&quot;&gt;Deployment Configuration&lt;/h3&gt;

&lt;p&gt;ECS 서비스에서 &lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_DeploymentConfiguration.html&quot;&gt;배포와 관련된 설정&lt;/a&gt;을 보면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maximumPercent&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minimumHealthyPercent&lt;/code&gt;가 있습니다.
비슷하면서도 헷갈리기 쉬운 2개의 설정값 개념은 손에 잡힐듯하면서도 쉽게 잡히지 않는 것 같아, 예시 상황을 적어보았습니다.😂&lt;/p&gt;

&lt;p&gt;&lt;em&gt;해당 개념이 조금 더 와닿을 수 있도록, 공식 문서를 읽어보시고 아래 상황이 어떨지 예상해 보세요!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;🧑🏻‍💻는 ECS &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maximumPercent&lt;/code&gt;가 200%, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minimumHealthyPercent&lt;/code&gt;가 100%로 설정되어 있으며, Rolling update 방식을 사용하고 있다.
현재 ver01을 운영하는 🧑🏻‍💻는 실수로 오류를 포함한 ver02를 배포했다. 기존 Task 4개일 때, 어떤 상황이 벌어지는가?&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;🖍 정답 보기&lt;/summary&gt;

  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minimumHealthyPercent&lt;/code&gt;가 100%이기 때문에 ver02에 프로비저닝되고 정상 상태로 확인될 때까지 ver01은 중단되지 않습니다.
ver02는 &lt;strong&gt;running&lt;/strong&gt; 상태로 진입하지 못해 &lt;strong&gt;provisioning-pending-stopped&lt;/strong&gt; 단계를 반복합니다.
이때 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maximumPercent&lt;/code&gt;가 200%임에 따라 ver02 Task는 4개와 ver01 Task 4개(합, 최대 8개)의 Task가 동시에 올라올 수 있습니다.&lt;/p&gt;

&lt;/details&gt;

&lt;h3 id=&quot;task-placement&quot;&gt;Task Placement&lt;/h3&gt;

&lt;p&gt;ECS의 서비스가 컨테이너 인스턴스에 Task를 배치하는 전략은 아래와 같이 3가지 분류됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binpack&lt;/code&gt;: CPU 또는 메모리를 최소화하기 위해 유휴 자원을 고려한 배치&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random&lt;/code&gt; : 무작위 배치&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spread&lt;/code&gt; : ami-id, availability-zone, instance-type, os-type 등을 고려한 배치&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위 3가지 전략은 단독 혹은 복수로 선택되어 사용될 수 있으며, 가용성을 확보하기 위해 AZ를 고려하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AZ + binpack&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AZ + spread&lt;/code&gt;와 같이 사용되기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;쿠버네티스를 공부해 보신 분이라면, 해당 전략은 마치 k8s의 nodeSelector와 비슷하게 동작합니다.&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;🔊 CapacityProviderReservation에 영향을 미치는 배포 설정과 배치 전략 &lt;br /&gt;
ECS 서비스 설정에서 언급한 배포 설정과 배치 전략은 가용성 문제와 직결되고 이는 비용 문제로도 이어집니다.
앞서 언급 한 CapacityProviderReservation 계산에 활용되는 M 값에 배포 설정과 배치 전략이 영향을 미친다는 점을 유의하세요!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;이번 포스팅을 통해 ECS와 관련된 내용을 정리하다 보니, AWS 내의 다른 오케스트레이션 서비스인 EKS의 운용 전략과 무척이나 비슷하다는 느낌을 지울 수 없었습니다.
쿠버네티스의 HPA 최적화, Pod 배치 및 리소스 할당 전략과 같은 포인트들은 운영을 하며 지속적으로 관리하는 관리 대상인 만큼,
위에 언급된 ECS의 운영 포인트들도 &lt;strong&gt;서비스를 배포한 이후에도 지속적으로 관심&lt;/strong&gt;을 가져야 하는 포인트임을 강조하며 마칩니다.&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      

      
        <summary type="html">EC2 기반의 ECS를 다루기 위한 사소한 지식들 톱아보기!</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Export cloudwatch log data to Amazon S3 using lambda</title>
      <link href="https://heuristicwave.github.io/Export_data_to_S3_Lambda" rel="alternate" type="text/html" title="Export cloudwatch log data to Amazon S3 using lambda" />
      <published>2022-04-07T00:00:00+00:00</published>
      <updated>2022-04-07T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/Export_data_to_S3_Lambda</id>
      <content type="html" xml:base="https://heuristicwave.github.io/Export_data_to_S3_Lambda">&lt;p&gt;본 글은 Cloudwatch Logs groups의 데이터를 Lambda를 사용해 주기적으로 S3로 export 하는 방법을 다룹니다.&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;글을 시작하기 앞서, &lt;a href=&quot;https://noob2geek.in/2021/06/18/export-aws-cloudwatch-logs-to-s3-using-lambda-functions-in-node-js/&quot;&gt;Shraddha Paghdar - Export AWS CloudWatch logs to S3 using lambda functions in Node.js&lt;/a&gt;
를 참고하여 해당 글을 작성했음을 알립니다. 본격적으로 방법을 소개하기 앞서, Cloudwatch Logs groups의 데이터를 Lambda를 사용해 주기적으로 S3로 export 하기 위한 플로우는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/background/exportLambda.png&quot; alt=&quot;imageBuilder&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Amazon EventBridge에 정의한 Rule에 의해 Lambda를 호출합니다.&lt;/li&gt;
  &lt;li&gt;이후 람다가 지정한 CloudWatch의 Logs에 적재된 데이터를 찾습니다.&lt;/li&gt;
  &lt;li&gt;2번에 연속되어 이관될 대상의 로그들이 S3로 이관됩니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;-workshop&quot;&gt;📜 Workshop&lt;/h2&gt;

&lt;h3 id=&quot;1️⃣-log를-담을-bucket-및-정책-생성하기&quot;&gt;1️⃣ Log를 담을 Bucket 및 정책 생성하기&lt;/h3&gt;

&lt;p&gt;Amazon S3 콘솔 화면에 접속해 Log들이 담길 Bucket을 생성하고 이어서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Permissions&lt;/code&gt;에서 S3 버킷에 대한 권한을 설정합니다.
해당 방법은 &lt;a href=&quot;https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/S3ExportTasksConsole.html&quot;&gt;공식 문서, 1단계와 3단계&lt;/a&gt;에 자세히 설명되어 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 공식 문서 3단계에서 기재된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random-string&lt;/code&gt;은 필요에 의한 경우 사용하세요. 해당 글에서는 편의상 생략하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2️⃣-lambda-생성하기&quot;&gt;2️⃣ Lambda 생성하기&lt;/h3&gt;

&lt;h4 id=&quot;step-1--lambda가-사용하는-iam-role--policy-생성&quot;&gt;Step 1 : Lambda가 사용하는 IAM Role &amp;amp; Policy 생성&lt;/h4&gt;

&lt;p&gt;Lambda가 Log를 Export 할 수 있도록 다음 정책을 생성합니다.
IAM에서 Create policy를 선택하고 아래 JSON을 복사하여 붙여 넣고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cloudwatch_export_task&lt;/code&gt;라는 이름으로 정책을 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;Version&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2012-10-17&quot;&lt;/span&gt;,
    &lt;span class=&quot;s2&quot;&gt;&quot;Statement&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&quot;Effect&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Allow&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Action&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;logs:CreateExportTask&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Resource&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;arn:aws:logs:{Region}:{AccountNumber}:*&quot;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lambda에 권한을 부여해 주기 위해서 IAM &amp;gt; Roles &amp;gt; Create Role을 선택합니다.
Use case로 Lambda를 선택하고 앞서 생성한 정책을 부여한 뒤, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;export_S3_lambda&lt;/code&gt;라는 이름으로 Role을 생성합니다.&lt;/p&gt;

&lt;h4 id=&quot;step-2--코드-작성&quot;&gt;Step 2 : 코드 작성&lt;/h4&gt;

&lt;p&gt;Lambda 콘솔 화면에서 아래와 같이 빈칸을 채우고, Step 1에서 만들어둔 role을 부여해 람다 함수를 생성합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/guide/exportLambda.png&quot; alt=&quot;baseimage&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 만약, Export 역할을 수행하는 &lt;strong&gt;람다 함수가 생성하는 로그&lt;/strong&gt;를 수집하고 싶을 경우에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Create a new role with basic Lambda permissions&lt;/code&gt;을
선택하고 Console에 의해 자동적으로 생성되는 Role에 Step 1에서 만든 정책을 부여하면 됩니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이어서 아래 코드를 복사하여 상황에 맞는 인자 값을 넣어주고 Deploy 합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameter&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;region : 로그 그룹과 대상 버킷은 동일 리전에 위치&lt;/li&gt;
  &lt;li&gt;destination : 로그가 이관되는 대상 버킷&lt;/li&gt;
  &lt;li&gt;logGroupName : Cloudwatch Log group 이름&lt;/li&gt;
  &lt;li&gt;destinationPrefix : 1️⃣ 에서 언급한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random-string&lt;/code&gt; 값&lt;/li&gt;
  &lt;li&gt;from/to : Lambda 함수가 호출 되는 시점을 기준으로, from/to 기간의 로그 그룹들을 export&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AWS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;aws-sdk&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cloudconfig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;2014-03-28&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;region&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;region&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cloudwatchlogs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AWS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;CloudWatchLogs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;cloudconfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;exports&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;handler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;destination&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;bucket-name&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;logGroupName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;log-groups-name&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;destinationPrefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;86400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cloudwatchlogs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createExportTask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;then&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;statusCode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;statusCode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;501&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이후 테스트 버튼을 눌러 결과값을 보면 taskId 값이 생성되고 S3에 로그가 이관된 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;3️⃣-eventbridge-트리거-생성하기&quot;&gt;3️⃣ EventBridge 트리거 생성하기&lt;/h3&gt;

&lt;p&gt;작성한 람다 함수 콘솔 화면 상단에서 &lt;strong&gt;Add trigger&lt;/strong&gt; 버튼을 눌러 다음과 같이 Rule을 생성합니다. 저는 주기를 점검하기 위해 아래와 같이 5분을 주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/post/guide/eventBridgeRule.png&quot; alt=&quot;baseimage&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;💡 &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/services-cloudwatchevents-expressions.html&quot;&gt;스케쥴 표현식 작성법&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outro&quot;&gt;Outro&lt;/h2&gt;

&lt;p&gt;지금까지 Lambda 함수와 EventBrdige를 사용하여 자동으로 로그를 S3으로 백업하는 방법을 알아보았습니다.
해당 방법 외에도 로그를 이관하는 다양한 방법들이 있으므로, 더 쉽고 좋은 방법이 있다면 알려주세요!&lt;/p&gt;

&lt;p&gt;소중한 시간을 내어 읽어주셔서 감사합니다! 잘못된 내용은 지적해 주세요! 😃&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      

      
        <summary type="html">본 글은 Cloudwatch Logs groups의 데이터를 Lambda를 사용해 주기적으로 S3로 export 하는 방법을 다룹니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Using the awslogs log driver in ECS(Fargate)</title>
      <link href="https://heuristicwave.github.io/ECS_CW_Logs" rel="alternate" type="text/html" title="Using the awslogs log driver in ECS(Fargate)" />
      <published>2022-03-01T00:00:00+00:00</published>
      <updated>2022-03-01T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/ECS_CW_Logs</id>
      <content type="html" xml:base="https://heuristicwave.github.io/ECS_CW_Logs">&lt;p&gt;ECS Task의 컨테이너가 생산하는 로그들은 CloudWatch를 활용하여 수집할 수 있습니다.
Cloudwatch Logs를 운영하며 로그 적재가 제대로 되지 않거나, Timestamp가 일치하지 않거나, 지나친 지연 시간이 발생하거나, 알아보기 어려운 형태로 로그가 쌓인다면 
아래 요소들을 고민해 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;-references&quot;&gt;📚 References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html&quot;&gt;Using the awslogs log driver&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Regular_expression&quot;&gt;Regular expression Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;fargate에서-필요한-awslogs-로그-드라이버&quot;&gt;Fargate에서 필요한 awslogs 로그 드라이버&lt;/h2&gt;

&lt;p&gt;공식 문서에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awslogs-region&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awslogs-group&lt;/code&gt; 만이 필요하다고 하지만, &lt;strong&gt;Fargate&lt;/strong&gt;를 사용하는 경우 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awslogs-stream-prefix&lt;/code&gt;이 추가적으로 필요합니다.
또한, 가시성을 확보하기 위해 CloudWatch Logs에 수집된 여러 줄의 로그를 하나의 메시지로 보기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awslogs-multiline-pattern&lt;/code&gt;이 필수적으로 필요합니다.&lt;/p&gt;

&lt;h3 id=&quot;awslogs-multiline-pattern&quot;&gt;awslogs-multiline-pattern&lt;/h3&gt;

&lt;p&gt;공식 문서의 Note 부분을 보면 다음과 같은 메모를 확인할 수 있습니다. &lt;em&gt;(정말 공식 문서는 한 줄도 그냥 지나칠 수 없는 것 같습니다!)&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Multiline logging performs regular expression parsing and matching of all log messages.
This may have a negative impact on logging performance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;실제로 저는 정규 표현식을 간과하고 검증되지 않은 정규식들을 적용했다가 다음과 같은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Negative Impact&lt;/code&gt;를 만났습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;로그가 수집되기까지의 지나친 지연 시간 발생 (10분 이상)&lt;/li&gt;
  &lt;li&gt;지연시간으로 인한 Timestamp 불일치 (Ingestion time과 Event Timestamp의 과도한 오차)&lt;/li&gt;
  &lt;li&gt;1, 2번 이유로 인한 로그 미수집&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;regular-expression-lab&quot;&gt;Regular Expression Lab&lt;/h2&gt;

&lt;p&gt;지금부터 예시들을 통해, CW Logs를 운영하며 만날 수 있는 상황들을 체험해 보겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;샘플 로그를 복사하여 &lt;a href=&quot;https://regexr.com&quot;&gt;RegExr&lt;/a&gt;에서 match 여부를 테스트해 볼 수 있습니다.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;case-1️⃣&quot;&gt;Case 1️⃣&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awslogs-multiline-pattern&lt;/code&gt;의 &lt;strong&gt;value&lt;/strong&gt;로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;^INFO&lt;/code&gt;를 설정할 경우 3개의 Line 중 match 되는 라인은 몇 라인일까요?&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;INFO | &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pkg/trace/info/stats.go:104 &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;LogStats&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;                &lt;span class=&quot;c&quot;&gt;# Line 1&lt;/span&gt;
INFO | &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pkg/trace/info/stats.go:104 &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;LogStats&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;                &lt;span class=&quot;c&quot;&gt;# Line 2&lt;/span&gt;
12:15:10 UTC | INFO | &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pkg/trace/info/stats.go:104 &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;LogStats&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Line 3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;details&gt;
  &lt;summary&gt;🖍 정답 보기&lt;/summary&gt;

  &lt;blockquote&gt;
    &lt;p&gt;&lt;strong&gt;INFO&lt;/strong&gt; | (pkg/trace/info/stats.go:104 in LogStats)                # Line 1&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;^(caret) 은 전체 문자열의 시작 위치에만 일치하므로, Line 1 만이 match 됩니다.&lt;/p&gt;

&lt;/details&gt;

&lt;h3 id=&quot;case-2️⃣&quot;&gt;Case 2️⃣&lt;/h3&gt;

&lt;p&gt;다음은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;시:분:초&lt;/code&gt;를 표현하는 정규 표현식 입니다. 해당 정규 표현식은 아래 3줄을 모두 Match 시킬 수 있을까요? &lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(0[1-9]|1[0-9]|2[0-4]):(0[1-9]|[1-5][0-9]):(0[1-9]|[1-5][0-9])&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;07:36:35 | Which line will match? Line 1
08:00:01 | I am Line 2!
08:01:00 | I am Line 3!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;details&gt;
  &lt;summary&gt;🖍 정답 보기&lt;/summary&gt;

  &lt;blockquote&gt;
    &lt;p&gt;&lt;strong&gt;07:36:35&lt;/strong&gt; | I was matched &lt;br /&gt;
08:00:01 | I was not matched! &lt;br /&gt;
08:01:00 | I was not matched! &lt;br /&gt;&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;그렇다면 왜? 첫 번째 라인만이 매칭되었을까요? &lt;strong&gt;분, 초&lt;/strong&gt;에 해당하는 표현식을 유심히 살펴보면 00분 00시는 매칭되지 않습니다.
때문에 각각 (분 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(0[0-9]|[1-5][0-9])&lt;/code&gt;, 초 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(0[0-9]|[1-5][0-9])&lt;/code&gt;)로 수정해야 위 3줄을 매칭 시킬 수 있습니다.&lt;/p&gt;

&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;other-case&quot;&gt;Other Case&lt;/h3&gt;

&lt;p&gt;위 2가지 케이스만 준비된다면 모든 로그들을 제대로 분리하여 수집할 수 있을까요?&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;🤔 생각해보기&lt;/summary&gt;

  &lt;ul&gt;
    &lt;li&gt;Flag가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INFO&lt;/code&gt; 형식이 아닌 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WARN&lt;/code&gt;이 발생할 경우&lt;/li&gt;
    &lt;li&gt;Timestamp로 매칭 작업을 하는데 한 줄에 1회 이상 Timestamp가 포함된 경우
      &lt;blockquote&gt;
        &lt;p&gt;ex) &lt;strong&gt;08:00:01&lt;/strong&gt; | It’s &lt;strong&gt;08:02:03&lt;/strong&gt; right now.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/li&gt;
    &lt;li&gt;Application Crash로 인한 예상치 못한 메시지가 포함될 경우&lt;/li&gt;
    &lt;li&gt;awslogs 로그 드라이버 내의 우선순위&lt;/li&gt;
  &lt;/ul&gt;

&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;아마도 위에 기재한 것들 외에도 더 고려 할 것들이 많을 것 같습니다.
개발이나 알고리즘 문제를 풀 때와 마찬가지로 항상 예상치 못한 실패 지점을 예상하는 습관이 필요한 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;ECS Error Handling and Troubleshooting&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./ECS_Exec&quot;&gt;Using Amazon ECS Exec for debugging&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./ECS_CW_Logs&quot;&gt;Using the awslogs log driver in ECS(Fargate)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="devops" />
      

      
        <summary type="html">ECS Task의 컨테이너가 생산하는 로그들은 CloudWatch를 활용하여 수집할 수 있습니다. Cloudwatch Logs를 운영하며 로그 적재가 제대로 되지 않거나, Timestamp가 일치하지 않거나, 지나친 지연 시간이 발생하거나, 알아보기 어려운 형태로 로그가 쌓인다면 아래 요소들을 고민해 볼 수 있습니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Using Amazon ECS Exec for debugging</title>
      <link href="https://heuristicwave.github.io/ECS_Exec" rel="alternate" type="text/html" title="Using Amazon ECS Exec for debugging" />
      <published>2022-02-22T00:00:00+00:00</published>
      <updated>2022-02-22T00:00:00+00:00</updated>
      <id>https://heuristicwave.github.io/ECS_Exec</id>
      <content type="html" xml:base="https://heuristicwave.github.io/ECS_Exec">&lt;p&gt;Docker에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;exec&lt;/code&gt; 명령어를 통해 실행중인 컨테이너에 접속하여 디버깅이 가능하다.
21년 3월 부터 해당 기능이 AWS의 ECS에서도 사용가능하게 되었는데, 해당 기능을 사용하며 만났던 문제들을 기록.&lt;/p&gt;

&lt;h2 id=&quot;-references&quot;&gt;📚 References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-exec.html&quot;&gt;Using Amazon ECS Exec for debugging&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/cli/latest/reference/ecs/execute-command.html&quot;&gt;AWS CLI Cmd Ref : excute-commnad&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;exec-활성화&quot;&gt;Exec 활성화&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;SSM 에이전트와 SSM 서비스 간의 통신에 필요한 권한 부여&lt;/li&gt;
  &lt;li&gt;task-definition config 추가
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s2&quot;&gt;&quot;linuxParameters&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;initProcessEnabled&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;CLI로 execute-command enable 후, 점검
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;aws ecs create-service &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--cluster&lt;/span&gt; cluster-name &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--task-definition&lt;/span&gt; task-definition-name &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--enable-execute-command&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--service-name&lt;/span&gt; service-name &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--desired-count&lt;/span&gt; 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;아래 명령어로 활성화 여부 확인. (grep option 활용, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep -F4 &quot;managedAgents&quot;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep &quot;enableExecuteCommand&quot;&lt;/code&gt;)&lt;/p&gt;
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;aws ecs describe-tasks &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--cluster&lt;/span&gt; cluster-name &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--tasks&lt;/span&gt; task-id 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;활성화 상태일 때의 Snippet&lt;/p&gt;
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;tasks&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            ...
            &lt;span class=&quot;s2&quot;&gt;&quot;containers&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    ...
                    &lt;span class=&quot;s2&quot;&gt;&quot;managedAgents&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                            &lt;span class=&quot;s2&quot;&gt;&quot;lastStartedAt&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2021-03-01T14:49:44.574000-06:00&quot;&lt;/span&gt;,
                            &lt;span class=&quot;s2&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;ExecuteCommandAgent&quot;&lt;/span&gt;,
                            &lt;span class=&quot;s2&quot;&gt;&quot;lastStatus&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;RUNNING&quot;&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
            ...
            &lt;span class=&quot;s2&quot;&gt;&quot;enableExecuteCommand&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
            ...
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Running ECS Exec
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;aws ecs execute-command &lt;span class=&quot;nt&quot;&gt;--cluster&lt;/span&gt; cluster-name &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--task&lt;/span&gt; task-id &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--container&lt;/span&gt; container-name &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--interactive&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--command&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/bin/sh&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;문제-해결&quot;&gt;문제 해결&lt;/h2&gt;

&lt;p&gt;Exec 명령어 이후 에러 핸들 (공식 문서들에 답이 다 있엇다 😂)&lt;/p&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;An error occurred &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ClusterNotFoundException&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; when calling the ExecuteCommand operation: Cluster not found.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Cluster ARN 기입 (From AWS CLI Ref : The Amazon Resource Name (ARN) or short name of the cluster from AWS CLI Ref)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;클라이언트 PC에 SSM Plugin 설치 (From AWS Docs : Prerequisites for using ECS Exec)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;ECS Error Handling and Troubleshooting&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./ECS_Exec&quot;&gt;Using Amazon ECS Exec for debugging&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./ECS_CW_Logs&quot;&gt;Using the awslogs log driver in ECS(Fargate)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Heuristic Wave</name>
        
        
      </author>

      

      
        <category term="aws" />
      
        <category term="devops" />
      

      
        <summary type="html">Docker에서는 exec 명령어를 통해 실행중인 컨테이너에 접속하여 디버깅이 가능하다. 21년 3월 부터 해당 기능이 AWS의 ECS에서도 사용가능하게 되었는데, 해당 기능을 사용하며 만났던 문제들을 기록.</summary>
      

      
      
    </entry>
  
</feed>
